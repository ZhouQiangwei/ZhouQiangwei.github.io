<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[project-methylSeekr]]></title>
    <url>%2F2019%2F05%2F28%2Fproject-methylSeekr%2F</url>
    <content type="text"><![CDATA[安装出错，缺少libxml通过pip与conda安装都报错，找不到该包。 下载后安装123456wget ftp://xmlsoft.org/libxml2/libxml2-git-snapshot.tar.gztar -zxvf libxml2-git-snapshot.tar.gzcd libxml2-2.9.2/./configure --prefix=/public/home/qwzhou/software/libxml2makemake install 添加环境变量：12345##libxmlexport PATH=/public/home/qwzhou/software/libxml2/bin:$PATHexport CPLUS_INCLUDE_PATH=/public/home/qwzhou/software/libxml2/include:$CPLUS_INCLUDE_PATHexport C_INCLUDE_PATH=/public/home/qwzhou/software/libxml2/include:$C_INCLUDE_PATHexport LD_LIBRARY_PATH=/public/home/qwzhou/software/libxml2/lib:$LD_LIBRARY_PATH R 程序直接载入系统的module内的首先在bashrc最前添加一下内容：12345678910export LD_LIBRARY_PATH=""export LIBRARY_PATH=""export MANPATH=""export INCLUDE=""export FPATH=""export CPATH=""export MKLROOT=""export MIC_LD_LIBRARY_PATH=""export NLSPATH=""source /public/home/software/opt/moudles/Modules/3.2.10/init/bash module av R 查看存在的Rmodule load R/3.6.0 载入如果需要卸载：module unload R/3.6.0 methylSeekr使用1234567891011121314151617181920212223242526fai &lt;- read.delim(&quot;/public/home/qwzhou/project/Genome/oryza/rice_msu.fa.fai&quot;, header=F)chromosome_lengths &lt;- fai$V2names(chromosome_lengths) &lt;- fai$V1#修改格式#[15:38:08] qwzhou@mn02:~/project/Allele_Web :#awk -v OFS=&quot;\t&quot; &apos;&#123;print $1,$2,$3,$6,$5&#125;&apos; Oryza_Sativa/GSE42410/BS-Seq/GSM1039487/GSM1039487_loci.CG.txt &gt; Oryza_Sativa/GSE42410/BS-Seq/GSM1039487/GSM1039487_loci.CG.txt.methylseekr##报错#d &lt;- readMethylome(&quot;/public/home/qwzhou/project/Allele_Web/Oryza_Sativa/GSE42410/BS-Seq/GSM1039487/GSM1039487_loci.CG.txt.methylseekr&quot;, chromosome_lengths)#Error in scan(FileName, what = list(chr = character(0), pos = integer(0), :# scan()需要&apos;a real&apos;, 而不是&apos;+&apos;## 去掉第三列awk -v OFS=&quot;\t&quot; &apos;&#123;print $1,$2,$6,$5&#125;&apos; Oryza_Sativa/GSE42410/BS-Seq/GSM1039487/GSM1039487_loci.CG.txt &gt; Oryza_Sativa/GSE42410/BS-Seq/GSM1039487/GSM1039487_loci.CG.txt.methylseekrd &lt;- readMethylome(&quot;/public/home/qwzhou/project/Allele_Web/Oryza_Sativa/GSE42410/BS-Seq/GSM1039487/GSM1039487_loci.CG.txt.methylseekr&quot;, chromosome_lengths)#okawk -v OFS=&quot;\t&quot; &apos;$1!~/^#/&#123;print $1,$2&#125;&apos; Oryza_Sativa/GSE42410/BS-Seq/GSM1039487/GSM1039487.vcf &gt; Oryza_Sativa/GSE42410/BS-Seq/GSM1039487/GSM1039487.snp.methylseekrsnps.gr &lt;- readSNPTable(&quot;/public/home/qwzhou/project/Allele_Web/Oryza_Sativa/GSE42410/BS-Seq/GSM1039487/GSM1039487.snp.methylseekr&quot;, chromosome_lengths)## removr snpmeth.gr &lt;- removeSNPs(d, snps.gr)##sample = &quot;rice&quot;num.cores=4pdf(paste0(sample, &quot;.pdf&quot;), width=14)#plotAlphaDistributionOneChr(m=meth.gr, chr.sel=&quot;Chr10&quot;, num.cores=num.cores)PMDsegments.gr &lt;- segmentPMDs(m=meth.gr, chr.sel=&quot;Chr10&quot;, seqLengths=chromosome_lengths, num.cores=num.cores)head(PMDsegments.gr)#plotPMDSegmentation(m=meth, segs=PMDsegments.gr) 需要cpg islands区域：123456789git clone https://github.com/bioinfoUGR/cpgcluster.git[16:20:21] qwzhou@mn02:~/project/Genome/oryza/cpgisland :$ ln -s ../rice_msu.fa[16:20:26] qwzhou@mn02:~/project/Genome/oryza/cpgisland :$ perl ~/software/cpgcluster/CpGcluster.pl ./ 50 1E-5### 只能处理单条染色体，[16:47:55] qwzhou@mn02:~/project/Genome/oryza/cpgisland :$ awk -v ff="NA" '&#123;if($0~/^&gt;/)&#123;gsub(/&gt;/,"",$1);ff=$1".fa";print "&gt;"$1 &gt; ff&#125;else&#123;print $0 &gt;&gt; ff&#125;&#125;' ../rice_msu.faperl ~/software/cpgcluster/CpGcluster.pl /public/home/qwzhou/project/Genome/oryza/cpgisland/ 50 1E-5 预测到的cpgislands长度并不受限制，许多小于200bp，而且06年的paper换一个[17:15:27] qwzhou@mn02:~/software :$ wget ftp://ftp.ebi.ac.uk/pub/software/unix/EMBOSS/emboss-latest.tar.gz[19:48:53] qwzhou@mn02:~/software/EMBOSS-6.6.0 :$ ./configure –prefix=/public/home/qwzhou/software/EMBOSS-6.6.0make &amp;&amp; make install bashrcexport PATH=/public/home/qwzhou/software/EMBOSS-6.6.0/bin:$PATH ###12345678filelist=`ls ./*.fa`for i in $filelistdo newcpgreport -sequence ./$&#123;i&#125; -window 100 -shift 1 -minlen 200 -minoe 0.6 -minpc 60 -outfile $&#123;i&#125;.newcpgreportdonegrep "CpG island" *.fa.newcpgreport | awk -v OFS="\t" 'split($1,a,".") &amp;&amp; sub(/\.\./,"\t",$4)&#123;print a[1],$4&#125;' &gt; rice.cpgisland.bed 继续methylSeekr123456789101112131415161718192021222324252627CpGisland &lt;- import("/public/home/qwzhou/project/Genome/oryza/cpgisland/rice.cpgisland.bed", format="bed")write.csv(calculateFDRs(meth.gr, CpGisland, PMDs=PMDsegments.gr, num.cores=num.cores)$FDRs, paste0(sample,".PMD.stats"))write.csv(calculateFDRs(meth.gr, CpGisland, num.cores=num.cores)$FDRs, paste0(sample,".stats"))### UMR LMRbuild &lt;- get("BSgenome.Osativa.MSU.MSU7")PMD.UMRLMR &lt;- segmentUMRsLMRs(m=meth.gr, meth.cutoff=0.5, nCpG.cuidentifying UMRs and LMRses, myGenomeSeq=build, seqLengths=chromosome_lengths, PMDs=PMDsegments.gr)#plotFinalSegmentation(m=meth.gr, segs=PMD.UMRLMR, meth.cutoff=0.5, PMDs=PMDsegments.gr, minCover = minMeanCov)# Repeat without filtering PMDsUMRLMR &lt;- segmentUMRsLMRs(m=meth.gr, meth.cutoff=0.5, nCpG.cutoff=5, num.cores=num.cores, myGenomeSeq=build, seqLengths=chromosome_lengths)#plotFinalSegmentation(m=meth, segs=UMRLMR, meth.cutoff=0.5, minCover = minMeanCov)dev.off()# Export to bed/bigbedtmp &lt;- list("PMD"=PMDsegments.gr[PMDsegments.gr$type=="PMD"], "UMR"=UMRLMR[UMRLMR$type=="UMR"], "LMR"=UMRLMR[UMRLMR$type=="LMR"], "PMD.UMR"=PMD.UMRLMR[PMD.UMRLMR$type=="UMR"], "PMD.LMR"=PMD.UMRLMR[PMD.UMRLMR$type=="LMR"])chrom.sizes &lt;- data.frame(seqlevels(build), seqlengths(build))write.table(chrom.sizes, paste0(sample, ".chrom.sizes"), quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)for (j in names(tmp)) &#123; bed.file.name &lt;- paste(sample, j, "bed", sep=".") export(tmp[[j]], bed.file.name, format="bed") # system(paste0("cut -f1,2,3 ", bed.file.name, " &gt; tmp; ", /public/home/qwzhou/software/EMBOSS-6.6.0/bin/bedToBigBed, " tmp ", sample, ".chrom.sizes ", gsub(".bed$", ".bb", bed.file.name), "; rm tmp")) system(paste0("cut -f1,2,3 ", bed.file.name, " &gt; tmp; /public/home/qwzhou/software/EMBOSS-6.6.0/bin/bedToBigBed tmp ", sample, ".chrom.sizes ", gsub(".bed$", ".bb", bed.file.name), "; rm tmp"))&#125; 下载UCSCwget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bedToBigBed 获取HMD首先获取gap[21:29:22] qwzhou@mn02:~/project/Genome/oryza :$ awk -v ff=”NA” -v OFS=”\t” ‘{if($0~/^&gt;/){gsub(/&gt;/,””,$1);ff=$1;}else{sub(/:/,”\t”,$0);print ff,$0}}’ batmeth2_index/rice_msu.fa.N &gt; rice_msu.fa.gapawk -v OFS=”\t” ‘{print $1,”0”,$2}’ rice_msu.fa.fai &gt; rice_msu.fa.bed awk -v OFS=”\t” ‘{print $1,$2,$3}’ ~/rice.PMD.bed ~/rice.PMD.UMR.bed ~/rice.PMD.LMR.bed ~/project/Genome/oryza/rice_msu.fa.gap | sort -k1,1 -k2,2n -k3,3n | bedtools subtract -a ~/project/Genome/oryza/rice_msu.fa.bed -b - &gt; ~/rice.HMD.bed awk -v OFS=”\t” ‘ARGIND==1{print $1,$2,$3,”PMD”}ARGIND==2{print $1,$2,$3,”LMR”}ARGIND==3{print $1,$2,$3,”UMR”}ARGIND==4{print $1,$2,$3,”HMD”}’ rice.PMD.bed rice.PMD.LMR.bed rice.PMD.UMR.bed rice.HMD.bed | sort -k1,1 -k2,2n -k3,3n &gt; rice.segment.bed]]></content>
  </entry>
  <entry>
    <title><![CDATA[project-jbrwose]]></title>
    <url>%2F2019%2F05%2F27%2Fproject-jbrwose%2F</url>
    <content type="text"><![CDATA[批量生成track conf配置文件1awk -v FS="\",\"" 'ARGIND==1&#123;a=a""$0"\n"&#125;ARGIND==2 &amp;&amp; $3~/GSM/&#123;if($6!~/RNA-Seq/)&#123;gsub(/GSMid/,$3,a);print a&#125;&#125;' jbrowse.tracks.bs.sh data_result/modify_source/Oryza_sativa_clean.csv |less methratio 2 bw12python ~/software_devp/batmeth2_to_bigwig_v3.py -sort ~/project/Genome/oryza/rice_msu.fa.fai GSM1039487.methratio.txtpython ~/software_devp/batmeth2_to_bigwig_nostrand_v3.py -sort ~/project/Genome/oryza/rice_msu.fa.fai GSM1039487.methratio.txt Jbrowser puppeteer安装失败由于连接谷歌等443，可以换镜像一试，在主目录下.npmrc文件加入~/.npmrc或者root的/root/.npmrc.npmrc 加一条 PUPPETEER_DOWNLOAD_HOST=https://npm.taobao.org/mirrors Jbrowser 开发版，下载的目录里没有dist和example_data文件夹，可以下载一个稳定版拷贝一下DNA 甲基化插件准备甲基化格式文件，发现输入文件要求与batmeth2基本一致，除了他要求的最后一列是是否甲基化，我们是甲基化水平，先尝试。 1234(base) [qwzhou@h1-lgl rawdata]$ python ../../plugins/MethylationPlugin/bin/batmeth2_to_bigwig_v3.py genome/rice_msu.fa.fai GSM1039487.methratio.txt/bin/sh: bedGraphToBigWig: 未找到命令sudo cp ../../plugins/MethylationPlugin/bin/bedGraphToBigWig_linux.x86_64 /usr/bin/bedGraphToBigWig 输出结果是空的，因为or lineAr[6].isdigit() == False必须保证第七列isMeth是整数。修改如下：123456789101112131415161718isMeth = 0 if methType == 'CG': if value &gt;= 0.7: isMeth = 1 elif methType == 'CHG': if value &gt;= 0.5: isMeth = 1 elif methType == 'CHH': if value &gt;= 0.3: isMeth = 1 #isMeth = int(lineAr[6]) # adjust for negative strand if lineAr[2] == '-': value = value * -1 # (0) chrm (1) start (2) end (3) value outStr = '&#123;:s&#125;\t&#123;:d&#125;\t&#123;:d&#125;\t&#123;:.6f&#125;&#123;:d&#125;\n'.format( chrm, pos, pos+1, value,isMeth )##最后一行value,isMeth之间没有空格？？？ 下载UCSC wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bedSort]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F05%2F11%2Ftmp%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091methsnpp="A549.snpwithmr.p.hapcut2.haplo.txt"methsnpn="A549.snpwithmr.n.hapcut2.haplo.txt"methp="A549.mr.hapcut2.p.haplo.txt "methn="A549.mr.hapcut2.n.haplo.txt "snphap="A549.snv.hapcut2.haplo.txt"## meth + snpmethsnpmerge="A549.snpwithmr.haplo.merge.txt"methmerge="A549.mr.haplo.merge.txt"hichap="../../hic/imr90/hic_out/bowtie_results/bwt2/imr90.haplo.txt"[15:44:13] qwzhou@mn02:~/project/methhap/WGBS/A549 :$ awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;methsnpp&#125; $&#123;methsnpp&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge &gt; $&#123;methsnpmerge&#125;awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;' $&#123;methsnpmerge&#125;awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;' $&#123;methsnpmerge&#125;## methawk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;methp&#125; $&#123;methp&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge &gt; $&#123;methmerge&#125;awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;' $&#123;methmerge&#125;awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;' $&#123;methmerge&#125;## snpawk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;snphap&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;snphap&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'## snp meth +hic##合并snpmeth~/project/methhap/WGBS/bsmerge $&#123;methsnpp&#125; $&#123;methsnpn&#125; &gt; snpwithmr.merge.hapcut2.haplo.txt##合并hic~/project/methhap/WGBS/bsmergehic snpwithmr.merge.hapcut2.haplo.txt $&#123;hichap&#125; &gt; snpwithmr.hap.mergedhic.txtawk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' snpwithmr.hap.mergedhic.txt | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'awk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' snpwithmr.hap.mergedhic.txt | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'### 覆盖 repeat## meth snpbedtools intersect -a $&#123;methsnpmerge&#125; -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'## methbedtools intersect -a $&#123;methmerge&#125; -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'## snpawk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;snphap&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | bedtools intersect -a - -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'### + hicawk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' snpwithmr.hap.mergedhic.txt | bedtools intersect -a - -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;']]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F05%2F04%2Fproject-asmweb-aws%2F</url>
    <content type="text"><![CDATA[body { max-width: 980px; border: 1px solid #ddd; outline: 1300px solid #fff; margin: 16px auto; } body .markdown-body { padding: 45px; } @font-face { font-family: fontawesome-mini; src: url(data:font/woff;charset=utf-8;base64,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) format('woff'); } .markdown-body { font-family: sans-serif; -ms-text-size-adjust: 100%; -webkit-text-size-adjust: 100%; color: #333333; overflow: hidden; font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif; font-size: 16px; line-height: 1.6; word-wrap: break-word; } .markdown-body a { background: transparent; } .markdown-body a:active, .markdown-body a:hover { outline: 0; } .markdown-body b, .markdown-body strong { font-weight: bold; } .markdown-body mark { background: #ff0; color: #000; font-style: italic; font-weight: bold; } .markdown-body sub, .markdown-body sup { font-size: 75%; line-height: 0; position: relative; vertical-align: baseline; } .markdown-body sup { top: -0.5em; } .markdown-body sub { bottom: -0.25em; } .markdown-body h1 { font-size: 2em; margin: 0.67em 0; } .markdown-body img { border: 0; } .markdown-body hr { -moz-box-sizing: content-box; box-sizing: content-box; height: 0; } .markdown-body pre { overflow: auto; } .markdown-body code, .markdown-body kbd, .markdown-body pre, .markdown-body samp { font-family: monospace, monospace; font-size: 1em; } .markdown-body input { color: inherit; font: inherit; margin: 0; } .markdown-body html input[disabled] { cursor: default; } .markdown-body input { line-height: normal; } .markdown-body input[type="checkbox"] { box-sizing: border-box; padding: 0; } .markdown-body table { border-collapse: collapse; border-spacing: 0; } .markdown-body td, .markdown-body th { padding: 0; } .markdown-body .codehilitetable { border: 0; border-spacing: 0; } .markdown-body .codehilitetable tr { border: 0; } .markdown-body .codehilitetable pre, .markdown-body .codehilitetable div.codehilite { margin: 0; } .markdown-body .linenos, .markdown-body .code, .markdown-body .codehilitetable td { border: 0; padding: 0; } .markdown-body td:not(.linenos) .linenodiv { padding: 0 !important; } .markdown-body .code { width: 100%; } .markdown-body .linenos div pre, .markdown-body .linenodiv pre, .markdown-body .linenodiv { border: 0; -webkit-border-radius: 0; -moz-border-radius: 0; border-radius: 0; -webkit-border-top-left-radius: 3px; -webkit-border-bottom-left-radius: 3px; -moz-border-radius-topleft: 3px; -moz-border-radius-bottomleft: 3px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; } .markdown-body .code div pre, .markdown-body .code div { border: 0; -webkit-border-radius: 0; -moz-border-radius: 0; border-radius: 0; -webkit-border-top-right-radius: 3px; -webkit-border-bottom-right-radius: 3px; -moz-border-radius-topright: 3px; -moz-border-radius-bottomright: 3px; border-top-right-radius: 3px; border-bottom-right-radius: 3px; } .markdown-body * { -moz-box-sizing: border-box; box-sizing: border-box; } .markdown-body input { font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; line-height: 1.4; } .markdown-body a { color: #4183c4; text-decoration: none; } .markdown-body a:hover, .markdown-body a:focus, .markdown-body a:active { text-decoration: underline; } .markdown-body hr { height: 0; margin: 15px 0; overflow: hidden; background: transparent; border: 0; border-bottom: 1px solid #ddd; } .markdown-body hr:before, .markdown-body hr:after { display: table; content: " "; } .markdown-body hr:after { clear: both; } .markdown-body h1, .markdown-body h2, .markdown-body h3, .markdown-body h4, .markdown-body h5, .markdown-body h6 { margin-top: 15px; margin-bottom: 15px; line-height: 1.1; } .markdown-body h1 { font-size: 30px; } .markdown-body h2 { font-size: 21px; } .markdown-body h3 { font-size: 16px; } .markdown-body h4 { font-size: 14px; } .markdown-body h5 { font-size: 12px; } .markdown-body h6 { font-size: 11px; } .markdown-body blockquote { margin: 0; } .markdown-body ul, .markdown-body ol { padding: 0; margin-top: 0; margin-bottom: 0; } .markdown-body ol ol, .markdown-body ul ol { list-style-type: lower-roman; } .markdown-body ul ul ol, .markdown-body ul ol ol, .markdown-body ol ul ol, .markdown-body ol ol ol { list-style-type: lower-alpha; } .markdown-body dd { margin-left: 0; } .markdown-body code, .markdown-body pre, .markdown-body samp { font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace; font-size: 12px; } .markdown-body pre { margin-top: 0; margin-bottom: 0; } .markdown-body kbd { background-color: #e7e7e7; background-image: -moz-linear-gradient(#fefefe, #e7e7e7); background-image: -webkit-linear-gradient(#fefefe, #e7e7e7); background-image: linear-gradient(#fefefe, #e7e7e7); background-repeat: repeat-x; border-radius: 2px; border: 1px solid #cfcfcf; color: #000; padding: 3px 5px; line-height: 10px; font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace; display: inline-block; } .markdown-body>*:first-child { margin-top: 0 !important; } .markdown-body>*:last-child { margin-bottom: 0 !important; } .markdown-body .headerlink { font: normal 400 16px fontawesome-mini; vertical-align: middle; margin-left: -16px; float: left; display: inline-block; text-decoration: none; opacity: 0; color: #333; } .markdown-body .headerlink:focus { outline: none; } .markdown-body h1 .headerlink { margin-top: 0.8rem; } .markdown-body h2 .headerlink, .markdown-body h3 .headerlink { margin-top: 0.6rem; } .markdown-body h4 .headerlink { margin-top: 0.2rem; } .markdown-body h5 .headerlink, .markdown-body h6 .headerlink { margin-top: 0; } .markdown-body .headerlink:hover, .markdown-body h1:hover .headerlink, .markdown-body h2:hover .headerlink, .markdown-body h3:hover .headerlink, .markdown-body h4:hover .headerlink, .markdown-body h5:hover .headerlink, .markdown-body h6:hover .headerlink { opacity: 1; text-decoration: none; } .markdown-body h1 { padding-bottom: 0.3em; font-size: 2.25em; line-height: 1.2; border-bottom: 1px solid #eee; } .markdown-body h2 { padding-bottom: 0.3em; font-size: 1.75em; line-height: 1.225; border-bottom: 1px solid #eee; } .markdown-body h3 { font-size: 1.5em; line-height: 1.43; } .markdown-body h4 { font-size: 1.25em; } .markdown-body h5 { font-size: 1em; } .markdown-body h6 { font-size: 1em; color: #777; } .markdown-body p, .markdown-body blockquote, .markdown-body ul, .markdown-body ol, .markdown-body dl, .markdown-body table, .markdown-body pre, .markdown-body .admonition { margin-top: 0; margin-bottom: 16px; } .markdown-body hr { height: 4px; padding: 0; margin: 16px 0; background-color: #e7e7e7; border: 0 none; } .markdown-body ul, .markdown-body ol { padding-left: 2em; } .markdown-body ul ul, .markdown-body ul ol, .markdown-body ol ol, .markdown-body ol ul { margin-top: 0; margin-bottom: 0; } .markdown-body li>p { margin-top: 16px; } .markdown-body dl { padding: 0; } .markdown-body dl dt { padding: 0; margin-top: 16px; font-size: 1em; font-style: italic; font-weight: bold; } .markdown-body dl dd { padding: 0 16px; margin-bottom: 16px; } .markdown-body blockquote { padding: 0 15px; color: #777; border-left: 4px solid #ddd; } .markdown-body blockquote>:first-child { margin-top: 0; } .markdown-body blockquote>:last-child { margin-bottom: 0; } .markdown-body table { display: block; width: 100%; overflow: auto; word-break: normal; word-break: keep-all; } .markdown-body table th { font-weight: bold; } .markdown-body table th, .markdown-body table td { padding: 6px 13px; border: 1px solid #ddd; } .markdown-body table tr { background-color: #fff; border-top: 1px solid #ccc; } .markdown-body table tr:nth-child(2n) { background-color: #f8f8f8; } .markdown-body img { max-width: 100%; -moz-box-sizing: border-box; box-sizing: border-box; } .markdown-body code, .markdown-body samp { padding: 0; padding-top: 0.2em; padding-bottom: 0.2em; margin: 0; font-size: 85%; background-color: rgba(0,0,0,0.04); border-radius: 3px; } .markdown-body code:before, .markdown-body code:after { letter-spacing: -0.2em; content: "\00a0"; } .markdown-body pre>code { padding: 0; margin: 0; font-size: 100%; word-break: normal; white-space: pre; background: transparent; border: 0; } .markdown-body .codehilite { margin-bottom: 16px; } .markdown-body .codehilite pre, .markdown-body pre { padding: 16px; overflow: auto; font-size: 85%; line-height: 1.45; background-color: #f7f7f7; border-radius: 3px; } .markdown-body .codehilite pre { margin-bottom: 0; word-break: normal; } .markdown-body pre { word-wrap: normal; } .markdown-body pre code { display: inline; max-width: initial; padding: 0; margin: 0; overflow: initial; line-height: inherit; word-wrap: normal; background-color: transparent; border: 0; } .markdown-body pre code:before, .markdown-body pre code:after { content: normal; } /* Admonition */ .markdown-body .admonition { -webkit-border-radius: 3px; -moz-border-radius: 3px; position: relative; border-radius: 3px; border: 1px solid #e0e0e0; border-left: 6px solid #333; padding: 10px 10px 10px 30px; } .markdown-body .admonition table { color: #333; } .markdown-body .admonition p { padding: 0; } .markdown-body .admonition-title { font-weight: bold; margin: 0; } .markdown-body .admonition>.admonition-title { color: #333; } .markdown-body .attention>.admonition-title { color: #a6d796; } .markdown-body .caution>.admonition-title { color: #d7a796; } .markdown-body .hint>.admonition-title { color: #96c6d7; } .markdown-body .danger>.admonition-title { color: #c25f77; } .markdown-body .question>.admonition-title { color: #96a6d7; } .markdown-body .note>.admonition-title { color: #d7c896; } .markdown-body .admonition:before, .markdown-body .attention:before, .markdown-body .caution:before, .markdown-body .hint:before, .markdown-body .danger:before, .markdown-body .question:before, .markdown-body .note:before { font: normal normal 16px fontawesome-mini; -moz-osx-font-smoothing: grayscale; -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; line-height: 1.5; color: #333; position: absolute; left: 0; top: 0; padding-top: 10px; padding-left: 10px; } .markdown-body .admonition:before { content: "\f056\00a0"; color: 333; } .markdown-body .attention:before { content: "\f058\00a0"; color: #a6d796; } .markdown-body .caution:before { content: "\f06a\00a0"; color: #d7a796; } .markdown-body .hint:before { content: "\f05a\00a0"; color: #96c6d7; } .markdown-body .danger:before { content: "\f057\00a0"; color: #c25f77; } .markdown-body .question:before { content: "\f059\00a0"; color: #96a6d7; } .markdown-body .note:before { content: "\f040\00a0"; color: #d7c896; } .markdown-body .admonition::after { content: normal; } .markdown-body .attention { border-left: 6px solid #a6d796; } .markdown-body .caution { border-left: 6px solid #d7a796; } .markdown-body .hint { border-left: 6px solid #96c6d7; } .markdown-body .danger { border-left: 6px solid #c25f77; } .markdown-body .question { border-left: 6px solid #96a6d7; } .markdown-body .note { border-left: 6px solid #d7c896; } .markdown-body .admonition>*:first-child { margin-top: 0 !important; } .markdown-body .admonition>*:last-child { margin-bottom: 0 !important; } /* progress bar*/ .markdown-body .progress { display: block; width: 300px; margin: 10px 0; height: 24px; -webkit-border-radius: 3px; -moz-border-radius: 3px; border-radius: 3px; background-color: #ededed; position: relative; box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1); } .markdown-body .progress-label { position: absolute; text-align: center; font-weight: bold; width: 100%; margin: 0; line-height: 24px; color: #333; text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000; -webkit-font-smoothing: antialiased !important; white-space: nowrap; overflow: hidden; } .markdown-body .progress-bar { height: 24px; float: left; -webkit-border-radius: 3px; -moz-border-radius: 3px; border-radius: 3px; background-color: #96c6d7; box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1); background-size: 30px 30px; background-image: -webkit-linear-gradient( 135deg, rgba(255, 255, 255, .4) 27%, transparent 27%, transparent 52%, rgba(255, 255, 255, .4) 52%, rgba(255, 255, 255, .4) 77%, transparent 77%, transparent ); background-image: -moz-linear-gradient( 135deg, rgba(255, 255, 255, .4) 27%, transparent 27%, transparent 52%, rgba(255, 255, 255, .4) 52%, rgba(255, 255, 255, .4) 77%, transparent 77%, transparent ); background-image: -ms-linear-gradient( 135deg, rgba(255, 255, 255, .4) 27%, transparent 27%, transparent 52%, rgba(255, 255, 255, .4) 52%, rgba(255, 255, 255, .4) 77%, transparent 77%, transparent ); background-image: -o-linear-gradient( 135deg, rgba(255, 255, 255, .4) 27%, transparent 27%, transparent 52%, rgba(255, 255, 255, .4) 52%, rgba(255, 255, 255, .4) 77%, transparent 77%, transparent ); background-image: linear-gradient( 135deg, rgba(255, 255, 255, .4) 27%, transparent 27%, transparent 52%, rgba(255, 255, 255, .4) 52%, rgba(255, 255, 255, .4) 77%, transparent 77%, transparent ); } .markdown-body .progress-100plus .progress-bar { background-color: #a6d796; } .markdown-body .progress-80plus .progress-bar { background-color: #c6d796; } .markdown-body .progress-60plus .progress-bar { background-color: #d7c896; } .markdown-body .progress-40plus .progress-bar { background-color: #d7a796; } .markdown-body .progress-20plus .progress-bar { background-color: #d796a6; } .markdown-body .progress-0plus .progress-bar { background-color: #c25f77; } .markdown-body .candystripe-animate .progress-bar{ -webkit-animation: animate-stripes 3s linear infinite; -moz-animation: animate-stripes 3s linear infinite; animation: animate-stripes 3s linear infinite; } @-webkit-keyframes animate-stripes { 0% { background-position: 0 0; } 100% { background-position: 60px 0; } } @-moz-keyframes animate-stripes { 0% { background-position: 0 0; } 100% { background-position: 60px 0; } } @keyframes animate-stripes { 0% { background-position: 0 0; } 100% { background-position: 60px 0; } } .markdown-body .gloss .progress-bar { box-shadow: inset 0 4px 12px rgba(255, 255, 255, .7), inset 0 -12px 0 rgba(0, 0, 0, .05); } /* MultiMarkdown Critic Blocks */ .markdown-body .critic_mark { background: #ff0; } .markdown-body .critic_delete { color: #c82829; text-decoration: line-through; } .markdown-body .critic_insert { color: #718c00 ; text-decoration: underline; } .markdown-body .critic_comment { color: #8e908c; font-style: italic; } .markdown-body .headeranchor { font: normal normal 16px fontawesome-mini; line-height: 1; display: inline-block; text-decoration: none; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; } .headeranchor:before { content: '\e157'; } .markdown-body .task-list-item { list-style-type: none; } .markdown-body .task-list-item+.task-list-item { margin-top: 3px; } .markdown-body .task-list-item input { margin: 0 4px 0.25em -20px; vertical-align: middle; } /* Media */ @media only screen and (min-width: 480px) { .markdown-body { font-size:14px; } } @media only screen and (min-width: 768px) { .markdown-body { font-size:16px; } } @media print { .markdown-body * { background: transparent !important; color: black !important; filter:none !important; -ms-filter: none !important; } .markdown-body { font-size:12pt; max-width:100%; outline:none; border: 0; } .markdown-body a, .markdown-body a:visited { text-decoration: underline; } .markdown-body .headeranchor-link { display: none; } .markdown-body a[href]:after { content: " (" attr(href) ")"; } .markdown-body abbr[title]:after { content: " (" attr(title) ")"; } .markdown-body .ir a:after, .markdown-body a[href^="javascript:"]:after, .markdown-body a[href^="#"]:after { content: ""; } .markdown-body pre { white-space: pre; white-space: pre-wrap; word-wrap: break-word; } .markdown-body pre, .markdown-body blockquote { border: 1px solid #999; padding-right: 1em; page-break-inside: avoid; } .markdown-body .progress, .markdown-body .progress-bar { -moz-box-shadow: none; -webkit-box-shadow: none; box-shadow: none; } .markdown-body .progress { border: 1px solid #ddd; } .markdown-body .progress-bar { height: 22px; border-right: 1px solid #ddd; } .markdown-body tr, .markdown-body img { page-break-inside: avoid; } .markdown-body img { max-width: 100% !important; } .markdown-body p, .markdown-body h2, .markdown-body h3 { orphans: 3; widows: 3; } .markdown-body h2, .markdown-body h3 { page-break-after: avoid; } } /*GitHub*/ .codehilite {background-color:#fff;color:#333333;} .codehilite .hll {background-color:#ffffcc;} .codehilite .c{color:#999988;font-style:italic} .codehilite .err{color:#a61717;background-color:#e3d2d2} .codehilite .k{font-weight:bold} .codehilite .o{font-weight:bold} .codehilite .cm{color:#999988;font-style:italic} .codehilite .cp{color:#999999;font-weight:bold} .codehilite .c1{color:#999988;font-style:italic} .codehilite .cs{color:#999999;font-weight:bold;font-style:italic} .codehilite .gd{color:#000000;background-color:#ffdddd} .codehilite .ge{font-style:italic} .codehilite .gr{color:#aa0000} .codehilite .gh{color:#999999} .codehilite .gi{color:#000000;background-color:#ddffdd} .codehilite .go{color:#888888} .codehilite .gp{color:#555555} .codehilite .gs{font-weight:bold} .codehilite .gu{color:#800080;font-weight:bold} .codehilite .gt{color:#aa0000} .codehilite .kc{font-weight:bold} .codehilite .kd{font-weight:bold} .codehilite .kn{font-weight:bold} .codehilite .kp{font-weight:bold} .codehilite .kr{font-weight:bold} .codehilite .kt{color:#445588;font-weight:bold} .codehilite .m{color:#009999} .codehilite .s{color:#dd1144} .codehilite .n{color:#333333} .codehilite .na{color:teal} .codehilite .nb{color:#0086b3} .codehilite .nc{color:#445588;font-weight:bold} .codehilite .no{color:teal} .codehilite .ni{color:purple} .codehilite .ne{color:#990000;font-weight:bold} .codehilite .nf{color:#990000;font-weight:bold} .codehilite .nn{color:#555555} .codehilite .nt{color:navy} .codehilite .nv{color:teal} .codehilite .ow{font-weight:bold} .codehilite .w{color:#bbbbbb} .codehilite .mf{color:#009999} .codehilite .mh{color:#009999} .codehilite .mi{color:#009999} .codehilite .mo{color:#009999} .codehilite .sb{color:#dd1144} .codehilite .sc{color:#dd1144} .codehilite .sd{color:#dd1144} .codehilite .s2{color:#dd1144} .codehilite .se{color:#dd1144} .codehilite .sh{color:#dd1144} .codehilite .si{color:#dd1144} .codehilite .sx{color:#dd1144} .codehilite .sr{color:#009926} .codehilite .s1{color:#dd1144} .codehilite .ss{color:#990073} .codehilite .bp{color:#999999} .codehilite .vc{color:teal} .codehilite .vg{color:teal} .codehilite .vi{color:teal} .codehilite .il{color:#009999} .codehilite .gc{color:#999;background-color:#EAF2F5} project-asmweb-aws149 下载anaconda3 wget https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh #-bash: wget: 未找到命令 sudo yum -y install wget sh Anaconda3-2019.03-Linux-x86_64.sh #Anaconda3-2019.03-Linux-x86_64.sh:行353: bunzip2: 未找到命令 sudo yum -y install bzip2 #关闭conda #conda config --set auto_activate_base false pip install django==1.11.1 #ModuleNotFoundError: No module named &#39;pymysql&#39; pip install pymysql #File &quot;/home/ec2-user/anaconda3/lib/python3.7/site-packages/django/contrib/admin/widgets.py&quot;, line 151 # &#39;%s=%s&#39; % (k, v) for k, v in params.items(), # ^ #SyntaxError: Generator expression must be parenthesized 修改/home/ec2-user/anaconda3/lib/python3.7/site-packages/django/contrib/admin/widgets.py文件去掉最后的逗号。 #django.db.utils.OperationalError: (2003, &quot;Can&#39;t connect to MySQL server on &#39;127.0.0.1&#39; ([Errno 111] Connection refused)&quot;) 安装mysql sudo yum install mysql 失败，下载： wget https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.15-1.el7.x86_64.rpm-bundle.tar wget http://mirror.centos.org/centos/6/os/x86_64/Packages/libaio-0.3.107-10.el6.x86_64.rpm sudo rpm -ivh libaio-0.3.107-10.el6.x86_64.rpm (base) [ec2-user@ip-172-31-31-134 ~]$ sudo rpm -ivh mysql-community-common-8.0.15-1.el7.x86_64.rpm mysql-community-libs-8.0.15-1.el7.x86_64.rpm mysql-community-client-8.0.15-1.el7.x86_64.rpm mysql-community-server-8.0.15-1.el7.x86_64.rpm 初始化： sudo mysqld --initialize 更改mysql数据库目录的所属用户及其所属组，然后启动mysql数据库 chown mysql:mysql /var/lib/mysql -R systemctl start mysqld.service]]></content>
  </entry>
  <entry>
    <title><![CDATA[project-machinelearning-basic]]></title>
    <url>%2F2019%2F05%2F03%2Fproject-machinelearning-basic%2F</url>
    <content type="text"><![CDATA[基础内容线性模型 - 就是知道的线性曲线 y = ax +b回归 - 表示是连续的 （例如，身高，体重）离散 - 非连续的 （例如，形状 - 方的，圆的）所以就有了线性回归模型评估模型好坏的函数：损失函数 L - 预测值y-hat 与实际值y之间的差值，损失函数越小，模型更可靠。 根据函数导数，可以使得损失函数最小。例如导数为S=2t当该位置导数值为正时，减小t轴的值，S更小。相反当该位置导数值为负时，增加t轴的值。我们初识t的值为$t_0$，那么$t_{next}=t_0-a*d_s/d_t$，其中a为学习步长（需要根据经验进行人工调整），也被称作超参。]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>machinelearing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[aws-passwd-login]]></title>
    <url>%2F2019%2F04%2F20%2Faws-passwd-login%2F</url>
    <content type="text"><![CDATA[我们首先要重置root密码，输入命令 sudo passwd root 接着会输入两次新的root密码。 接下来切换到root帐号 su 接着输入刚才设定的root密码 我们还要重置centos的密码 passwd ec2-user 还是重复重置root密码的那个过程。 能完这些输入这几条命令就可以实现直接密码登录了 1234567sed -ri 's/^#?(PasswordAuthentication)\s+(yes|no)/\1 yes/' /etc/ssh/sshd_configsed -ri 's/^#?(PermitRootLogin)\s+(yes|no)/\1 yes/' /etc/ssh/sshd_configsed -ri 's/^/#/;s/sleep 10"\s+/&amp;\n/' /root/.ssh/authorized_keysservice sshd restart]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>aws</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project-asmweb-aws]]></title>
    <url>%2F2019%2F04%2F20%2Fproject-asmweb-aws%2F</url>
    <content type="text"><![CDATA[149部署123456789101112131415安装Anaconda3安装Djangopip install django==1.11pip install mysql登陆数据库修改密码。mysql -uroot -pmysql&gt; SET password for 'root'@'localhost'=password('newpassword'); mysql&gt; create database django_mysql;##pip uninstall apschedulerpip install apscheduler==2.1.2pip install pysamsudo firewall-cmd --zone=public --add-port=8000/tcp --permanentsudo firewall-cmd --reloadsudo firewall-cmd --zone=public --list-ports 下载anaconda3123456789101112131415161718192021222324252627282930313233343536373839wget https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh#-bash: wget: 未找到命令sudo yum -y install wgetsh Anaconda3-2019.03-Linux-x86_64.sh#Anaconda3-2019.03-Linux-x86_64.sh:行353: bunzip2: 未找到命令sudo yum -y install bzip2#关闭conda#conda config --set auto_activate_base falsepip install django==1.11.1python -m django --version#ModuleNotFoundError: No module named 'pymysql'pip install pymysql#File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/django/contrib/admin/widgets.py", line 151# '%s=%s' % (k, v) for k, v in params.items(),# ^#SyntaxError: Generator expression must be parenthesized修改/home/ec2-user/anaconda3/lib/python3.7/site-packages/django/contrib/admin/widgets.py文件去掉最后的逗号。#django.db.utils.OperationalError: (2003, "Can't connect to MySQL server on '127.0.0.1' ([Errno 111] Connection refused)")安装mysqlsudo yum install mysql失败，下载：wget https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.15-1.el7.x86_64.rpm-bundle.tarwget http://mirror.centos.org/centos/6/os/x86_64/Packages/libaio-0.3.107-10.el6.x86_64.rpmsudo rpm -ivh libaio-0.3.107-10.el6.x86_64.rpm(base) [ec2-user@ip-172-31-31-134 ~]$ sudo rpm -ivh mysql-community-common-8.0.15-1.el7.x86_64.rpm mysql-community-libs-8.0.15-1.el7.x86_64.rpm mysql-community-client-8.0.15-1.el7.x86_64.rpm mysql-community-server-8.0.15-1.el7.x86_64.rpm初始化：sudo mysqld --initialize更改mysql数据库目录的所属用户及其所属组，然后启动mysql数据库chown mysql:mysql /var/lib/mysql -Rsystemctl start mysqld.service]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>aws</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project-bssnp]]></title>
    <url>%2F2019%2F04%2F11%2Fproject-bssnp%2F</url>
    <content type="text"><![CDATA[snp发现k562 WGS与WGBS中杂合子占的比例差别非常大，怀疑是BS数据中DNA甲基化对SNP检测的影响（C/T G/A）可以检查一下。]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>bssnp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project-dayday]]></title>
    <url>%2F2019%2F04%2F08%2Fproject-dayday%2F</url>
    <content type="text"><![CDATA[deeptoolscomputeMatrix scale-regions -S H3K27Me3-input.bigWig H3K4Me1-Input.bigWig -R genes19.bed genesX.bed –beforeRegionStartLength 3000 –regionBodyLength 5000 –afterRegionStartLength 3000 –skipZeros -o matrix.mat.gz multiBamSummary bins –bamfiles ../ATCS-001/ATCS_001.sort.rm.qual.bam ../ATCS-027/ATCS_027.sort.rm.qual.bam ATCS-044/ATCS-044.sort.rm.qual.bam ATCS-045/ATCS-045.sort.rm.qual.bam ATCS-046/ATCS-046.sort.rm.qual.bam ATCS-047/ATCS-047.sort.rm.qual.bam ATCS-048/ATCS-048.sort.rm.qual.bam ATCS-049/ATCS-049.sort.rm.qual.bam ATCS-050/ATCS-050.sort.rm.qual.bam ATCS-051/ATCS-051.sort.rm.qual.bam ATCS-052/ATCS-052.sort.rm.qual.bam –minMappingQuality 30 –labels 001 027 044 045 046 047 048 049 050 051 052 -out readCounts.npz –outRawCounts readCounts.tab multiBigwigSummary bins -b ../ATCS-001/ATCS_001.bw ../ATCS-027/ATCS_027.bw ATCS-044/ATCS-044.bw ATCS-045/ATCS-045.bw ATCS-046/ATCS-046.bw ATCS-047/ATCS-047.bw ATCS-048/ATCS-048.bw ATCS-049/ATCS-049.bw ATCS-050/ATCS-050.bw ATCS-051/ATCS-051.bw ATCS-052/ATCS-052.bw –labels 001 027 044 045 046 047 048 049 050 051 052 -out readCounts.npz –outRawCounts readCounts.tab plotCorrelation -in readCounts.npz –corMethod spearman –skipZeros –plotTitle “Spearman Correlation” –whatToPlot heatmap –colorMap RdYlBu –plotNumbers -o heatmap_SpearmanCorr_readCounts.png –outFileCorMatrix SpearmanCorr_readCounts.tabplotPCA -in readCounts.npz -o PCA_readCounts.png -T “PCA analysis” awk -v OFS=”\t” ‘{print $1,$4,$5,$7}’ ~/project/Genome/TAIR10/TAIR10.gene.gff &gt; ~/project/Genome/TAIR10/TAIR10.gene.bedcomputeMatrix scale-regions -S ../ATCS-001/ATCS_001.bw ../ATCS-027/ATCS_027.bw ATCS-044/ATCS-044.bw ATCS-045/ATCS-045.bw ATCS-046/ATCS-046.bw ATCS-047/ATCS-047.bw ATCS-048/ATCS-048.bw ATCS-049/ATCS-049.bw ATCS-050/ATCS-050.bw ATCS-051/ATCS-051.bw ATCS-052/ATCS-052.bw -R ~/project/Genome/TAIR10/TAIR10.gene.bed –beforeRegionStartLength 3000 –regionBodyLength 5000 –afterRegionStartLength 3000 –skipZeros -o matrix.mat.gz plotHeatmap -m matrix.mat.gz -out Heatmap.png –whatToShow ‘heatmap and colorbar’ –kmeans 3 –dpi 100 –boxAroundHeatmaps no #–zMin -4 -4 0 –zMax 0 0 5 plotProfile -m matrix.mat.gz -out Profile.png –numPlotsPerRow 2 –plotTitle “Profile” Jbrowse 配置chromHMM，bed4需要根据第四列名称设置颜色。oryza/tracks.conf123[tracks.ChromHMM]style.color = function(feature) &#123; var NNa = feature.get('name'); if(NNa == 'HMD') return 'Crimson'; if(NNa == 'PMD') return 'LightSalmon'; if(NNa == 'LMR') return 'DeepSkyBlue'; if(NNa == 'UMR') return 'LightCyan';return 'pink'; &#125;` BatMeth2 本地安装gsl后添加环境变量gsl12345export C_INCLUDE_PATH=$C_INCLUDE_PATH:/home/xxx/software/gsl-2.5/include/export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/xxx/software/gsl-2.5/lib/export GSL_LD=/home/xxx/software/gsl-2.5/libexport CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/home/xxx/software/gsl-2.5/include/export LIBRARY_PATH=$LIBRARY_PATH:/home/xxx/software/gsl-2.5/lib QQQ ?int pos = 0;写在char strand;这一行前，输出的pos值就不对。1234567891011121314151617181920char strand;char context[10];int meth=0;int cover=0;float ml=0;int pos=0;while(fgets(Dummy,BATBUF,INfile)!=0)&#123; if(Dummy[0]=='#') &#123; continue; &#125; //chrM 1 - CHH 2 1795 0.001114 sscanf(Dummy,"%s%d%s%s%d%d%f",chrom,&amp;pos,&amp;strand,context,&amp;meth,&amp;cover,&amp;ml); if(strcmp(Mcontext, "ALL") == 0 || strcmp(Mcontext, context) == 0)&#123; if(meth &gt;= mCover &amp;&amp; cover &gt;= TotalCover &amp;&amp; ml &gt;= weight &amp;&amp; ml &lt;= 1-weight)&#123; if(strand == '+')&#123; //$1,$2,".\tC\tT\t600\tPASS\t.\tGT\t0/1" printf("%d %d %d %f", pos, meth, cover, ml); exit(0); fprintf(OutfileP, "%s\t%d\t.\tC\tT\t600\tPASS\t.\tGT\t0/1\n", chrom, pos); &#125;else if(strand == '-')&#123; cpp is unsignedbool isunsigned (char* str){ for(int i = 0; i &lt; strlen(str); i++) { if(!isdigit(str[i])) { return false; } } return true;} conda12345678910111213You have chosen to not have conda modify your shell scripts at all.To activate conda's base environment in your current shell session:eval "$(/root/anaconda3/bin/conda shell.YOUR_SHELL_NAME hook)"To install conda's shell functions for easier access, first activate, then:conda initIf you'd prefer that conda's base environment not be activated on startup, set the auto_activate_base parameter to false:conda config --set auto_activate_base false 上传数据到ncbi12[14:41:11] qwzhou@mn02:~/tair_zwang/PM/rawdata :$ ascp -i /public/ home/qwzhou/tair_zwang/PM/ncbisrakey/ -QT -l100m -k1 -d /public/home/qwzhou/tair_zwang/PM/rawdata/ subasp@upload.ncbi.nlm.nih.gov:uploads/1010170266_qq.com_nnF1H7nv 训练：每个位点的柱状图特征值 –&gt; 离散值（差异，非差异）逻辑线性回归 一个位点输入，计算柱状图特征值到模型，得到C对应的预测值即差异的可能性。 Jbrowser puppeteer安装失败由于连接谷歌等443，可以换镜像一试，在主目录下.npmrc文件加入~/.npmrc或者root的/root/.npmrc.npmrc 加一条 PUPPETEER_DOWNLOAD_HOST=https://npm.taobao.org/mirrors Jbrowser 开发版，下载的目录里没有dist和example_data文件夹，可以下载一个稳定版拷贝一下github上传文件是灰色的git上如何删除一个文件夹？如果直接git rm本地的文件夹也被删除，应该删缓冲。git rm -r –cached some-directorygit commit -m “Remove the now ignored directory some-directory”git push -u origin master！ 设置无密码远程登录首先mac本地生成密钥，-C描述，-f生成文件名。12╭─[MacBook-Pro] as qiangweizhou in ~/.ssh 05-11 14:30:07╰──➤ ssh-keygen -t rsa -C myserverhzau -f myserverhzau 拷贝myserverhzau.pub的内容到远程服务器.ssh/authorized_keys文件内，修改文件权限chmod 600 authorized_keys然后本地的.pub文件不用的话可以删除了。然后编辑本地.ssh/config添加内容如下：123456Host ms150 Hostname 211.69.141.150 Port 22 User qwzhou IdentityFile ~/.ssh/myserverhzau ServerAliveInterval 60 Jbrowse 跳转端口 静态文件总是加载失败，最后还是以8080配置到apache2/var/www/html/browser 配置后后来偶然发现，报错信息为net::ERR_CONTENT_LENGTH_MISMATCH 206 (Partial Content)，即js信息加载不全，那么实际上不需要跳转到apache的在Nginx.conf添加如下配置1234## 添加到http&#123;&#125;内proxy_buffer_size 128k;proxy_buffers 32 128k;proxy_busy_buffers_size 128k; https://blog.csdn.net/tcf_jingfeng/article/details/80325644 nginx.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125# For more information on configuration, see:# * Official English Documentation: http://nginx.org/en/docs/# * Official Russian Documentation: http://nginx.org/ru/docs/user qwzhou;worker_processes auto;error_log /var/log/nginx/error.log;pid /run/nginx.pid;# Load dynamic modules. See /usr/share/nginx/README.dynamic.include /usr/share/nginx/modules/*.conf;events &#123; worker_connections 1024;&#125;http &#123; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; proxy_buffer_size 128k; proxy_buffers 32 128k; proxy_busy_buffers_size 128k; include /etc/nginx/mime.types; default_type application/octet-stream; # Load modular configuration files from the /etc/nginx/conf.d directory. # See http://nginx.org/en/docs/ngx_core_module.html#include # for more information. #include /etc/nginx/conf.d/*.conf; server &#123; listen 80; #listen [::]:80 default_server; server_name localhost; charset utf-8; #root /usr/share/nginx/html; # Load configuration files for the default server block. #include /etc/nginx/default.d/*.conf; location / &#123; uwsgi_pass 218.199.68.149:8000; include /etc/nginx/uwsgi_params; &#125; location /static &#123; expires 30d; autoindex on; #add_header Cache-Control private; alias /home/qwzhou/www/alleleweb/collected_static; &#125; location /browser/ &#123; proxy_pass http://218.199.68.149:8080/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; server &#123; listen 8080; server_name localhost; root /home/qwzhou/www/browser; index index.html; location / &#123; root /home/qwzhou/www/browser; #proxy_pass http://218.199.68.149:8080/browser; # 域名对应映射url #try_files '' /index.html; #index index.html; &#125; &#125;# Settings for a TLS enabled server.## server &#123;# listen 443 ssl http2 default_server;# listen [::]:443 ssl http2 default_server;# server_name _;# root /usr/share/nginx/html;## ssl_certificate "/etc/pki/nginx/server.crt";# ssl_certificate_key "/etc/pki/nginx/private/server.key";# ssl_session_cache shared:SSL:1m;# ssl_session_timeout 10m;# ssl_ciphers HIGH:!aNULL:!MD5;# ssl_prefer_server_ciphers on;## # Load configuration files for the default server block.# include /etc/nginx/default.d/*.conf;## location / &#123;# &#125;## error_page 404 /404.html;# location = /40x.html &#123;# &#125;## error_page 500 502 503 504 /50x.html;# location = /50x.html &#123;# &#125;# &#125;&#125; 打开防火墙端口123456789101112131415161718192021222324252627sudo vim /etc/sysconfig/iptables添加如下-A INPUT -p tcp -m state --state NEW -m tcp --dport 8080 -j ACCEPT重启防火墙/etc/init.d/iptables restart/etc/init.d/iptables: No such file or directory在RHEL7开始，使用systemctl工具来管理服务程序，包括了service和chkconfig如下：sudo systemctl stop firewalld.servicesudo systemctl start firewalld.service但是上述配置未生效，以下办法：查看打开的端口：sudo firewall-cmd --zone=public --list-ports添加端口sudo firewall-cmd --zone=public --add-port=8080/tcp --permanent ##（--permanent永久生效，没有此参数重启后失效）重新载入firewall-cmd --reload查看firewall-cmd --zone= public --query-port=8080/tcp删除firewall-cmd --zone= public --remove-port=8080/tcp --permanent配置apache：sudo vim /etc/httpd/conf/httpd.conf重启apache：sudo service httpd restart shell 文件名前缀GSM2927945.meth.png 希望活得 meth.png：echo ${file#GSM2927945.}echo ${file#*.} shell 重做batmeth2可视化部分12345678910111213141516171819202122232425262728293031cd $1dir=`ls`for gse in $dirdoecho $gseif [ -d $gse ]thencd $gsecd "BS-Seq"gsmdir=`ls`for gsm in $gsmdirdoecho $gsmif [ -d $gsm ]thencd $gsm/public/home/qwzhou/software/BatMeth2/bin/methyPlot ./$&#123;gsm&#125;.methBins.txt ./$&#123;gsm&#125;.Methygenome.pdf 0.025 ./$&#123;gsm&#125;.Methylevel.1.txt ./$&#123;gsm&#125;.function.pdf TSS TTS ./$&#123;gsm&#125;.AverMethylevel.1.txt ./$&#123;gsm&#125;.Methenrich.pdf #&gt;&gt; ./$&#123;gsm&#125;.run.log 2&gt;&amp;1files=`ls *png`for file in $filesdo#name=`basename $file`#echo $namemv $&#123;file&#125; batmeth2_report_*/images/$&#123;file#*.&#125;donecd ../fidone shell 处理文件名【http://www.lichaozheng.info/2012/03/20/shell-获取文件名和后缀名/】代码：file=”thisfile.txt”echo “filename: ${file%.}”echo “extension: ${file##.}”输出：filename: thisfileextension: txt附：Bash字符串处理基于Pattern Matching的子串替换${STR/$OLD/$NEW}替换第一个。${STR//$OLD/$NEW}替换所有。注意：不能使用正则表达式，只能使用?的Shell扩展。只能用shell通配符如 ? [list] [!list] [a-z]。${STR/#$OLD/$NEW}替换开头。如果STR以OLD串开头，则替换。${STR/%$OLD/$NEW}替换结尾。如果STR以OLD串结尾，则替换。 [user@laptop ~]# STR=”Hello World”[user@laptop ~]# echo ${STR/o/O}HellO World[user@laptop ~]# echo ${STR//o/O}HellO WOrld[user@laptop ~]# STR=”Hello World”[user@laptop ~]# echo ${STR/#He/he}hello World[user@laptop ~]# echo ${STR/#o/he}Hello World[user@laptop ~]# echo ${STR/%He/he}Hello World[user@laptop ~]# echo ${STR/%ld/lD}Hello WorlD 如果被替换串包含/字符，那么要转义，写成\/。 [user@laptop ~]# filename=”/user/admin/monitoring/process.sh”[user@laptop ~]# echo ${filename/#\/user/\/tmp}/tmp/admin/monitoring/process.sh[user@laptop ~]# echo ${filename/%.*/.ksh}/user/admin/monitoring/process.ksh[user@laptop ~]# 将环境变量PATH的各个目录分开，每行显示一个。echo -e ${PATH/:/\n} [user@laptop ctmw]# echo $PATH/usr/kerberos/sbin:/usr/kerberos/bin:/usr/apache/apache-ant-1.7.1/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/user/bin[user@laptop ctmw]# echo -e ${PATH//:/’\n’}/usr/kerberos/sbin/usr/kerberos/bin/usr/apache/apache-ant-1.7.1/bin/usr/local/sbin/usr/local/bin/sbin/bin/usr/sbin/usr/bin/user/bin[user@laptop ctmw]# echo “${PATH//:/$’\n’}”/usr/kerberos/sbin/usr/kerberos/bin/usr/apache/apache-ant-1.7.1/bin/usr/local/sbin/usr/local/bin/sbin/bin/usr/sbin/usr/bin/user/bin 基于Pattern Matching的子串删除子串删除是一种特殊的替换${STR/$SUB}将STR中第一个SUB子串删除${STR//$SUB}将STR中所有SUB子串删除${STR#$PREFIX}去头，从开头去除最短匹配前缀${STR##$PREFIX}去头，从开头去除最长匹配前缀${STR%$SUFFIX}去尾，从结尾去除最短匹配后缀${STR%%$SUFFIX}去尾，从结尾去除最长匹配后缀注意：经常会记错#和%的含义，有一个帮助记忆的方法看一下键盘，#在$之前，%在$之后，就知道#去头，%去尾。注意：不能使用正则表达式，只能使用?*的Shell扩展。 [user@laptop ~]# STR=”Hello World”[user@laptop ~]# echo ${STR#He}llo World[user@laptop ~]# echo ${STR#Heo}World[user@laptop ~]# echo ${STR##Heo}rld[user@laptop ~]# PREFIX=”o”[user@laptop ~]# echo ${STR#$PREFIX}World[user@laptop ~]# echo ${STR##$PREFIX}rld[user@laptop ~]# echo ${STR%o}Hello W[user@laptop ~]# echo ${STR%%o}Hell[user@laptop ~]# SUFFIX=”o”[user@laptop ~]# echo ${STR%$SUFFIX}Hello W[user@laptop ~]# echo ${STR%%$SUFFIX}Hell 典型应用：得到文件的扩展名[user@laptop ~]# FILE=hello.jpg[user@laptop ~]# echo ${FILE##*.}jpg 使用sed命令实现正则表达式替换使用sed命令可以进行正则表达式的替换。echo “$STR” | sed “s/$OLD/$NEW/”将STR中的OLD子串替换成NEW。 [user@laptop ~]# STR=”123456789″[user@laptop ~]# echo “$STR” | sed s/345/OK/12OK6789[user@laptop ~]# OLD=345[user@laptop ~]# NEW=OK[user@laptop ~]# echo “$STR” | sed “s/$OLD/$NEW/”12OK6789 使用tr命令实现字符集合的替换使用tr命令可以实现字符的替换，并且可以是从一批字符到另一批字符的替换。比如小写字母变成大写字母，或者反过来。 [user@laptop ~]# echo “bash” | tr “[a-z]” “[b-z]”cbti上面的命令是将原串中的a替换成b，被替换成c，以此类推。 网上问题：Linux中 有没有一个命令可以将 字符串中出现的 +或者- 替换成对应的-或者+ 即 “+” ——&gt; “-” “-”——&gt;”+” 例如 GMT+8-9变成 GMT-8+9 [user@laptop ~]# echo “GMT+8-9″ | sed ‘s/-/#/g’ | sed ‘s/+/-/g’ | sed ‘s/#/+/g’GMT-8+9上面是网上提供的答案。如果用tr来实现，更简洁些。[user@laptop ~]# echo “GMT+8-9″ | tr “+-” “-+”GMT-8+9 路径字符串的处理dirname ${FULLPATH}取目录部分。basename ${FULLPATH}取文件名部分。basename ${FULLPATH} ${EXT}取文件名部分，并且去掉指定的扩展名。[user@laptop ~]# FULLPATH=/user/work/project/backup.tar.gz[user@laptop ~]# dirname “$FULLPATH”/user/work/project[user@laptop ~]# basename “$FULLPATH”backup.tar.gz[user@laptop ~]# basename “$FULLPATH” .gzbackup.tar[user@laptop ~]# basename “$FULLPATH” .tarbackup.tar.gz[user@laptop ~]# basename “$FULLPATH” .tar.gzbackup取目录部分：${FULLPATH%/}（类似 dirname “$FULLPATH”）取文件名称：FILE=${FULLPATH##/}（类似 basename “$FULLPATH”）取最短基本名称：${FILE%%.}取最长基本名称：${FILE%.}取最短扩展名：${FILE##.} 或者 ${FULLPATH##.}取最长扩展名：${FILE#.} 或者 ${FULLPATH#.} [user@laptop ~]# FULLPATH=/user/work/project/backup.tar.gz[user@laptop ~]# echo ${FULLPATH%/}/user/work/project[user@laptop ~]# dirname “$FULLPATH”/user/work/project[user@laptop ~]# FILE=${FULLPATH##/}[user@laptop ~]# echo $FILEbackup.tar.gz[user@laptop ~]# basename “$FULLPATH”backup.tar.gz[user@laptop ~]# echo ${FILE%%.}backup[user@laptop ~]# echo ${FILE%.}backup.tar[user@laptop ~]# echo ${FILE##.}gz[user@laptop ~]# echo ${FILE#.}tar.gz[user@laptop ~]# 牛基因组 Bos taurusUMD3.1 Bos_taurushttp://bovinegenome.elsiklab.missouri.edu/node/61 python3 map(float, lista)返回的是迭代器，而不是转换为float的列表，需要加一步转换：list(map(float, lista)) awk清空数组 split(“”,array) delete array 不同基因组位置转换liftover方法一：Picard，可以参考mm9tomm10vcf文章。方法二：UCSC liftoverwget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/liftOver但是这个liftover二进制文件是编译后的，与目前系统不符合。1234[14:01:45] qwzhou@node102:~ :$ ./liftOver./liftOver: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by ./liftOver)./liftOver: /lib64/libc.so.6: version `GLIBC_2.17' not found (required by ./liftOver) https://genome.sph.umich.edu/wiki/LiftOver#Binary_liftOver_tool方法三：CrossMapwget https://sourceforge.net/projects/crossmap/files/CrossMap-0.3.4.tar.gz因为0.2.9以上版本需要python3，重新下载低版本wget https://sourceforge.net/projects/crossmap/files/CrossMap-0.2.9.tar.gz安装：12python setup.py install --root=/public/home/qwzhou/software/CrossMap-0.2.9... 安装失败 还是用方法一吧。。。首先，转文件为vcf格式：12[13:46:41] qwzhou@comput54:~/practice/k562/WGBS :$ awk -v OFS="\t" 'ARGIND==1 &amp;&amp; $1~/^#/&#123;print $0&#125;ARGIND==2 &amp;&amp; FNR&gt;1&#123;print "chr"$1,$2,".",$3,$4,"600\tPASS\t.\tGT\t0/1"&#125;' wgbs.replace.mdups.snp.filtered.sort.vcf tum.letters.haplotyped_across_tumor.passing.cleaned.called.txt &gt; tum.letters.haplotyped_across_tumor.passing.cleaned.called.vcf 下载hg19 to hg38 chain文件：123[13:48:58] qwzhou@login:~/practice/Genome/hg38 :$ wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gzgunzip hg19ToHg38.over.chain.gz 运行liftover：12[13:47:36] qwzhou@comput54:~/practice/k562/WGBS :$ java -jar ~/software/picard.jar LiftoverVcf I=tum.letters.haplotyped_across_tumor.passing.cleaned.called.vcf O=tum.letters.haplotyped_across_tumor.passing.cleaned.called.hg38.vcf CHAIN=~/practice/Genome/hg38/hg19ToHg38.over.chain REJECT=rejected_variants.vcf R=~/practice/Genome/hg38/hg38.chr.fa 运行错误，这里无法确认allle1与allele2哪个是ref哪个是var，不能改转vcf。还是想办法用bed格式。测试方法二中liftover，在142发现可以正常运行：运行：12[14:11:49] qwzhou@mn02:~/hapvswgs :$ ../liftOver tum.letters.haplotyped_across_tumor.passing.cleaned.called.bed hg19ToHg38.over.chain.gz k562.bed k562.unlifted.bed 发现输出文件为空，查阅后发现，我们转换的bed格式不准确，需要间隔1bp12[13:58:40] qwzhou@comput54:~/practice/k562/WGBS :$ awk -v OFS="\t" 'FNR&gt;1&#123;print "chr"$1,$2,$2+1,$3,$4&#125;' tum.letters.haplotyped_across_tumor.passing.cleaned.called.txt &gt; tum.letters.haplotyped_across_tumor.passing.cleaned.called.bed 重新运行liftover 可用工具汇总：https://www.biostars.org/p/65558/ vector/deque/list 效率比较==================================================DNA甲基化单倍型组装 methyhaplo数据运行过程速度太慢，运行大约近一周时间，进度只完成一半左右。检查原因：1，读取bam文件，需要处理每条序列，删选可能的潜在C位点，之后根据该位点覆盖度计算valid C位点，实际有很多序列无需进行这一步处理，因为C位点不满足我们的要求（validC - coverage &gt;=4 and hetero-methylation）。解决办法：读入甲基化位点文件，methratio，根据位点甲基化覆盖度以及水平来对read进行处理，为满足该条件的位点的覆盖read不做任何处理。 2，read的甲基化state：SSSSShx==x==z===========hh=====h=x====hh====hx=========D==============Ih========h=============x=====h=hhh=x=T=Z=hx我们在获取序列第i位点信息时，计算方法为：1234567891011121314for(;ReadStep&lt;strlen(read.methState);ReadStep++) &#123; if(RealLen==index) break; if(read.methState[ReadStep] == 'S' || read.methState[ReadStep] == 'I') &#123; continue; &#125;else if(read.methState[ReadStep] == 'D') &#123; RealLen++; continue; &#125;else&#123; RealLen++; &#125; &#125; 需要对read做循环处理，但是由于每条read上可能存在n个validC，因此该序列可能需要被计算n次。解决办法：在第一次处理时，将S，I替换为’’。然后或许该序列i位置信息方法，read.methstate[i]。 但是在将这些部分预期可能的耗时地方注释掉之后，程序时间有了一定的提高，但是非常不理想。进一步检查可能的原因，在检查代码过程中，想到代码中对vector进行了大量的操作。对vector的内存机制查看之前的资料发现，因为我们存储的read处理之后需要从vector头部删掉erase（vector.begin()），vector在erase操作后实际减少了本身的size但是vector本身操作需要申请一段连续的内存地址，在capacity不够是会以0.5~1倍的空间增大，而erase删除存储单元后，vector本身的capacity并不会减少，因此会出现随着数据运行vector的size是波动的（1-10000左右），但是capacity是随着处理read的增加一直在增加的。解决办法：1，在初始化vector时，定义该vector的内存容量capacity（reserve(50000)），并且在处理过程中需要定期释放以及删除的内存区域，我们知道在C++中vector的删除v1.clear()只会删掉所有size，但并未释放capacity内存区域，需要我们释放即将v1与空vector进行交换：vector().swap(v1)，而根据vector size大小删除未占用的内存是类似的操作：（vector(v1).swap(v1)）。效果：在完成该操作后，我们对程序的占用内存进行查看（ps aux），发现内存的增加以及vector的capacity是稳定的（初始化大小50000），不会随read的处理而无限的增大，但是对时间的改善很小。进一步寻找原因：我们知道vector需要申请一段连续的内存地址，在进行尾端的插入以及删除erase时不会对整个vector的内存地址发生改变，但是如果我们需要在vector的首端进行删除erase（这是我们程序中一直在操作的内容），vector在去掉首端的第一个元素后，剩下的元素会全部迁移一个单位，这是非常耗时的操作，因为一开始网上未找到有实际时间验证的信息，所以对vector、list、deque的添加 插入删除 所需要的时间进行测试：123456789101112131415161718192021222324252627282930313233343536373839404142####testvector.cpp#include &lt;vector&gt;#include &lt;iostream&gt;#include &lt;time.h&gt;using namespace std;struct Point&#123; int x; int y; Point():x(0),y(0) &#123;&#125;&#125;;int main()&#123; clock_t s1,f1,s2,f2,s3,f3; int N=1000000; s1=clock(); vector&lt;Point&gt; point_vec(N); f1=clock(); cout&lt;&lt;(double)(f1-s1)/CLOCKS_PER_SEC&lt;&lt;" S"&lt;&lt;endl; s3=clock(); int i=0; for(i=0;i&lt;=N;i++) &#123; Point P; point_vec.push_back(P); &#125; f3=clock(); cout&lt;&lt;(double)(f3-s3)/CLOCKS_PER_SEC&lt;&lt;" S"&lt;&lt;endl; s2=clock(); while(point_vec.size()&gt;0)&#123; point_vec.erase(point_vec.begin()); &#125; f2=clock(); cout&lt;&lt;(double)(f2-s2)/CLOCKS_PER_SEC&lt;&lt;" S"&lt;&lt;endl; return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344###testlist.cpp#include &lt;iostream&gt;#include &lt;list&gt;#include &lt;time.h&gt;using namespace std;struct Point&#123; int x; int y; Point():x(0),y(0) &#123;&#125;&#125;;int main()&#123; clock_t s1,f1,s2,f2,s3,f3; list&lt;Point&gt; point_vec; s1=clock(); int i;int N=10000000; for(i=0;i&lt;=N;i++) &#123; Point P; point_vec.push_front(P); &#125; f1=clock(); cout&lt;&lt;(double)(f1-s1)/CLOCKS_PER_SEC&lt;&lt;" S"&lt;&lt;endl; s3=clock(); for(i=0;i&lt;=N;i++) &#123; Point P; point_vec.push_back(P); &#125; f3=clock(); cout&lt;&lt;(double)(f3-s3)/CLOCKS_PER_SEC&lt;&lt;" S"&lt;&lt;endl; s2=clock(); while(point_vec.size()&gt;0)&#123; point_vec.pop_front(); &#125; f2=clock(); cout&lt;&lt;(double)(f2-s2)/CLOCKS_PER_SEC&lt;&lt;" S"&lt;&lt;endl; return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344####testdeque.cpp#include &lt;iostream&gt;#include&lt;deque&gt;#include &lt;time.h&gt;using namespace std;struct Point&#123; int x; int y; Point():x(0),y(0) &#123;&#125;&#125;;int main()&#123; clock_t s1,f1,s2,f2,s3,f3; deque&lt;Point&gt; point_vec; s1=clock(); int i;int N=10000000; for(i=0;i&lt;=N;i++) &#123; Point P; point_vec.push_front(P); &#125; f1=clock(); cout&lt;&lt;(double)(f1-s1)/CLOCKS_PER_SEC&lt;&lt;" S"&lt;&lt;endl; s3=clock(); for(i=0;i&lt;=N;i++) &#123; Point P; point_vec.push_back(P); &#125; f3=clock(); cout&lt;&lt;(double)(f3-s3)/CLOCKS_PER_SEC&lt;&lt;" S"&lt;&lt;endl; s2=clock(); while(point_vec.size()&gt;0)&#123; point_vec.pop_front(); &#125; f2=clock(); cout&lt;&lt;(double)(f2-s2)/CLOCKS_PER_SEC&lt;&lt;" S"&lt;&lt;endl; return 0;&#125; 主要测试内容为插入N个元素 尾端插入、首端插入、首端删除：1，N=100000结果：vector：0.001484 S0.004673 S3.4818 Slist：0.017136 S0.016473 S0.022026 Sdeque:0.004028 S0.004597 S0.002443 S2,N=1000000结果：vector:0.013873 S0.048349 S1112.85 Slist:0.154731 S0.157853 S0.217059 Sdeque:0.038313 S0.047 S0.025429 S结论：从我们结果可以看出我们在vector、list、deque测试中，首端以及尾端的插入vector以及deque要快于list，但是在进行首端的删除时deque &gt; list &gt;&gt;vector，deque大约时vector的1000倍以上，而且随着元素数增大时间差别更大。红色显示为最慢时间，绿色为最快。而对三者的尾端删除以及中间插入删除因为程序中不需要这部分操作因此并未进行测序。在查阅资料中看到有测试显示list&gt;deque （https://baptiste-wicht.com/posts/2012/12/cpp-benchmark-vector-list-deque.html#），进一步发现同样有做过详细的测试工作针对deque、list、vector等，结论也是首端删除deque&gt; list &gt;&gt; vector （http://www.cppblog.com/sailing/articles/161659.html）。因此修改程序内vector为deque，由于vector Pvalues，并未进行erase操作，而且我们需要对Pvalue完成排序以及逆向计算Qvalues，而我们查到的资料显示后向遍历deque最快但是与vector以及list相差不大，不做更改，查找资料显示逆向遍历时间。（当然这部分可以更改，未更改原因我们需要进行排序：1，sort同样适合deque 2，但是deque复杂度大，因此对deque的操作不如直接使用vector，并且认为时间相差不大。）接下来还是要将vector Pvalue改为deque测试比较一下（强迫症难受）vector list deque0.885 0.879 0.690。 将文档中所有vector（除Pvalue外）改为deque后，结果： 处理10000条序列：samtools view -h -f 96,144 A549.methstate.sort.bam | head -10000 &gt; test.sam取正链10000条序列。（但是在测试中发现程序中负链函数同样启动了，检查原因发现我们忽略了一些情况，例如：0x200 QCFAIL .. not passing quality controls以及正负链同样出现在同一read中，这种情况不明白原因，后续需要解决。先完成时间测试）old version（vector）start time： 16:37:24end time：16:38:35total time: 71snew version (deque)start time: 16:39:05end time: 16:39:08total time: 3s 2,处理30000条序列：samtools view -h -f 96,144 A549.methstate.sort.bam | head -30000 &gt; test.samold versionstart：16:42:33end：16:54:57time：744snew version：start ：16:41:12end： 16:41:22total：10s结论：因为3万条序列后，随着序列增加old version需要时间太久，不做进一步测试，但是我们同样可以看到新的版本修改deque后时间效率具有非常明显的提高。 R, 取某列1ma&lt;-a[c(3,4,5)] R, 添加列名1names(profile_text)=c("chr","coord","SNV", "MethSNV.SNV", "MethSNV") R, 每一列一个样本，画点图、boxplot、线图12345678910111213141516171819202122232425262728profile_text &lt;- read.table(&quot;C:/Users/qwzhou/Desktop/code/phaseddensity.chr1.txt&quot;, header=T, row.names=1, quote=&quot;&quot;)#names(profile_text)=c(&quot;chr&quot;,&quot;coord&quot;,&quot;SNV&quot;, &quot;MethSNV.SNV&quot;, &quot;MethSNV&quot;)#head(profile_text)#Meth.SNP SNP Meth.SNP.SNP. #10000 10 3 3#10001 34 28 30library(ggplot2)library(reshape2)profile_text$xvariable = rownames(profile_text)data_m &lt;- melt(profile_text, id.vars=c(&quot;xvariable&quot;))data_m$xvariable &lt;- as.numeric(data_m$xvariable)## 点图p &lt;- ggplot(data_m, aes(x=xvariable, y=value,color=variable,group=variable)) +geom_point() +ylim(0,100)#+ stat_smooth(method=&quot;auto&quot;, se=FALSE) + theme(legend.position=c(0.85,0.2))p## boxplotdata_m$value &lt;- pmin(data_m$value,100)p &lt;- ggplot(data_m, aes(x=variable, y=value,color=variable,group=variable)) +geom_boxplot()p## 线图data_m2&lt;-data_m[data_m$variable!=&quot;MethSNV&quot;,]p &lt;- ggplot(data_m2, aes(x=xvariable, y=value,color=variable,group=variable)) + stat_smooth(method=&quot;auto&quot;, se=FALSE)p +labs(title=&quot;&quot;,x=&quot;&quot;, y = &quot;Phased number&quot;)+ theme_bw() + ## 背景 theme(panel.grid =element_blank()) + ## 删去网格线 theme(plot.title = element_text(hjust = 0.5, size = 18, colour = &quot;black&quot;, face = &quot;bold&quot;) ,axis.title.y = element_text(size=16,colour = &quot;black&quot;,face = &quot;bold&quot;), axis.text.y = element_text(size=10, colour = &quot;black&quot;), axis.text.x = element_text(size=16, colour = &quot;black&quot;), legend.position = c(0.85,0.5)) python3：cmd运行python脚本，提示 No module named ‘xxx’原因：在pycharm编辑器运行时，会将当前工程的所有文件夹路径都作为包的搜索路径；而在命令行中运行时，只是搜索当前路径 解决方案：在py文件最前面加上以下代码12345import sysimport oscurPath = os.path.abspath(os.path.dirname(__file__))rootPath = os.path.split(curPath)[0]sys.path.append(rootPath) django项目 http到httpshttps://www.jianshu.com/p/655dd8bc3347 查看端口sudo netstat -nltp kill 端口程序sudo kill -9 27415 kill uwsgi程序所有项目killall -9 uwsgi sort vcfchr_order目前是必须指定的，其实可以根据bam/genome生成某一文件包含所有染色体名1234567891011121314input=$1out=$2chr_order="chrM\nchr1\nchr2\nchr3\nchr4\nchr5\nchr6\nchr7\nchr8\nchr9\nchr10\nchr11\nchr12\nchr13\nchr14\nchr15\nchr16\nchr17\nchr18\nchr19\nchr20\nchr21\nchr22\nchrY\nchrX"#echo -e $chr_order | while read line#do# echo $line#donecat $input | grep "^#" &gt; .header.vcfcat $input | grep -v "^#" | sort -k1,1 -k2,2n &gt; .pre.sorted.vcfecho -e $chr_order | while read linedo cat .pre.sorted.vcf | grep "^$line"$'\t' &gt;&gt; .header.vcfdonemv .header.vcf $&#123;out&#125; &amp;&amp; rm .pre.sorted.vcf DNA甲基化单倍型hapcut212345678910111213awk -v OFS="\t" '$3=="+" &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,".\tC\tT\t600\tPASS\t.\tGT\t0/1"&#125;' k562.mr.methratio.txt &gt; k562.mr.methratio.p.txtcat wgbs.replace.mdups.snp.filtered.sort.vcf k562.mr.methratio.p.txt &gt; k562.snpwithmr.p.vcfsh run.sortvcf.sh k562.snpwithmr.p.vcf k562.snpwithmr.p.sort.vcfsh run.Sstrand.sh wgbs.sort.bam~/software/HapCUT2/build/extractHAIRS --bam wgbs.sort.p.bam --VCF k562.snpwithmr.p.sort.vcf --out k562.snpwithmr.hapcut2.fragment~/software/HapCUT2/build/HAPCUT2 --fragments k562.snpwithmr.hapcut2.fragment --vcf k562.snpwithmr.p.sort.vcf --output k562.snpwithmr.hapcut2.haplo.txtawk -v OFS="\t" '$3=="-" &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,".\tG\tA\t600\tPASS\t.\tGT\t0/1"&#125;' k562.mr.methratio.txt &gt; k562.mr.methratio.n.txtcat wgbs.replace.mdups.snp.filtered.sort.vcf k562.mr.methratio.n.txt &gt; k562.snpwithmr.n.vcfsh run.sortvcf.sh k562.snpwithmr.n.vcf k562.snpwithmr.n.sort.vcf~/software/HapCUT2/build/extractHAIRS --bam wgbs.sort.n.bam --VCF k562.snpwithmr.n.sort.vcf --out k562.snpwithmr.n.hapcut2.fragment~/software/HapCUT2/build/HAPCUT2 --fragments k562.snpwithmr.n.hapcut2.fragment --vcf k562.snpwithmr.n.sort.vcf --output k562.snpwithmr.n.hapcut2.haplo.txt genome 按照固定长度分割基因组到bed格式文件：1awk -v OFS="\t" '&#123;bin=2000;len=int($2/bin);for(i=0;i&lt;len;i++)&#123;print $1,i*bin+1,(i+1)*bin&#125;;if(len*bin &lt; $2)&#123;print $1,len*bin+1, $2&#125;&#125;' ~/practice/Genome/arabidopsis/TAIR10_chr_all.fa.fai &gt; TAIR10.splitby2k.bed]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>project</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sublimetext3-usage]]></title>
    <url>%2F2019%2F04%2F07%2Fsublimetext3-usage%2F</url>
    <content type="text"><![CDATA[Install Package时出现There are no packages available for installation问题官网描述To help resolve the issue, follow these steps: Select the View &gt; Show Console menu entryLook for any lines starting with Package Control:Try enabling the debug log for more informationEnsure any proxy information is set in the Package Control settingsIf you have a proxy and it rewrites secure connections, add its CA cert as trusted:Click the Preferences &gt; Browse Packages… menuOpen the User folderCreate a file named Package Control.user-ca-bundle and paste in a PEM-formatted version of the certificateMake sure you have the latest version of Package Control installed: 3.3.0If you are still having trouble, review the open issues. If you do not find a relevant issue, please open a new one, and be sure to include your debug log. 解决办法在Preferences-&gt;Package Setting-&gt;Package Control -&gt;Setting User 中可以进行用户设置。将文件下载后，进行本地访问。首先访问https://packagecontrol.io/channel_v3.json，右键另存为channel_v3.json，然后在Setting User设置中，添加代码路径。{ “channels”: [ “/Users/qiangweizhou/channel_v3.json” ]}解决！ 常用的插件名称 功能ConvertToUTF8 解决文件编码转换的问题 Emmet：快速编写html、css、js的神级插件BracktHighLighter 括号高亮显示 ColorPicke：颜色选择器HTMLBeautify HTML格式化插件IMESupport 输入法支持插件Material Theme 一个主题ChineseLocalization 汉化插件SideBarEnhancements 增加左边栏的功能]]></content>
  </entry>
  <entry>
    <title><![CDATA[project_batmeth2]]></title>
    <url>%2F2019%2F04%2F03%2Fproject-batmeth2%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>batmeth2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project_alleleweb]]></title>
    <url>%2F2019%2F04%2F03%2Fproject-alleleweb%2F</url>
    <content type="text"><![CDATA[Allele 数据库功能serch物种 基因输出结果：热图1在所有样本基因内的甲基化水平热图 （进化树）在所有样本基因启动子的甲基化水平热图 设置jbrowse显示格式先修改csv文件1234567891011121314[02:21:40] qwzhou@mn02:~/project/Allele_Web :$ awk -v FS="," '$1!~/GSE/&#123;if(NR==1)&#123;print $0&#125;else&#123; printf $1"-mState";for(i=2;i&lt;=NF;i++)&#123;printf ","$i&#125;;print ""; printf $1"-mC";for(i=2;i&lt;=NF;i++)&#123;printf ","$i&#125;;print ""; printf $1"-mCG";for(i=2;i&lt;=NF;i++)&#123;printf ","$i&#125;;print ""; printf $1"-mCHG";for(i=2;i&lt;=NF;i++)&#123;printf ","$i&#125;;print ""; printf $1"-mCHH";for(i=2;i&lt;=NF;i++)&#123;printf ","$i&#125;;print ""; printf $1"-mCGns";for(i=2;i&lt;=NF;i++)&#123;printf ","$i&#125;;print ""; printf $1"-mCHGns";for(i=2;i&lt;=NF;i++)&#123;printf ","$i&#125;;print ""; printf $1"-mCHHns";for(i=2;i&lt;=NF;i++)&#123;printf ","$i&#125;;print ""&#125;&#125;' Oryza_sativa_clean.csv &gt; Oryza_sativa_clean_jbrowse.csv##142[root@h1-lgl browser]# perl bin/flatfile-to-json.pl --bed datasets/oryza/rice.cpgisland.bed --trackLabel 'CpGislands' 配置uwsgim nginx alleleweb项目下1.1 修改setting.py文件12345678910111213141516171819202122232425262728293031# SECURITY WARNING: don't run with debug turned on in production!DEBUG = False #True 关闭开发模式，关闭后不再在项目目录下寻找静态文件### DIRS下添加项目模版路径 os.path.join(BASE_DIR, 'MethAelle/templates'),TEMPLATES = [ &#123; 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [ os.path.join(BASE_DIR, 'MethAelle/templates'), ], 'APP_DIRS': True, 'OPTIONS': &#123; 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], &#125;, &#125;,]## 静态文件# Static files (CSS, JavaScript, Images)# https://docs.djangoproject.com/en/1.10/howto/static-files/STATIC_URL = '/static'STATIC_ROOT = os.path.join(BASE_DIR, 'collected_static') ## 将静态文件都整合到这里STATICFILES_DIRS = ( os.path.join(BASE_DIR, 'MethAelle/static'), ## 这里是现在的静态文件所在的目录) 首先建立文件夹： mkdir collected_static运行python manage.py collectstatic，在collected_static目录下将包含该项目的静态文件。 1.2 修改webapps目录下wsgim.pyj这部分主要是添加公gong路径PROJECT_DIR，并未测试不加这部分是否能生效12345678910111213141516171819import osfrom os.path import join,dirname,abspathPROJECT_DIR = dirname(dirname(abspath(__file__)))#3import sys # 4sys.path.insert(0,PROJECT_DIR) # 5from django.core.wsgi import get_wsgi_applicationos.environ.setdefault("DJANGO_SETTINGS_MODULE", "webapps.settings")application = get_wsgi_application()#os.environ["DJANGO_SETTINGS_MODULE"] = "blog.settings" # 7from django.core.wsgi import get_wsgi_applicationapplication = get_wsgi_application() 1.3 创建myweb_uwsgi.ini，内容如下123456789101112131415161718[uwsgi]socket = 218.199.68.149:8000chdir = /home/qwzhou/www/alleleweb##项目目录#wsgi-file = webapps/wsgi.pymodule = webapps.wsgi:application#MethAelle#callable = MethAellemaster = trueprocesses = 4threads = 2max-requests = 3000chmod-socket = 664vacuum = truestats = %(chdir)/uwsgi/uwsgi.statuspidfile = %(chdir)/uwsgi/uwsgi.piddaemonize = %(chdir)/uwsgi/uwsgi.log 首先创建uwsgi： mkdir uwsgi运行uwsgi：uwsgi --ini myweb_uwsgi.ini这一步运行后会在uwsgi目录下生成三个文件，日志文件、状态文件、运行id。如果对项目做了修改，需要重新加载才能生效：uwsgi --reload uwsgi/uwsgi.pid 配置nginx.conf，修改部分如下vi /etc/nginx/nginx.conf12345678910111213141516171819202122232425262728293031323334user qwzhou;## 用户名修改为所用账户，防止权限问题。### server server &#123; listen 80; #listen [::]:80 default_server; server_name localhost; charset utf-8; #root /usr/share/nginx/html; # Load configuration files for the default server block. #include /etc/nginx/default.d/*.conf; location / &#123; uwsgi_pass 218.199.68.149:8000; include /etc/nginx/uwsgi_params; &#125; location /static &#123; expires 30d; autoindex on; #add_header Cache-Control private; alias /home/qwzhou/www/alleleweb/collected_static; ## 静态文件collect后的路径 &#125; error_page 404 /404.html; location = /usr/share/nginx/html/40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /usr/share/nginx/html/50x.html &#123; &#125; &#125; 重启nginx：sudo systemctl restart nginx django项目 http到httpshttps://www.jianshu.com/p/655dd8bc3347 配置uwsgim nginx 错误静态文件配置之后一直不生效，半天后发现/static处多写了一个匹配符： js中替换src，刷新问题经常发生替换后并未刷新，是因为浏览器保存了缓存图片，在生成图片时修改一下文件名即可。12$("#alleleoutpic").attr("src", "/static/MethAelle/"+response);$("#alleleoutpict").attr("href", "/static/MethAelle/"+response); mysql 更改密码12345678910111213登陆数据库修改密码。# mysql -uroot -p更新 mysql 库中 user 表的字段：MariaDB [(none)]&gt; use mysql; MariaDB [mysql]&gt; UPDATE user SET password=password('newpassword') WHERE user='root'; MariaDB [mysql]&gt; flush privileges; MariaDB [mysql]&gt; exit;或者，使用 set 指令设置root密码：MariaDB [(none)]&gt; SET password for 'root'@'localhost'=password('newpassword'); MariaDB [(none)]&gt; exit; 包含的物种和处理进程Data list 上图： 1 对应该gsm数据在genome browser可视化情况（DNA甲基化水平bw、或者基因表达水平bw） 2 DNA甲基化数据对应BatMeth2分析结果可视化情况。RNAseq还没想好，好像也不需要这个。（可以试着完成如下，如果是BS-Seq数据显示，如果是RNA-Seq数据那么不显示这个小图标） 3 DNA甲基化数据对应等位差异DNA甲基化（链接到具体位置表、在每条染色体上的分布饼状图/柱状图、在基因组上的密度分布等） RNAseq数据对应等位差异表达基因（连接到具体基因表） 4 sra list 测试转bigwig格式123awk -v OFS="\t" '$4=="CG"&#123;print $1,$2,$2,$3$7&#125;' GSM1634321.methratio.txt &gt; tt.bedgragh[16:06:06] qwzhou@mn02:~/project/Allele_Web/Cordyceps_militaris/GSE66919/BS-Seq/GSM1634321 :$ ../../../../bedGraphToBigWig tt.bedgragh ~/project/Genome/CM01/GCF_000225605.1_CmilitarisCM01_v01_genomic.fa.len myBigWig.bw 成功 RNAseq 分析流程数据预处理（fastp） 比对 （hisat2） 123456789## build indexhisat2-build genomefile indexprefix##paired-endhisat2 -p 8 -x /index/location/indexprefix -1 R1.fq.gz -2 R2.fq.gz -S outprefix.sam##singlehisat2 -p 8 -x /index/location/indexprefix -U R1.fq.gz -S outprefix.sam##多个文件，可以用逗号间隔 等位差异分析 （ASEQ） 12345## gene.bed 格式：chr start end geneid## vcf.list 文件内包含snp文件路径，改文件通过与之对应的BS-Seq数据获得（bssnpcall）。## rnaseq.list 文件内包含RNAseq.sort.bam文件路径，例如在本文件夹下，则为./outprefix.sort.bamsamtools sort -O BAM -@ 6 -o outprefix.sort.bam outprefix.samASEQ vcflist=vcf.list bamlist=rnaseq.list genes=gene.bed mode=ASE threads=6 mbq=20 mrq=20 mdc=10 pht=0.01 pft=0.01 out=./ASEQ/ 基因表达水平分布 （deeptools，bam2bw） 1bamCoverage -b outprefix.sort.bam -o outprefix.bw BS-Seq数据分析BatMeth2流程分析 （DNA甲基化水平、DNA甲基化可视化结果、bw、） 12## snp检测，线程不要超过四个bssnpcall -g genome -i sort.bam -o outprefix.vcf -p 4 等位差异甲基化分析（methyhaplo） 等位差异DNA甲基化在染色体功能元件的分布（bedtools inersect | awk ‘gff id’ | sort -rn | head -6 &gt; barplot） 等位差异DNA甲基化在染色体上的密度分布（？）bedtools/deeptools centos 安装 mysql1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768691. 卸载默认安装的mariadb：yum search mysqlyum remove mariadb.x86_642. 去官网找到mysql的下载版本https://dev.mysql.com/downloads/repo/yum/找到下面的Linux7，即CentOS7(CentOS是Red Hat旗下的)在下面的链接上直接右键复制链接（或者可以先下载到本地然后再用ftp传到服务器）3. 安装安装：wget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm注：推荐在/tmp目录下进行4. 本地安装yum源yum localinstall mysql5. 检测是否已经安装yum search mysql找到对应的软件包，复制名称6. 使用yum安装yum install mysql-community-server.x86_647. 查看是否安装成功ps -ef | grep mysql8. 启动mysqlservice mysqld startservice mysqld restartservice mysqld stop9. 查找默认登录密码cat /var/log/mysqld.log | grep password10. 登录mysql -uroot -p密码注：推荐使用 mysql -uroot-p 回车之后再输入密码。因为使用history命令会看到你明文的密码11. 修改密码SET PASSWORD = PASSWORD(' xxxx ');12. 开通远程连接权限use mysql;show tables;select * from user \Gselect host, user from user \G注：\G会格式化显示update user set host="%" where Host='localhost' and user = "root";更新权限flush privileges;或者直接重启服务：service mysqld restart Django Mysql安装mysql in macbrew install mysql 更改密码/usr/bin/mysql_secure_installation Enter password: ERROR 2002 (HY000): Can’t connect to local MySQL12mysqld stopmysql.server restart 安装pymysqlpip install pymysql 修改settings.py123456789101112131415161718192021# Database# https://docs.djangoproject.com/en/2.0/ref/settings/#databases # 数据库配置 默认的数据库为sqlite# DATABASES = &#123;# 'default': &#123;# 'ENGINE': 'django.db.backends.sqlite3',# 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),# &#125;# &#125;DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', # 数据库引擎 'NAME': 'django_mysql', # 数据库名 'USER': 'root', # 账号 'PASSWORD': 'root', # 密码 'HOST': '127.0.0.1', # HOST 'POST': 3306, # 端口 &#125;&#125; 配置init.py1234567"""setting中的配置默认为sqlite3数据库 当需要修改成MySql时并且在setting.py的同级目录的__init__.py 加入如下配置否则会报错： Error loading MySQLdb module."""import pymysqlpymysql.install_as_MySQLdb() 在app文件的models.py文件中 创建数据表（GSEid）12345678910111213141516171819202122232425262728293031""" 该类是用来生成数据库的 必须要继承models.Model"""class GSMid(models.Model): """ 创建如下几个表的字段 """ # GEO ID primary_key=True: 该字段为主键 Geoid = models.CharField('geoid', primary_key=True, max_length=15) # 碱基数目 字符串 最大长度20 Bases = models.CharField('Bases', max_length=20) # 测序设备 整数 null=False, 表示该字段不能为空 Instrument = models.CharField('Instrument', max_length=50) # Layout 布尔类型 默认True: 男生 False:女生 Layout = models.CharField('Layout', max_length=15) # Library strategy unique=True 该字段唯一 Library = models.CharField('Library', max_length=15) # Organism Organism = models.CharField('Organism', max_length=50) # Organization Organization = models.CharField('Organization', max_length=50) # SRA sra = models.CharField('SRA list', max_length=50) # Source Source = models.CharField('Source', max_length=100) # Title Title = models.CharField('Title', max_length=100) # 指定表名 不指定默认APP名字——类名(app_demo_Student) class Meta: db_table = 'gsmid' 在利用models.py文件生成数据库表之前，手动的先创建数据库12mysql&gt; create database django_mysql;Query OK, 1 row affected (0.01 sec) 终端运行命令1234567891011121314151617181920212223python manage.py makemigrationspython manage.py migrate##Operations to perform: Apply all migrations: MethAelle, admin, auth, contenttypes, sessionsRunning migrations: Applying MethAelle.0001_initial... OK Applying MethAelle.0002_gsmid... OK Applying MethAelle.0003_auto_20190317_0524... OK Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying sessions.0001_initial... OK 查看我们的django_mysql数据库，其中GSMid就是用models文件生成的表，其他的表是项目自动生成的，可以先不用管123456789101112131415161718192021mysql&gt; use django_mysqlDatabase changed mysql&gt; show tables;+----------------------------+| Tables_in_django_mysql |+----------------------------+| auth_group || auth_group_permissions || auth_permission || auth_user || auth_user_groups || auth_user_user_permissions || django_admin_log || django_content_type || django_migrations || django_session || GSMid || MethAelle_item |+----------------------------+12 rows in set (0.00 sec) 表结构,desc查看表结构12345678910111213141516mysql&gt; desc GSMid;+--------------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------------+--------------+------+-----+---------+-------+| Geoid | varchar(15) | NO | PRI | NULL | || Bases | varchar(20) | NO | | NULL | || Instrument | varchar(50) | NO | | NULL | || Layout | varchar(15) | NO | | NULL | || Library | varchar(15) | NO | | NULL | || Organism | varchar(50) | NO | | NULL | || Organization | varchar(50) | NO | | NULL | || sra | varchar(50) | NO | | NULL | || Source | varchar(100) | NO | | NULL | || Title | varchar(100) | NO | | NULL | |+--------------+--------------+------+-----+---------+-------+10 rows in set (0.01 sec) 至此Django利用models文件创建数据库表的功能已经完毕。 接下来用代码的方式演示一下Django如何进行增删改查增加数据 (views.py)1234567891011121314151617181920212223from MethAelle.models import GSMid"""插入list数据"""def loaddatalist(request): for i in range(0, 6): # 从models文件中获取GSMid对象 gsmid = GSMid() # 给对象赋值 gsmid.Geoid = "GSM-" + str(i) gsmid.Bases = "1.5G" gsmid.Instrument = "Illumina hiseq2000" gsmid.Layout = "Paired" gsmid.Library = "BS-seq" gsmid.Organism="Arabidopsis thaliana" gsmid.Organization = "HZAU" gsmid.sra = "srr01029-" + str(i) gsmid.Source = "seed-" + str(i) gsmid.Title = "Test1" # 插入数据 gsmid.save() return HttpResponse('datalist load done!') urls.py 文件中 urlpatterns中配置1url(r'^loaddatalist$', views.loaddatalist, name="loaddatalist") 查看是否插入成功1select * from GSMid; 查询数据1`&quot;&quot;&quot;``查询``&quot;&quot;&quot;``def` `find(request):`` ``#sql = &apos;select * from student&apos;`` ``# django 也可以执行原生的sql语句`` ``#result = Student.objects.raw(sql)` ` ``# 查询name = tom1的数据`` ``result ``=` `Student.objects.``filter``(name``=``&apos;tom1&apos;``)`` ``&quot;&quot;&quot;`` ``result为&lt;class &apos;django.db.models.query.QuerySet&apos;&gt;的对象`` ``需要进行数据处理`` ``&quot;&quot;&quot;`` ``arr ``=` `[]`` ``for` `i ``in` `result:`` ``content ``=` `&#123;``&apos;学号&apos;``: i.studentNum, ``&apos;姓名&apos;``: i.name, ``&apos;性别&apos;``: i.sex&#125;`` ``arr.append(content)`` ``print``(arr)`` ``print``(``type``(arr))`` ``return` `HttpResponse(arr)` 删除数据1234567&quot;&quot;&quot;删除&quot;&quot;&quot;def delete(request, Geoid): gsmid = GSMid.objects.get(Geoid=Geoid) gsmid.delete() return HttpResponse(&apos;删除成功.&apos;) settings.py中urlpatterns的配置如下 1`url(r``&apos;^delete/(?P&lt;studentNum&gt;.+)&apos;``, views.delete)` 修改显示mysql到table修改views.py12345def table(request): gsmlist=GSMid.objects.all() #获取我们的数据库信息到names里 #return render(request,'table.html',&#123;'form':table_form&#125;) #return render_to_response('MethAelle/table.html',locals()) #必须用这个return return render(request, 'MethAelle/table.html', locals()) 修改table.js1234567891011121314151617181920212223"ajax": "/static/MethAelle/data/objects.txt", 改为"ajax": "", // /static/MethAelle/data/objects.txt "columns": [ &#123; "class": "details-control", "orderable": false, "data": null, "defaultContent": "" &#125;, &#123; "data": "Geoid" &#125;, &#123; "data": "sra" &#125;, &#123; "data": "Library" &#125;, &#123; "data": "Source" &#125;, &#123; "data": "Layout" &#125;, &#123; "data": "Instrument" &#125;, &#123; "data": "Organization" &#125;, &#123; "data": "Organism" &#125;, &#123; "data": "Title" &#125;, &#123; "data": "Bases" &#125; ], "order": [[1, 'asc']]首先去掉本地显示文件 修改table.html12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;table id="example" class="display" style="width:100%"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;GEO ID&lt;/th&gt; &lt;th&gt;SRA&lt;/th&gt; &lt;th&gt;Library&lt;/th&gt; &lt;th&gt;Source&lt;/th&gt; &lt;th&gt;Layout&lt;/th&gt; &lt;th&gt;Bases&lt;/th&gt; &lt;th&gt;Organization&lt;/th&gt; &lt;th&gt;Instrument&lt;/th&gt; &lt;th&gt;Title&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &#123;% for gsm in gsmlist %&#125; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Geoid&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.sra&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Library&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Source&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Layout&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Bases&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Organization&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Instrument&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Title&#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;tfoot&gt; &lt;tr&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;GEO ID&lt;/th&gt; &lt;th&gt;SRA&lt;/th&gt; &lt;th&gt;Library&lt;/th&gt; &lt;th&gt;Source&lt;/th&gt; &lt;th&gt;Layout&lt;/th&gt; &lt;th&gt;Bases&lt;/th&gt; &lt;th&gt;Organization&lt;/th&gt; &lt;th&gt;Instrument&lt;/th&gt; &lt;th&gt;Title&lt;/th&gt; &lt;/tr&gt; &lt;/tfoot&gt;&lt;/table&gt; 参考： https://www.jb51.net/article/151269.htmnavmenu主页下拉菜单点击后背景变成灰色，设置为透明色（如下） 123456789101112131415161718/*navmenu*/#methnavmenu.navbar-default .navbar-nav .dropdown&#123; padding: 0px;&#125;#methnavmenu.navbar-default .navbar-nav&gt;li&gt;a &#123; background-color: #e7e7e705;&#125;#methnavmenu.navbar-default .navbar-nav&gt;li&gt;a:hover,#methnavmenu.navbar-default .navbar-nav&gt;li&gt;a:focus &#123; color: #20ae3d; background-color: #e7e7e705;&#125;#methnavmenu.navbar-default .navbar-nav&gt;.open&gt;a,#methnavmenu.navbar-default .navbar-nav&gt;.open&gt;a:hover,#methnavmenu.navbar-default .navbar-nav&gt;.open&gt;a:focus &#123; color: #20ae3d; background-color: #e7e7e705;&#125; 实现三级菜单 12345678910111213141516171819&lt;li class="dropdown" id="nav_table_menu"&gt; &lt;a href="&#123;% url 'table' %&#125;" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"&gt;Data List &lt;span class="caret"&gt;&lt;/span&gt;&lt;/a&gt; &lt;!-- &lt;a href="&#123;% url 'table' %&#125;" role="button" &gt;Table &lt;span class="caret"&gt;&lt;/span&gt;&lt;/a&gt; --&gt; &lt;ul class="dropdown-menu"&gt; &lt;li class="dropdown-submenu"&gt; &lt;!--需要在css中添加submenu的格式，否则不显示下一级菜单--&gt; &lt;a href="#" class="dropdown-toggle" data-toggle="dropdown"&gt; Animals &lt;b class="caret-right"&gt;&lt;/b&gt; &lt;!--需要在css中添加caret格式，向右的箭头--&gt; &lt;/a&gt; &lt;ul class="dropdown-menu"&gt; &lt;li&gt;&lt;a href="#"&gt;Human&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#"&gt;Mouse&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="&#123;% url 'table' %&#125;"&gt;Arabidopsis thaliana&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/* dropdown submenu*/.dropdown-submenu &#123; position: relative&#125;.dropdown-submenu &gt; .dropdown-menu &#123; top: 0; left: 100%; min-width: 200px; margin-top: -6px; margin-left: -1px; -webkit-border-radius: 0; -moz-border-radius: 0; border-radius: 0&#125;.dropdown-submenu:hover &gt; .dropdown-menu &#123; display: block&#125;.bigd-dropup .dropdown-submenu &gt; .dropdown-menu &#123; top: auto; bottom: 0; margin-top: 0; margin-bottom: -2px; -webkit-border-radius: 0; -moz-border-radius: 0; border-radius: 0&#125;.dropdown-submenu &gt; a:after &#123; display: block; float: right; width: 0; height: 0; margin-top: 5px; margin-right: -10px; border-color: transparent; border-left-color: #ccc; border-style: solid; border-width: 0; content: " "&#125;.dropdown-submenu:hover &gt; a:after &#123; border-left-color: #fff&#125;.dropdown-submenu.bigd-pull-left &#123; float: none&#125;.dropdown-submenu.bigd-pull-left &gt; .dropdown-menu &#123; left: -100%; margin-left: 10px; -webkit-border-radius: 0; -moz-border-radius: 0; border-radius: 0&#125; /*向右的箭头*/.caret-right &#123; display: inline-block; border: 4px solid transparent; border-left: 4px solid #000; width: 0; height: 0; right: 5px; top: 10px; left: auto; content: ' '; position: absolute&#125;/*三级菜单 done*/ 主页添加描述内容主要问题：添加描述内容两边宽度（class=container），以及上下间隔（class=index） 1234567891011121314&lt;!-- end header --&gt;&lt;div class="container"&gt; &lt;div class="index"&gt; &lt;!-- padding=15px --&gt; &lt;div class="row"&gt; &lt;div class="col-md-12"&gt; &lt;p class="text-justify" style="font-size: 18px"&gt; The Allele-specific DNA Methylation databases (AlleleMeth) is a database that integrates genome-wide DNA methylomes and Allele-specific DNA methylation across a variety of species and provides an interactive browser for visualization of high-resolution DNA methylation data. &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- panel --&gt; &lt;div class="panel panel-primary"&gt; Index css 12345678910/*home 预留间隔*/.index &#123; background-color: #ffffff; position: relative; padding: 15px 15px 15px 15px; border-width: 1px; margin-bottom: 0; -webkit-box-shadow: inset 0 3px 6px rgba(0, 0, 0, .05); box-shadow: inset 0 3px 6px rgba(0, 0, 0, .05);&#125; navbar 三级菜单选中颜色1234567891011121314151617181920212223242526&lt;!--在dropdown-menu添加id，其实也可以统一添加类,去掉id，添加focuslist类--&gt; &lt;ul class="dropdown-menu"&gt; &lt;!--animals--&gt; &lt;li class="dropdown-submenu"&gt; &lt;a href="#" class="dropdown-toggle" data-toggle="dropdown"&gt; Animals &lt;b class="caret-right"&gt;&lt;/b&gt; &lt;/a&gt; &lt;ul class="dropdown-menu focuslist" &lt;!--id="navbar_animals"--&gt; &gt; &lt;li&gt;&lt;a href="&#123;% url 'table' %&#125;"&gt;Human&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="&#123;% url 'table' %&#125;"&gt;Mouse&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;!--PLANT--&gt; &lt;li class="dropdown-submenu"&gt; &lt;a href="#" class="dropdown-toggle" data-toggle="dropdown"&gt; Plants &lt;b class="caret-right"&gt;&lt;/b&gt; &lt;/a&gt; &lt;ul class="dropdown-menu focuslist" &lt;!--id="navbar_plants"--&gt; &gt; &lt;li&gt;&lt;a href="&#123;% url 'table' %&#125;"&gt;Arabidopsis thaliana&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="&#123;% url 'table' %&#125;"&gt;Oryza&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;!----&gt; &lt;/ul&gt; 12345678910111213/* navbar 三级菜单选中颜色-绿色*//*#navbar_animals &gt; li &gt; a:hover,#navbar_animals &gt; li &gt; a:focus,#navbar_plants &gt; li &gt; a:hover,#navbar_plants &gt; li &gt; a:focus &#123; color: #20ae3d;&#125;*/.focuslist &gt; li &gt; a:hover,.focuslist &gt; li &gt; a:focus &#123; color: #20ae3d;&#125; 添加位置标示 1234567891011121314&lt;div class="container"&gt;&lt;ol class="breadcrumb"&gt; &lt;li&gt; &lt;a href="&#123;% url 'home' %&#125;"&gt; &lt;i class="fa fa-home"&gt;Home&lt;/i&gt; &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;i class="fa font-awesome"&gt;Data List&lt;/i&gt; &lt;/li&gt; &lt;li&gt; &lt;i class="active"&gt;data&lt;/i&gt; &lt;/li&gt;&lt;/ol&gt; 1234.breadcrumb &#123; margin-bottom: 0; background-color: #ffffff;&#125; 修改body字体1234567/*修改body字体*/body &#123; font-family: Arial, "Microsoft YaHei", "微软雅黑", serif; /*font-size: 16px;*/ background-color: #ffffff; position: relative;&#125; 插入icons1&lt;i class="fa fa-area-chart"&gt;&lt;/i&gt; mac删除定时任务crontab -e进入配置文件，删除以下自动换桌面命令 0 12 * * 1 /bin/bash /Users/qiangweizhou/tools/Mac-command-wallpaper/wallpaper randweb com 表格信息excel批量导入mysqlloadexcel2mysql.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import pymysql.cursors #用来操作数据库 参考地址： https://pypi.org/project/PyMySQL/#downloads 如果报错请按照这个链接安装 pip3 install PyMySQL#import xlrd # 用来读excel 参考地址: https://www.cnblogs.com/MrLJC/p/3715783.htmlfrom openpyxl import load_workbook # 可以支持xlsx的工具,https://www.cnblogs.com/anpengapple/p/6399304.html?utm_source=itdadao&amp;utm_medium=referralimport os # 用来度文件 参考地址: https://www.cnblogs.com/mufenglin/p/7676160.htmlimport re # 正则表达式模块 参考地址: http://www.runoob.com/python/python-reg-expressions.html# 连接数据库connection = pymysql.connect(host='localhost', # 数据库地址 user='root', # 数据库用户名 password='qiangwei12',# 数据库密码 db='django_mysql', # 数据库名称 charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)cursor = connection.cursor()# 创建数据库tablename = 'GSMid'#sql = "CREATE TABLE `"+tablename+"` (`pmid` int(11) NOT NULL,`article_title` varchar(1024) DEFAULT NULL,`author_list` varchar(1024) DEFAULT NULL,`abstract_text` text DEFAULT NULL,`keywords` varchar(1025) DEFAULT NULL,`pmcid` char(255) DEFAULT NULL,`pub_med_pub_date` char(255) DEFAULT NULL,`journal_issue` char(255) DEFAULT NULL,`serch_text` char(255) DEFAULT NULL) ENGINE=MyISAM DEFAULT CHARSET=utf8"#cursor.execute("DROP TABLE IF EXISTS `"+tablename+"`")#cursor.execute(sql)#connection.commit()count=0# 遍历目录basedir = '/Users/qiangweizhou/科研/DNA甲基化数据库/data_result/organism/'rootdir = os.listdir(basedir)#for subdir in rootdir: # 遍历第一层目录 1 2 3 4 5 6# if os.path.isdir(subdir):# subrootdir = os.listdir(basedir+subdir)for files in rootdir: # 遍历第二层目录 如 1下面的目录 print(os.path.splitext(files)[0]) if files[0]!='~' and os.path.splitext(files)[1]=='.xlsx': # 如果是excel文件 # data = xlrd.open_workbook(basedir+subdir+'/'+files) # table = data.sheets()[0] wb = load_workbook(basedir+files) table = wb.get_sheet_by_name("Sheet1") print("导入",basedir+files,"数据中,已经导入",count,"条数据") ##### 下面的方法是一个excel运行一次插入语句，经验证太慢，一个excel导入耗时超过3分钟 # thissql = 'insert into '+tablename+' values ' # for row in range(1,table.nrows): # value = '(' # for col in range(0,9): # value += "'"+str(table.cell(row,col).value)+"'," # value = value[:(len(value)-1)]+")," # thissql +=value # thissql = thissql[:(len(thissql))] # cursor.execute(thissql) # connection.commit() ##### 下面的方法是一行运行一次插入语句 thissql = 'insert into '+tablename+' values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)' for row in range(2,table.max_row+1): ## table.max_row+1因为range是开合的，需要+1 #print(table.cell(row=row,column=1).value, table.max_row, row) if table.cell(row=row,column=1).value == "N": continue organism=(table.cell(row=row,column=8).value) Source=(table.cell(row=row,column=10).value).split('&lt;a href', 1)[0] if Source.find(';'): Source=(Source).split(';', 1)[1] ## 爬虫时候title+sample，去掉title部分 if len(Source) &gt; 500: Source = Source[0:500] #print(Source) cursor.execute(thissql,( table.cell(row=row,column=3).value, table.cell(row=row,column=1).value, table.cell(row=row,column=4).value, table.cell(row=row,column=5).value, table.cell(row=row,column=6).value, table.cell(row=row,column=7).value, organism, table.cell(row=row,column=9).value, Source,table.cell(row=row,column=11).value,)) count+=1 connection.commit()print('批量导入数据完毕，共导入:',count,'条数据')# 关闭数据库connection.close() 首先清空数据库table 1234use django_mysqlshow tables; #查看表格select * from GSMid; #显示内容TRUNCATE TABLE GSMid; #情况 运行导入到mysql： 1python loadexcel2mysql.py Show 5 entries1&lt;script src="&#123;% static 'MethAelle/vendor/datatables/js/jquery.dataTables.js' %&#125;" type="text/javascript"&gt;&lt;/script&gt; 文件路径：MethAelle/vendor/datatables/js/jquery.dataTables.js 首先在选项中添加5，&quot;aLengthMenu&quot;: [ 5, 10, 25, 50, 100 ], 修改iDisplayLength为5，默认长度 控制table不超出div在table上层div添加overflow: auto; 文档：table.html 123456&lt;div class="panel panel-primary"&gt; &lt;div class="panel-heading"&gt;&#123;&#123;Organism&#125;&#125; Datasets List&lt;/div&gt; &lt;div class="panel-body" style="overflow: auto;"&gt; &lt;div class="row"&gt; &lt;!-- end col-left --&gt; &lt;div class="col-md-12"&gt; jquery.datatables第一列可以显示内容文件：table.js 123456789101112131415161718192021222324252627//将第一列data:null替换$(document).ready(function() &#123; var dt = $('#tabledatalistid').DataTable( &#123; // "processing": true, // "serverSide": true, "ajax": "", // /static/MethAelle/data/objects.txt "columns": [ &#123; "class": "details-control", "orderable": false, "data": "visul", //numm "defaultContent": "" &#125;, &#123; "data": "Geoid" &#125;, &#123; "data": "sra", "visible": false &#125;, &#123; "data": "Library" &#125;, &#123; "data": "Source" &#125;, &#123; "data": "Layout" &#125;, &#123; "data": "Bases" &#125;, &#123; "data": "Organization" &#125;, &#123; "data": "Instrument" &#125;, &#123; "data": "Title" &#125; ], "order": [[1, 'asc']] &#125; ); table.html内添加内容 （添加的是图标） 123456789101112131415161718192021222324252627282930313233&#123;% for gsm in gsmlist %&#125; &lt;tr&gt; &lt;td&gt; &lt;a href="&#123;% url 'jbrowse' %&#125;"&gt; &lt;i class="fa fa-area-chart" aria-hidden="false"&gt;&lt;/i&gt; &lt;/a&gt; &lt;a href="&#123;% url 'jbrowse' %&#125;"&gt; &lt;i class="fa fa-pie-chart" aria-hidden="true"&gt;&lt;/i&gt; &lt;/a&gt; &lt;a href="&#123;% url 'jbrowse' %&#125;"&gt; &lt;i class="fa fa-venus-mars" aria-hidden="true"&gt;&lt;/i&gt; &lt;/a&gt; &lt;a&gt; &lt;i class="fa fa-th-list" aria-hidden="true"&gt;&lt;/i&gt; &lt;/a&gt; &lt;/td&gt; &lt;td&gt; &lt;a href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=&#123;&#123;gsm.Geoid&#125;&#125;"&gt; &#123;&#123;gsm.Geoid&#125;&#125;&lt;/a&gt; &lt;/td&gt; &lt;td&gt; &lt;a href="https://www.ncbi.nlm.nih.gov/sra/&#123;&#123;gsm.sra&#125;&#125;"&gt; &#123;&#123;gsm.sra&#125;&#125;&lt;/a&gt; &lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Library&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Source&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Layout&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Bases&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Organization&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Instrument&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;gsm.Title&#125;&#125;&lt;/td&gt; &lt;/tr&gt;&#123;% endfor %&#125; 第三列隐藏，并显示在第一列点击后出现修改table.js内第三列，添加&quot;visible&quot;: false，内容可查看上一节 第一列点击出现： 修改table.js： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566//format d.sra 显示第三列sra内容function format ( d ) &#123; return 'The child row is a SRA list: ' + d.sra;&#125; $(document).ready(function() &#123; var dt = $('#tabledatalistid').DataTable( &#123; // "processing": true, // "serverSide": true, "ajax": "", // /static/MethAelle/data/objects.txt "columns": [ &#123; "class": "details-control", "orderable": false, "data": "visul", "defaultContent": "" &#125;, &#123; "data": "Geoid" &#125;, &#123; "data": "sra", "visible": false &#125;, &#123; "data": "Library" &#125;, &#123; "data": "Source" &#125;, &#123; "data": "Layout" &#125;, &#123; "data": "Bases" &#125;, &#123; "data": "Organization" &#125;, &#123; "data": "Instrument" &#125;, &#123; "data": "Title" &#125; ], "order": [[1, 'asc']] &#125; ); // Array to track the ids of the details displayed rows var detailRows = []; $('#tabledatalistid tbody').on( 'click', 'tr td.details-control', function () &#123; var tr = $(this).closest('tr'); var row = dt.row( tr ); var idx = $.inArray( tr.attr('id'), detailRows ); if ( row.child.isShown() ) &#123; tr.removeClass( 'details' ); row.child.hide(); // Remove from the 'open' array detailRows.splice( idx, 1 ); &#125; else &#123; tr.addClass( 'details' ); row.child( format( row.data() ) ).show(); // Add to the 'open' array if ( idx === -1 ) &#123; detailRows.push( tr.attr('id') ); &#125; &#125; &#125; ); // On each draw, loop over the `detailRows` array and show any child rows dt.on( 'draw', function () &#123; $.each( detailRows, function ( i, id ) &#123; $('#'+id+' td.details-control').trigger( 'click' ); &#125; ); &#125; );&#125; ); 去掉边框，底线变绿色1234#methnavmenu&#123; border-width: 0px; border-bottom: 1px solid #099722;&#125; 边角弧度需要添加到div下 1234#bs-example-navmenu-collapse-1&#123; border-radius: 6px; border-bottom: 1px solid #099722;&#125; navbar选择list下某一网页，需要激活li实现效果如下： 在file网页中添加： 12345678910 &lt;!-- navbar --&gt;&lt;script type="text/javascript"&gt; $(document).ready(function () &#123; // $('#nav_file').click(function (e) &#123; //e.preventDefault(); // $('#nav_file').removeClass('active'); $('#navbar_analysis').addClass('active'); &#125;);&lt;/script&gt; 对应navbar中： 123456789101112&lt;!-- Analysis --&gt; &lt;li class="dropdown" id="navbar_analysis"&gt; &lt;a href="&#123;% url 'table' %&#125;" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"&gt;Analysis/ Function &lt;span class="caret"&gt;&lt;/span&gt;&lt;/a&gt; &lt;!-- &lt;a href="&#123;% url 'table' %&#125;" role="button" &gt;Table &lt;span class="caret"&gt;&lt;/span&gt;&lt;/a&gt; --&gt; &lt;ul class="dropdown-menu"&gt; &lt;li&gt;&lt;a href="&#123;% url 'file' %&#125;"&gt;Allele Meth visulization&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#"&gt;ASM analysis&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#"&gt;Differential analysis&lt;/a&gt;&lt;/li&gt; &lt;li role="separator" class="divider"&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#"&gt;One more separated link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; RNAseq不显示BatMeth2网页结果，因此需要判断数据类型12345&#123;% if gsm.Library == "Bisulfite-Seq" %&#125; &lt;a target="_blank" href="&#123;% url 'jbrowse' %&#125;"&gt; &lt;!--batmeth2 results--&gt; &lt;i class="fa fa-pie-chart" aria-hidden="true"&gt;&lt;/i&gt; &lt;/a&gt;&#123;% endif %&#125; django send email 发邮件设置app下的setting.py 12345678## send e-mailEMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend' #email后端EMAIL_USE_TLS = False #是否使用TLS安全传输协议EMAIL_USE_SSL = True #是否使用SSL加密，qq企业邮箱要求使用EMAIL_HOST = 'smtp.qq.com' #发送邮件的邮箱 的 SMTP服务器，这里用了qq企业邮箱EMAIL_PORT = 465 #发件箱的SMTP服务器端口 or 25EMAIL_HOST_USER = '1010170266@qq.com' #发送邮件的邮箱地址EMAIL_HOST_PASSWORD = 'ksglqeziekpibdeh' #发送邮件的邮箱密码，账号的密码必须是授权码，忘了的可以在qq邮箱里面设置，把已关闭 | 开启 IMAP/SMTP服务 view. py中添加： 123456789101112131415161718192021from django.core.mail import send_maildef sendMessage(request): request.encoding='utf-8' print (request.GET) if 'name' in request.GET: name = request.GET['name'] if 'subject_title' in request.GET: Subject = request.GET['subject_title'] if 'email' in request.GET: email = request.GET['email'] if 'message' in request.GET: message = email + "\n" + request.GET['message'] send_mail( Subject, message, '1010170266@qq.com', ['1010170266@qq.com'], ) return render(request, 'MethAelle/contact.html', &#123;"message":"Send successful, thanks! We will check your message asap."&#125;) 添加横线1&lt;hr&gt; 1margin-top: 0; 响应式布局中重要的meta标签设置.适用于手机浏览器兼容性设置1234567891011121314&lt;!-- #手机浏览器兼容性设置 --&gt; &lt;meta content="application/xhtml+xml;charset=UTF-8" http-equiv="Content-Type"&gt; &lt;meta content="no-cache,must-revalidate" http-equiv="Cache-Control"&gt; &lt;meta content="no-cache" http-equiv="pragma"&gt; &lt;meta content="0" http-equiv="expires"&gt; &lt;meta content="telephone=no, address=no" name="format-detection"&gt; &lt;meta content="width=device-width, initial-scale=1.0" name="viewport"&gt; &lt;meta name="apple-mobile-web-app-capable" content="yes" /&gt; &lt;meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" /&gt; &lt;!-- #手机浏览器兼容性设置 --&gt;粘贴到顶部后和原来的meta标签对齐.可以实现响应式布局. 手机模式下拉菜单关闭不了，点击后只是闪烁一下 发现在custom.css内设置了格式如下，删除后正常。 12345678910#bs-example-navmenu-collapse-1 &#123; display: block; background-size: cover; /* background-image: url('/static/MethAelle/img/2.jpg'); */ background-color: #fff; margin-left: -15px; margin-right: -15px;&#125; 发现手机中菜单栏，点不开，一点就关闭解决：是bootstrap3.3.7中的bug，替换为4.1.0后正常 12&lt;!-- 最新的 Bootstrap 核心 JavaScript 文件 --&gt;&lt;script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js" integrity="sha384-uefMccjFJAIv6A+rW+L4AHf99KvxDjWSu1z9VI8SKNVmz4sk7buKt/6v9KI65qnm" crossorigin="anonymous"&gt;&lt;/script&gt; 删除： 1&lt;script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"&gt;&lt;/script&gt; 修改文件：file、table、jbrowse、gragh 其他文件未调用该bootstrap，所以不存在问题。]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>alleleweb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project_methhap]]></title>
    <url>%2F2019%2F04%2F03%2Fproject-methhap%2F</url>
    <content type="text"><![CDATA[asm与基因表达1234567891011121314151617[18:40:00] qwzhou@login:~/practice/A549_BS/asmonGeneexpression :$ awk -v OFS="\t" '&#123;if($7=="-")&#123;print $1,$5,"-"&#125;else&#123;print $1,$4,"+"&#125;&#125;' gex.big0Head.gtf &gt; gex.big0Head.TSS.ped3[18:40:50] qwzhou@login:~/practice/A549_BS/asmonGeneexpression :$ awk -v OFS="\t" '&#123;if($7=="-")&#123;print $1,$5,"-"&#125;else&#123;print $1,$4,"+"&#125;&#125;' gex.big0Tail.gtf &gt; gex.big0Tail.TSS.ped3[18:41:16] qwzhou@login:~/practice/A549_BS/asmonGeneexpression :$ awk -v OFS="\t" '&#123;if($7=="-")&#123;print $1,$5,"-"&#125;else&#123;print $1,$4,"+"&#125;&#125;' gex.eq0.gtf &gt; gex.eq0.TSS.ped3###区分两类来看[18:53:56] qwzhou@login:~/practice/A549_BS/asmonGeneexpression :$ cat gex.big0Head.gtf gex.big0Tail.gtf &gt; gex.expression.gtf$ awk -v OFS="\t" '&#123;if($7=="-")&#123;print $1,$5,"-"&#125;else&#123;print $1,$4,"+"&#125;&#125;' gex.expression.gtf &gt; gex.expression.TSS.ped3##获得富集情况[19:01:54] qwzhou@login:~/practice/A549_BS/asmonGeneexpression :$ awk -v num=21238 '&#123;printf $1;for(i=2;i&lt;=NF;i++)&#123;printf "\t"100*$i/num&#125;&#125;' A549.asmonExpressionGene.Methy.1.txt &gt; A549.asmonExpressionGene.Methy.1.txt.Aver[19:02:45] qwzhou@login:~/practice/A549_BS/asmonGeneexpression :$ awk -v num=37005 '&#123;printf $1;for(i=2;i&lt;=NF;i++)&#123;printf "\t"100*$i/num&#125;&#125;' A549.asmonUnGene.Methy.1.txt &gt; A549.asmonUnGene.Methy.1.txt.Aver asm的分布ASM在基因上的分布1234 awk -v OFS="\t" '&#123;if($7=="+")&#123;print $1,$4,$7&#125;else&#123;print $1,$5,$7&#125;&#125;' ~/practice/Genome/hg38/gene.gtf &gt; gene.ped3[11:29:32] qwzhou@login:~/practice/hepG2/WGBS :$ ~/software_devp/methyhaplo/ASMannoSites -o HepG2.asmonTSS -G ~/practice/Genome/hg38/batmeth2-chr/hg38.chr.fa --ped ~/practice/Genome/hg38/gene.ped3 -d 5000 -ap hepG2.newasm.plus.txt -an hepG2.newasm.neg.txt# etc.... ASM在exon上的分布1234awk -v OFS="\t" '$3=="exon"&#123;if($7=="+")&#123;print $1,$4,$7&#125;else&#123;print $1,$5,$7&#125;&#125;' ~/practice/Genome/hg38/Homo_sapiens.GRCh38.90.addchr.gtf &gt; ~/practice/Genome/hg38/exon.ped3[12:58:48] qwzhou@login:~/practice/hepG2/WGBS :$ ~/software_devp/methyhaplo/ASMannoSites -o HepG2.asmonExon -G ~/practice/Genome/hg38/batmeth2-chr/hg38.chr.fa -b ~/practice/Genome/hg38/exon.ped3 -d 5000 -ap hepG2.newasm.plus.txt -an hepG2.newasm.neg.txt... 获取intron区域123456789101112131415161718192021[11:47:07] qwzhou@login:~/practice/Genome/hg38 :$ awk 'BEGIN&#123;FS="\t| |;";OFS="\t"&#125;$3=="exon"&#123;print $1,$4,$5,$10,$22,$7&#125;' Homo_sapiens.GRCh38.90.addchr.gtf &gt; exon.bed[11:47:43] qwzhou@login:~/practice/Genome/hg38 :$ awk 'BEGIN&#123;FS="\t| |;";OFS="\t"&#125;$3=="transcript"&#123;print $1,$4,$5,$10,$22,$7&#125;' Homo_sapiens.GRCh38.90.addchr.gtf &gt; transcript.bed## 排序[11:48:00] qwzhou@login:~/practice/Genome/hg38 :$ bedtools sort -i transcript.bed &gt; transcript.sorted.bed[11:48:35] qwzhou@login:~/practice/Genome/hg38 :$ bedtools sort -i exon.bed &gt; exon.sorted.bed## 合并区域[11:48:45] qwzhou@login:~/practice/Genome/hg38 :$ bedtools merge -i transcript.sorted.bed -s -c 4,5,6 -o distinct &gt; transcript.sorted.merged.bed[11:48:58] qwzhou@login:~/practice/Genome/hg38 :$ bedtools merge -i exon.sorted.bed -s -c 4,5,6 -o distinct &gt; exon.sorted.merged.bed## 相减获得intron区域## bedtools subtract -s -a transcript.sorted.merged.bed -b exon.sorted.merged.bed &gt; intron.bed生成的结果与transcript文件一样的，失败。。。 ASM在intron上的分布12345intron提取失败，用外显子的尾端来测试awk -v OFS="\t" '$3=="exon"&#123;if($7=="+")&#123;print $1,$5,$7&#125;else&#123;print $1,$4,$7&#125;&#125;' ~/practice/Genome/hg38/Homo_sapiens.GRCh38.90.addchr.gtf &gt; ~/practice/Genome/hg38/exonEnd.ped3[12:58:48] qwzhou@login:~/practice/hepG2/WGBS :$ ~/software_devp/methyhaplo/ASMannoSites -o HepG2.asmonExonend -G ~/practice/Genome/hg38/batmeth2-chr/hg38.chr.fa -b ~/practice/Genome/hg38/exonEnd.ped3 -d 5000 -ap hepG2.newasm.plus.txt -an hepG2.newasm.neg.txtetc... 获取基因间区1awk 'BEGIN&#123;OFS="\t";&#125; $3=="gene" &#123;print $1,$4-1,$5&#125;' Homo_sapiens.GRCh38.90.addchr.gtf | sortBed | complementBed -i stdin -g hg38.chr.fa.len.sort &gt; hg38_intergenic2.bed 获取基因间区不包含promoter12[13:58:26] qwzhou@login:~/practice/Genome/hg38 :$ awk 'BEGIN&#123;OFS="\t";&#125;ARGIND==1 &#123;a[$1]=$2&#125; ARGIND==2 &amp;&amp; $3=="gene" &#123;if($7=="+")&#123;if($4&gt;2000)&#123;s=$4-2000&#125;else&#123;s=$4&#125;;print $1,s,$5&#125;else&#123;if($5+2000 &lt;a[$1])&#123;s=$5+2000&#125;else&#123;s=$5&#125;;print $1,$4,s&#125;&#125;' hg38.chr.fa.len.sort Homo_sapiens.GRCh38.90.addchr.gtf | sortBed | complementBed -i stdin -g hg38.chr.fa.len.sort &gt; hg38_intergenic.noPromoter.bed 查看asm site在不同功能元件的分布123456789101112131415[13:40:39] qwzhou@login:~/practice/hepG2/WGBS :$ awk -v OFS="\t" '$1!~/^*/&#123;print $1,$2"\n"$1,$3&#125;' hepG2.newasm.plus.txt hepG2.newasm.neg.txt | sort -k1,1 -k2,2n |uniq &gt; hepG2.asm.loci.txt[13:43:19] qwzhou@login:~/practice/hepG2/WGBS :$ awk -v OFS="\t" '&#123;print $1,$2,$2&#125;' hepG2.asm.loci.txt |bedtools intersect -a - -b ~/practice/Genome/hg38/hg38_intergenic2.bed -wo | awk '&#123;a[$1" "$2]&#125;END&#123;print length(a)&#125;'16317[13:49:51] qwzhou@login:~/practice/hepG2/WGBS :$ awk -v OFS="\t" '&#123;print $1,$2,$2&#125;' hepG2.asm.loci.txt |bedtools intersect -a - -b ~/practice/Genome/hg38/hg38_intron.bed -wo | awk '&#123;a[$1" "$2]&#125;END&#123;print length(a)&#125;'20607[13:50:07] qwzhou@login:~/practice/hepG2/WGBS :$ awk -v OFS="\t" '&#123;print $1,$2,$2&#125;' hepG2.asm.loci.txt |bedtools intersect -a - -b ~/practice/Genome/hg38/hg38_exon_merged.bed -wo | awk '&#123;a[$1" "$2]&#125;END&#123;print length(a)&#125;'6047[14:02:25] qwzhou@login:~/practice/hepG2/WGBS :$ awk -v OFS="\t" '&#123;print $1,$2,$2&#125;' hepG2.asm.loci.txt |bedtools intersect -a - -b ~/practice/Genome/hg38/hg38_intergenic.noPromoter.bed -wo | awk '&#123;a[$1" "$2]&#125;END&#123;print length(a)&#125;'13802 ASM准确性验证比较 amrfinder/methpipe123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260awk 'ARGIND==1 &amp;&amp; $3=="+" &amp;&amp; $5&lt;0.05 &amp;&amp; sqrt($NF*$NF)&gt;0.6' BS.cvi.ler.dmc | awk -v lp=0,lc="N",a="",an=0 '&#123; if(lc!=$1)&#123; if(an&gt;3)&#123; print a; &#125; lp=$2;lc=$1;a=$0;an=1 &#125;else&#123; if(lp&gt;=$2-150)&#123; a=a"\n"$0;an++ &#125;else if(an&gt;3)&#123; print a;a=""; a=$0;an=1; &#125;else&#123;a=$0;an=1;&#125; lp=$2;lc=$1; &#125;&#125;' |less[11:25:46] qwzhou@mn02:~/project/methhap/tair :$ awk 'ARGIND==1 &amp;&amp; $3=="+" &amp;&amp; $5&lt;0.05 &amp;&amp; sqrt($NF*$NF)&gt;0.6' BS.cvi.ler.dmc | awk -v lp=0,lc="N",a="",an=0 '&#123; if(lc!=$1)&#123; if(an&gt;3)&#123; print a; &#125; lp=$2;lc=$1;a=$0;an=1 &#125;else&#123; if(lp&gt;=$2-150)&#123; a=a"\n"$0;an++ &#125;else if(an&gt;3)&#123; print a;a=""; a=$0;an=1; &#125;else&#123;a=$0;an=1;&#125; lp=$2;lc=$1; &#125;&#125;' | awk 'ARGIND==1&#123;a[$1" "$2]&#125;ARGIND==2 &amp;&amp; $5&lt;0.01&#123;if($1" "($2+1) in a)&#123;print $0&#125;&#125;' - BS-cviler.allelicmeth |wc -l627[11:25:58] qwzhou@mn02:~/project/methhap/tair :$ awk '$5&lt;0.01' BS-cviler.allelicmeth |wc -l1562[11:27:58] qwzhou@mn02:~/project/methhap/tair :$ awk 'ARGIND==1 &amp;&amp; $3=="+" &amp;&amp; $5&lt;0.05 &amp;&amp; sqrt($NF*$NF)&gt;0.6' BS.cvi.ler.dmc | awk -v lp=0,lc="N",a="",an=0 '&#123; if(lc!=$1)&#123; if(an&gt;3)&#123; print a; &#125; lp=$2;lc=$1;a=$0;an=1 &#125;else&#123; if(lp&gt;=$2-150)&#123; a=a"\n"$0;an++ &#125;else if(an&gt;3)&#123; print a;a=""; a=$0;an=1; &#125;else&#123;a=$0;an=1;&#125; lp=$2;lc=$1; &#125;&#125;' | awk 'ARGIND==1&#123;a[$1" "$2]&#125;ARGIND==2 &amp;&amp; $1!~/^*/ &amp;&amp; $1=="1"&#123;if($1" "$2 in a || $1" "$3 in a)&#123;print $0&#125;&#125;' - BS-cviler.asm.cg.plus.txt |wc -l1097[11:28:19] qwzhou@mn02:~/project/methhap/tair :$ awk '$1!~/^*/ &amp;&amp; $1=="1"' BS-cviler.asm.cg.plus.txt |wc -l1466[16:56:14] qwzhou@mn02:~/project/methhap/tair :$ awk '$5&lt;0.01' BS-cviler.allelicmeth | awk '&#123;print $1"\t"$2"\t"$2&#125;' | bedtools intersect -a - -b BS-cviler.amr -wo | awk '&#123;a[$1" "$2]&#125;END&#123;print length(a)&#125;'1261[16:56:30] qwzhou@mn02:~/project/methhap/tair :$ awk '$5&lt;0.01' BS-cviler.allelicmeth | wc -l1562[16:56:38] qwzhou@mn02:~/project/methhap/tair :$ awk 'ARGIND==1 &amp;&amp; $5&lt;0.01&#123;a[$1" "$2+1]&#125;ARGIND==2 &amp;&amp; $1!~/^*/&#123;if($1" "$2 in a || $1" "$3 in a)&#123;print $0&#125;&#125;' BS-cviler.allelicmeth BS-cviler.asm.cg.plus.txt |wc -l123### 所有染色体上allelicmeth -c /public/home/qwzhou/project/Genome/arabidopsis/chrformethpipe/2.fa -o BS-cviler.allelicmeth.2 BS-cviler.epiread.2allelicmeth -c /public/home/qwzhou/project/Genome/arabidopsis/chrformethpipe/3.fa -o BS-cviler.allelicmeth.3 BS-cviler.epiread.3allelicmeth -c /public/home/qwzhou/project/Genome/arabidopsis/chrformethpipe/4.fa -o BS-cviler.allelicmeth.4 BS-cviler.epiread.4allelicmeth -c /public/home/qwzhou/project/Genome/arabidopsis/chrformethpipe/5.fa -o BS-cviler.allelicmeth.5 BS-cviler.epiread.5allelicmeth -c /public/home/qwzhou/project/Genome/arabidopsis/chrformethpipe/chloroplast.fa -o BS-cviler.allelicmeth.chloroplast BS-cviler.epiread.chloroplastallelicmeth -c /public/home/qwzhou/project/Genome/arabidopsis/chrformethpipe/mitochondria.fa -o BS-cviler.allelicmeth.mitochondria BS-cviler.epiread.mitochondria[11:16:20] qwzhou@mn02:~/project/methhap/tair :$ cat BS-cviler.allelicmeth.* &gt; BS-cviler.allelicmethawk 'ARGIND==1 &amp;&amp; $5&lt;0.05 &amp;&amp; sqrt($NF*$NF)&gt;0.6' BS.cvi.ler.dmc | awk -v lp=0,lc="N",a="",an=0 '&#123; if(lc!=$1)&#123; if(an&gt;1)&#123; print a; &#125; lp=$2;lc=$1;a=$0;an=1 &#125;else&#123; if(lp&gt;=$2-300)&#123; a=a"\n"$0;an++ &#125;else if(an&gt;1)&#123; print a;a=""; a=$0;an=1; &#125;else&#123;a=$0;an=1;&#125; lp=$2;lc=$1; &#125;&#125;' | awk 'ARGIND==1&#123;a[$1" "$2]&#125;ARGIND==2 &amp;&amp; $5&lt;0.001&#123;if($1" "($2+1) in a)&#123;print $0&#125;&#125;' - BS-cviler.allelicmeth |wc -l12286[16:20:24] qwzhou@c06n09:~/project/methhap/tair :$ awk '$5&lt;0.001' BS-cviler.allelicmeth |wc -l36757$ awk 'ARGIND==1 &amp;&amp; $5&lt;0.05 &amp;&amp; sqrt($NF*$NF)&gt;0.6' BS.cvi.ler.dmc | awk -v lp=0,lc="N",a="",an=0 '&#123; if(lc!=$1)&#123; if(an&gt;1)&#123; print a; &#125; lp=$2;lc=$1;a=$0;an=1 &#125;else&#123; if(lp&gt;=$2-300)&#123; a=a"\n"$0;an++ &#125;else if(an&gt;1)&#123; print a;a=""; a=$0;an=1; &#125;else&#123;a=$0;an=1;&#125; lp=$2;lc=$1; &#125;&#125;' | awk 'ARGIND==1&#123;a[$1" "$2]&#125;ARGIND==2 &amp;&amp; $5&lt;0.0001&#123;if($1" "($2+1) in a)&#123;print $0&#125;&#125;' - BS-cviler.allelicmeth |wc -l7207[17:10:00] qwzhou@c06n09:~/project/methhap/tair :$ awk '$5&lt;0.0001' BS-cviler.allelicmeth |wc -l22741## methyhaplo~/software/methyhaplo/ASM -i BS-cviler.hap.cg.neg.txt -o BS-cviler.hap.asm.cg.neg.txt -p 0.05 -c 3[16:56:43] qwzhou@c06n09:~/project/methhap/tair :$ awk '$1!~/^*/ ' BS-cviler.hap.asm.cg.plus.txt |wc -l14226[16:56:46] qwzhou@c06n09:~/project/methhap/tair :$ awk '$1!~/^*/ ' BS-cviler.hap.asm.cg.neg.txt |wc -l14226### methyhaploawk -v OFS="\t" '$1!~/^*/&#123;print $1,$2"\n"$1,$3&#125;' BS-cviler.asm.cg.plus.txt | uniq &gt; BS-cviler.asm.cg.plus.txt2awk -v OFS="\t" '$1!~/^*/&#123;print $1,$2"\n"$1,$3&#125;' BS-cviler.asm.cg.neg.txt | uniq &gt; BS-cviler.asm.cg.neg.txt2$ wc -l BS-cviler.asm.cg.plus.txt27306 BS-cviler.asm.cg.plus.txt2[17:07:19] qwzhou@c06n09:~/project/methhap/tair :$ wc -l BS-cviler.asm.cg.neg.txt26916 BS-cviler.asm.cg.neg.txt2$ awk 'ARGIND==1 &amp;&amp; $5&lt;0.05 &amp;&amp; sqrt($NF*$NF)&gt;0.6' BS.cvi.ler.dmc | awk -v lp=0,lc="N",a="",an=0 '&#123; if(lc!=$1)&#123; if(an&gt;1)&#123; print a; &#125; lp=$2;lc=$1;a=$0;an=1 &#125;else&#123; if(lp&gt;=$2-300)&#123; a=a"\n"$0;an++ &#125;else if(an&gt;1)&#123; print a;a=""; a=$0;an=1; &#125;else&#123;a=$0;an=1;&#125; lp=$2;lc=$1; &#125;&#125;' | awk 'ARGIND==1&#123;a[$1" "$2]&#125;ARGIND==2 &amp;&amp; $1!~/^*/&#123;if($1" "$2 in a)&#123;print $0&#125;&#125;' - BS-cviler.asm.cg.neg.txt2 |wc -l4787[17:07:22] qwzhou@c06n09:~/project/methhap/tair :$ awk 'ARGIND==1 &amp;&amp; $5&lt;0.05 &amp;&amp; sqrt($NF*$NF)&gt;0.6' BS.cvi.ler.dmc | awk -v lp=0,lc="N",a="",an=0 '&#123; if(lc!=$1)&#123; if(an&gt;1)&#123; print a; &#125; lp=$2;lc=$1;a=$0;an=1 &#125;else&#123; if(lp&gt;=$2-300)&#123; a=a"\n"$0;an++ &#125;else if(an&gt;1)&#123; print a;a=""; a=$0;an=1; &#125;else&#123;a=$0;an=1;&#125; lp=$2;lc=$1; &#125;&#125;' | awk 'ARGIND==1&#123;a[$1" "$2]&#125;ARGIND==2 &amp;&amp; $1!~/^*/&#123;if($1" "$2 in a)&#123;print $0&#125;&#125;' - BS-cviler.asm.cg.plus.txt2 |wc -l5137### methyhaplo[16:32:01] qwzhou@c06n09:~/project/methhap/tair :$ awk 'ARGIND==1 &amp;&amp; $5&lt;0.05 &amp;&amp; sqrt($NF*$NF)&gt;0.6' BS.cvi.ler.dmc | awk -v lp=0,lc="N",a="",an=0 '&#123; if(lc!=$1)&#123; if(an&gt;3)&#123; print a; &#125; lp=$2;lc=$1;a=$0;an=1 &#125;else&#123; if(lp&gt;=$2-300)&#123; a=a"\n"$0;an++ &#125;else if(an&gt;3)&#123; print a;a=""; a=$0;an=1; &#125;else&#123;a=$0;an=1;&#125; lp=$2;lc=$1; &#125;&#125;' | awk 'ARGIND==1&#123;a[$1" "$2]&#125;ARGIND==2 &amp;&amp; $1!~/^*/ &#123;if($1" "$2 in a || $1" "$3 in a)&#123;print $0&#125;&#125;' - BS-cviler.asm.cg.plus.txt |wc -l4446[16:32:22] qwzhou@c06n09:~/project/methhap/tair :$ awk 'ARGIND==1 &amp;&amp; $5&lt;0.05 &amp;&amp; sqrt($NF*$NF)&gt;0.6' BS.cvi.ler.dmc | awk -v lp=0,lc="N",a="",an=0 '&#123; if(lc!=$1)&#123; if(an&gt;3)&#123; print a; &#125; lp=$2;lc=$1;a=$0;an=1 &#125;else&#123; if(lp&gt;=$2-300)&#123; a=a"\n"$0;an++ &#125;else if(an&gt;3)&#123; print a;a=""; a=$0;an=1; &#125;else&#123;a=$0;an=1;&#125; lp=$2;lc=$1; &#125;&#125;' | awk 'ARGIND==1&#123;a[$1" "$2]&#125;ARGIND==2 &amp;&amp; $1!~/^*/ &#123;if($1" "$2 in a || $1" "$3 in a)&#123;print $0&#125;&#125;' - BS-cviler.asm.cg.neg.txt |wc -l4179[16:32:28] qwzhou@c06n09:~/project/methhap/tair :$ awk '$1!~/^*/ ' BS-cviler.asm.cg.neg.txt |wc -l5433[16:32:44] qwzhou@c06n09:~/project/methhap/tair :$ awk '$1!~/^*/ ' BS-cviler.asm.cg.plus.txt |wc -l5735### overlap[16:31:22] qwzhou@c06n09:~/project/methhap/tair :$ awk 'ARGIND==1 &amp;&amp; $5&lt;0.0001&#123;a[$1" "$2+1]&#125;ARGIND!=1&#123;if($1" "$2 in a)&#123;print $0&#125;&#125;' BS-cviler.allelicmeth BS-cviler.asm.cg.plus.txt2 BS-cviler.asm.cg.neg.txt2 &gt; BS-cviler.methpipe.overlap.methyhaplo.asm.txt2103awk 'ARGIND==1 &amp;&amp; $5&lt;0.05 &amp;&amp; sqrt($NF*$NF)&gt;0.6' BS.cvi.ler.dmc | awk -v lp=0,lc="N",a="",an=0 '&#123; if(lc!=$1)&#123; if(an&gt;1)&#123; print a; &#125; lp=$2;lc=$1;a=$0;an=1 &#125;else&#123; if(lp&gt;=$2-300)&#123; a=a"\n"$0;an++ &#125;else if(an&gt;1)&#123; print a;a=""; a=$0;an=1; &#125;else&#123;a=$0;an=1;&#125; lp=$2;lc=$1; &#125;&#125;' | awk 'ARGIND==1&#123;a[$1" "$2]&#125;ARGIND==2 &#123;if($1" "$2 in a )&#123;print $0&#125;&#125;' - BS-cviler.methpipe.overlap.methyhaplo.asm.txt |wc -l1489 prec123456789101112131415[17:22:50] qwzhou@c06n06:~/project/methhap/bsChip/PrEC :$ samtools view -h PrEC.sort.bam.nosnp.meth.bam.G1.bam | awk '$5&gt;=20' | wc -l2558109[17:23:02] qwzhou@c06n06:~/project/methhap/bsChip/PrEC :$ samtools view -h PrEC.sort.bam.nosnp.meth.bam.G2.bam | awk '$5&gt;=20' | wc -l1787038[17:23:10] qwzhou@c06n06:~/project/methhap/bsChip/PrEC :$ samtools view -h PrEC.sort.bam.snp.bam.G1.bam | awk '$5&gt;=20' | wc -l1869200[17:23:26] qwzhou@c06n06:~/project/methhap/bsChip/PrEC :$ samtools view -h PrEC.sort.bam.snp.bam.G2.bam | awk '$5&gt;=20' | wc -l787527[17:23:35] qwzhou@c06n06:~/project/methhap/bsChip/PrEC :$ samtools view -h PrEC.sort.bam | awk '$5&gt;=20' | wc -l126312219 A549 Oct4 检测12[15:41:20] qwzhou@mn02:~/project/methhap/Oct4 :$ awk -v OFS="\t" '$7=="PASS" &amp;&amp; $NF~/0\/1/&#123;print $3,$1,$2,"1",$4"/"$5&#125;' ../WGBS/A549/wgbs.new.replace.mdups.snp.filtered.sort.vcf &gt; ../A549.snp.SNPsplit.vcf 需要先建立mask基因组索引1234567891011awk -v OFS="\t" '$1~/^#/&#123;print $0&#125;$1!~/^#/&#123;if($7=="PASS")&#123;print $1,$2,$3,$4,$5,$6,$7,$8,$9":FI",$10":1"&#125;else&#123;print $1,$2,$3,$4,$5,$6,$7,$8,$9":FI",$10":0"&#125;&#125;' /public/home/qwzhou/project/methhap/wgbs.new.replace.mdups.snp.filtered.sort.vcf &gt; wgbs.snp.filtered.SNPsplit.vcfawk -v OFS="\t" '$1~/^#/&#123;print $0&#125;$1!~/^#/ &amp;&amp; $NF~/0\/1/&#123;sub(/0\/1/,"1/1",$10);print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10&#125;' wgbs.snp.filtered.SNPsplit.vcf &gt; wgbs.replace.snp.filtered.SNPsplit.replaceheterowithhomo.vcf[18:57:42] qwzhou@c01n12:~/project/methhap/Oct4 :$ SNPsplit_genome_preparation --vcf_file ./bowtie2index/wgbs.replace.snp.filtered.SNPsplit.replaceheterowithhomo.vcf --reference_genome bowtie2index --strain A549~~~ SNPsplit_genome_preparation --vcf_file /public/home/qwzhou/project/methhap/wgbs.new.replace.mdups.snp.filtered.sort.vcf --reference_genome bowtie2index --strain A549~~~[18:07:52] qwzhou@c01n12:~/project/methhap/Oct4/A549_N-masked :$ cat ./*fa &gt; hg38.N-masked.farm chrchr*bowtie2-build hg38.N-masked.fa hg38.N-masked.fa bschiphct116首先建立mask-genome索引，完成比对，这里使用bwa123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[19:01:30] qwzhou@c02n06:~/project/methhap/bsChip/hct116/bwamethindex :$ awk -v OFS="\t" '$1~/^#/&#123;print $0&#125;$1!~/^#/&#123;if($7=="PASS")&#123;print $1,$2,$3,$4,$5,$6,$7,$8,$9":FI",$10":1"&#125;else&#123;print $1,$2,$3,$4,$5,$6,$7,$8,$9":FI",$10":0"&#125;&#125;' /public/home/qwzhou/project/methhap/bsChip/hct116_bs/hct116_bs/GSE118030/BS-Seq/GSM3317488/GSM3317488.vcf &gt; hct116.snp.filtered.SNPsplit.vcfawk -v OFS="\t" '$1~/^#/&#123;print $0&#125;$1!~/^#/ &amp;&amp; $NF~/0\/1/&#123;sub(/0\/1/,"1/1",$10);print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10&#125;' hct116.snp.filtered.SNPsplit.vcf &gt; hct116.snp.filtered.SNPsplit.replaceheterowithhomo.vcf## 拷贝vcf基因组信息到vcf文件##reference=&lt;ID=null,Source=file:/public/home/qwzhou/practice/Genome/hg38/hg38.chr.fa&gt;##contig=&lt;ID=chrM,length=16569,assembly=null,md5=c68f52674c9fb33aef52dcf399755519,species=null&gt;##contig=&lt;ID=chr1,length=248956422,assembly=null,md5=2648ae1bacce4ec4b6cf337dcae37816,species=null&gt;##contig=&lt;ID=chr2,length=242193529,assembly=null,md5=4bb4f82880a14111eb7327169ffb729b,species=null&gt;##contig=&lt;ID=chr3,length=198295559,assembly=null,md5=a48af509898d3736ba95dc0912c0b461,species=null&gt;##contig=&lt;ID=chr4,length=190214555,assembly=null,md5=3210fecf1eb92d5489da4346b3fddc6e,species=null&gt;##contig=&lt;ID=chr5,length=181538259,assembly=null,md5=f7f05fb7ceea78cbc32ce652c540ff2d,species=null&gt;##contig=&lt;ID=chr6,length=170805979,assembly=null,md5=6a48dfa97e854e3c6f186c8ff973f7dd,species=null&gt;##contig=&lt;ID=chr7,length=159345973,assembly=null,md5=94eef2b96fd5a7c8db162c8c74378039,species=null&gt;##contig=&lt;ID=chr8,length=145138636,assembly=null,md5=c67955b5f7815a9a1edfaa15893d3616,species=null&gt;##contig=&lt;ID=chr9,length=138394717,assembly=null,md5=addd2795560986b7491c40b1faa3978a,species=null&gt;##contig=&lt;ID=chr10,length=133797422,assembly=null,md5=907112d17fcb73bcab1ed1c72b97ce68,species=null&gt;##contig=&lt;ID=chr11,length=135086622,assembly=null,md5=1511375dc2dd1b633af8cf439ae90cec,species=null&gt;##contig=&lt;ID=chr12,length=133275309,assembly=null,md5=e81e16d3f44337034695a29b97708fce,species=null&gt;##contig=&lt;ID=chr13,length=114364328,assembly=null,md5=17dab79b963ccd8e7377cef59a54fe1c,species=null&gt;##contig=&lt;ID=chr14,length=107043718,assembly=null,md5=acbd9552c059d9b403e75ed26c1ce5bc,species=null&gt;##contig=&lt;ID=chr15,length=101991189,assembly=null,md5=f036bd11158407596ca6bf3581454706,species=null&gt;##contig=&lt;ID=chr16,length=90338345,assembly=null,md5=24e7cabfba3548a2bb4dff582b9ee870,species=null&gt;##contig=&lt;ID=chr17,length=83257441,assembly=null,md5=a8499ca51d6fb77332c2d242923994eb,species=null&gt;##contig=&lt;ID=chr18,length=80373285,assembly=null,md5=11eeaa801f6b0e2e36a1138616b8ee9a,species=null&gt;##contig=&lt;ID=chr19,length=58617616,assembly=null,md5=b0eba2c7bb5c953d1e06a508b5e487de,species=null&gt;##contig=&lt;ID=chr20,length=64444167,assembly=null,md5=b18e6c531b0bd70e949a7fc20859cb01,species=null&gt;##contig=&lt;ID=chr21,length=46709983,assembly=null,md5=2f45a3455007b7e271509161e52954a9,species=null&gt;##contig=&lt;ID=chr22,length=50818468,assembly=null,md5=221733a2a15e2de66d33e73d126c5109,species=null&gt;##contig=&lt;ID=chrY,length=57227415,assembly=null,md5=b2b7e6369564d89059e763cd6e736837,species=null&gt;##contig=&lt;ID=chrX,length=156040895,assembly=null,md5=49527016a48497d9d1cbd8e4a9049bd3,species=null&gt;###修改strain为hct116[19:09:12] qwzhou@c02n06:~/project/methhap/bsChip/hct116 :$ SNPsplit_genome_preparation --vcf_file ./bwamethindex/hct116.snp.filtered.SNPsplit.replaceheterowithhomo.vcf --reference_genome bwamethindex/ --strain hct116[19:09:43] qwzhou@c02n06:~/project/methhap/bsChip/hct116/hct116_N-masked :$ cat ./*fa &gt; hg38.N-masked.fa[19:09:50] qwzhou@c02n06:~/project/methhap/bsChip/hct116/hct116_N-masked :$ rm chrchr*[19:20:14] qwzhou@c02n06:~/project/methhap/bsChip/hct116/hct116_N-masked :$ python ~/software/bwa-meth-master/bwameth.py index hg38.N-masked.fa[15:58:18] qwzhou@mn02:~/project/methhap/bsChip/hct116 :$ awk '$1~/^#/ || $NF~/0\/1/' bwamethindex/hct116.snp.filtered.SNPsplit.vcf &gt; bwamethindex/hct116.snp.filtered.hetero.vcf[12:05:40] qwzhou@c03n06:~/project/methhap/bsChip/hct116 :$ awk -v OFS="\t" '$6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;if($3=="+")&#123;print $1,$2,".\tC\tT\t600\tPASS\t.\tGT\t0/1"&#125;else&#123;print $1,$2,".\tG\tA\t600\tPASS\t.\tGT\t0/1"&#125;&#125;' ../hct116_bs/hct116_bs/GSE118030/BS-Seq/GSM3317488/GSM3317488.methratio.txt &gt; hct116.mr.vcfawk 'ARGIND==1 &amp;&amp; $1~/^#/&#123;print $0&#125;ARGIND==2&#123;print $0&#125;' bwamethindex/hct116.snp.filtered.hetero.vcf hct116.mr.vcf &gt; hct116.mr.withheader.vcf PrEC123456789[15:54:49] qwzhou@mn02:~/project/methhap/bsChip/PrEC :$ awk '$1~/^#/ || $NF~/0\/1/' prepareGenome/PrEC.snp.filtered.SNPsplit.vcf &gt; prepareGenome/PrEC.snp.filtered.hetero.vcf[19:28:09] qwzhou@mn02:~/project/methhap/bsChip/PrEC :$ SNPsplit_genome_preparation --vcf_file ./prepareGenome/PrEC.snp.filtered.SNPsplit.replaceheterowithhomo.vcf --reference_genome prepareGenome/ --strain PrEC[19:28:32] qwzhou@mn02:~/project/methhap/bsChip/PrEC/PrEC_N-masked :$ cat ./*fa &gt; hg38.N-masked.farm chrchr*[19:29:52] qwzhou@c02n05:~/project/methhap/bsChip/PrEC/PrEC_N-masked :$ python ~/software/bwa-meth-master/bwameth.py index hg38.N-masked.fa LNCaP123456789[14:35:15] qwzhou@mn02:~/project/methhap/bsChip/LNCaP :$ awk '$1~/^#/ || $NF~/0\/1/' preGenome/LNCaP.snp.filtered.SNPsplit.vcf &gt; preGenome/LNCaP.snp.filtered.hetero.vcf[19:35:27] qwzhou@mn02:~/project/methhap/bsChip/LNCaP :$ SNPsplit_genome_preparation --vcf_file ./preGenome/LNCaP.snp.filtered.SNPsplit.replaceheterowithhomo.vcf --reference_genome preGenome/ --strain LNCaP[19:37:29] qwzhou@mn02:~/project/methhap/bsChip/LNCaP/LNCaP_N-masked :$ cat ./*fa &gt; hg38.N-masked.fa[19:38:05] qwzhou@mn02:~/project/methhap/bsChip/LNCaP/LNCaP_N-masked :$ rm chrchr*python ~/software/bwa-meth-master/bwameth.py index hg38.N-masked.fa 运算1234567891011121314151617181920212223242526272829303132333435363738[15:56:56] qwzhou@mn02:~/project/methhap/bsChip :$ awk -v OFS="\t" '$7=="PASS" &amp;&amp; $10~/0\/1/&#123;print $3,$1,$2,"1",$4"/"$5&#125;' prostate/prostate_bs/GSE86833/BS-Seq/GSM2309190/GSM2309190.vcf &gt; prostate/PrEC.snp.snpsplit.vcf[15:57:39] qwzhou@mn02:~/project/methhap/bsChip :$ awk -v OFS="\t" '$7=="PASS" &amp;&amp; $10~/0\/1/&#123;print $3,$1,$2,"1",$4"/"$5&#125;' prostate/prostate_bs/GSE86833/BS-Seq/GSM2309189/GSM2309189.vcf &gt; prostate/LNCaP.snp.snpsplit.vcf[15:59:49] qwzhou@mn02:~/project/methhap/bsChip :$ awk -v OFS="\t" '$3=="+" &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,".\tC\tT\t600\tPASS\t.\tGT\t0/1"&#125;' prostate/prostate_bs/GSE86833/BS-Seq/GSM2309190/GSM2309190.methratio.txt &gt; prostate/PrEC.mr.p.vcf[16:07:44] qwzhou@mn02:~/project/methhap/bsChip :$ awk -v OFS="\t" '$3=="-" &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,".\tG\tA\t600\tPASS\t.\tGT\t0/1"&#125;' prostate/prostate_bs/GSE86833/BS-Seq/GSM2309190/GSM2309190.methratio.txt &gt; prostate/PrEC.mr.n.vcf[16:14:26] qwzhou@mn02:~/project/methhap/bsChip :$ awk -v OFS="\t" '$3=="+" &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,".\tC\tT\t600\tPASS\t.\tGT\t0/1"&#125;' prostate/prostate_bs/GSE86833/BS-Seq/GSM2309189/GSM2309189.methratio.txt &gt; prostate/LNCaP.mr.p.vcf[16:19:15] qwzhou@mn02:~/project/methhap/bsChip :$ awk -v OFS="\t" '$3=="-" &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,".\tG\tA\t600\tPASS\t.\tGT\t0/1"&#125;' prostate/prostate_bs/GSE86833/BS-Seq/GSM2309189/GSM2309189.methratio.txt &gt; prostate/LNCaP.mr.n.vcf[16:49:49] qwzhou@mn02:~/project/methhap/bsChip :$ awk -v OFS="\t" '&#123;print $3,$1,$2,"1",$4"/"$5&#125;' prostate/PrEC.mr.p.vcf &gt; prostate/PrEC.mr.p.snpsplit.vcf[16:50:04] qwzhou@mn02:~/project/methhap/bsChip :$ awk -v OFS="\t" '&#123;print $3,$1,$2,"1",$4"/"$5&#125;' prostate/PrEC.mr.n.vcf &gt; prostate/PrEC.mr.n.snpsplit.vcf[16:52:28] qwzhou@mn02:~/project/methhap/bsChip :$ awk -v OFS="\t" '&#123;print $3,$1,$2,"1",$4"/"$5&#125;' prostate/LNCaP.mr.n.vcf &gt; prostate/LNCaP.mr.n.snpsplit.vcf[16:52:49] qwzhou@mn02:~/project/methhap/bsChip :$ awk -v OFS="\t" '&#123;print $3,$1,$2,"1",$4"/"$5&#125;' prostate/LNCaP.mr.p.vcf &gt; prostate/LNCaP.mr.p.snpsplit.vcf[16:54:49] qwzhou@mn02:~/project/methhap/bsChip :$ cat prostate/PrEC.snp.snpsplit.vcf prostate/PrEC.mr.p.snpsplit.vcf | sort -k2,2 -k3,3n &gt; prostate/PrEC.mrsnp.p.snpsplit.vcf[16:55:13] qwzhou@mn02:~/project/methhap/bsChip :$ cat prostate/PrEC.snp.snpsplit.vcf prostate/PrEC.mr.n.snpsplit.vcf | sort -k2,2 -k3,3n &gt; prostate/PrEC.mrsnp.n.snpsplit.vcf[16:55:40] qwzhou@mn02:~/project/methhap/bsChip :$ cat prostate/LNCaP.snp.snpsplit.vcf prostate/LNCaP.mr.p.snpsplit.vcf | sort -k2,2 -k3,3n &gt; prostate/LNCaP.mrsnp.p.snpsplit.vcf[16:56:14] qwzhou@mn02:~/project/methhap/bsChip :$ cat prostate/LNCaP.snp.snpsplit.vcf prostate/LNCaP.mr.n.snpsplit.vcf | sort -k2,2 -k3,3n &gt; prostate/LNCaP.mrsnp.n.snpsplit.vcf##hct116[17:09:39] qwzhou@mn02:~/project/methhap/bsChip/hct116_bs :$ awk -v OFS="\t" '$7=="PASS" &amp;&amp; $10~/0\/1/&#123;print $3,$1,$2,"1",$4"/"$5&#125;' hct116_bs/GSE118030/BS-Seq/GSM3317488/GSM3317488.vcf &gt; hct116.snp.snpsplit.vcf[17:10:49] qwzhou@mn02:~/project/methhap/bsChip/hct116_bs :$ awk -v OFS="\t" '$3=="+" &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,".\tC\tT\t600\tPASS\t.\tGT\t0/1"&#125;' hct116_bs/GSE118030/BS-Seq/GSM3317488/GSM3317488.methratio.txt &gt; hct116.mr.p.vcf[17:21:42] qwzhou@mn02:~/project/methhap/bsChip/hct116_bs :$ awk -v OFS="\t" '$3=="-" &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,".\tG\tA\t600\tPASS\t.\tGT\t0/1"&#125;' hct116_bs/GSE118030/BS-Seq/GSM3317488/GSM3317488.methratio.txt &gt; hct116.mr.n.vcf 6个细胞系的ASMG GO分析首先获取asmg1234567[10:45:18] qwzhou@mn02:~/project/methhap/WGBS :bedtools intersect -a ~/project/Genome/hg38/gene.id.bed -b A549/A549.newasm.bed -wo | cut -f1-6 | uniq &gt; A549.asmg.bedbedtools intersect -a ~/project/Genome/hg38/gene.id.bed -b imr90/imr90.asm.bed -wo | cut -f1-6 | uniq &gt; imr90.asmg.bedbedtools intersect -a ~/project/Genome/hg38/gene.id.bed -b gm12878/GM12878.asm.bed -wo | cut -f1-6 | uniq &gt; gm12878.asmg.bedbedtools intersect -a ~/project/Genome/hg38/gene.id.bed -b hepG2/hepG2.newasm.bed -wo | cut -f1-6 | uniq &gt; hepG2.asmg.bedbedtools intersect -a ~/project/Genome/hg38/gene.id.bed -b hues64/hues64.asm.bed -wo | cut -f1-6 | uniq &gt; hues64.asmg.bedbedtools intersect -a ~/project/Genome/hg38/gene.id.bed -b k562/k562.asm.bed -wo | cut -f1-6 | uniq &gt; k562.asmg.bed meth单独的单倍型长度1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071### hepG2[12:21:40] qwzhou@mn02:~/project/methhap/WGBS/hepG2 :$ awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' hepG2.mr.hapcut2.p.haplo.txt hepG2.mr.hapcut2.n.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge &gt; hepG2.mr.haplo.merge.txt[12:43:04] qwzhou@mn02:~/project/methhap/WGBS/hepG2 :$ awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;' hepG2.mr.haplo.merge.txt683 14502 104522[12:43:28] qwzhou@mn02:~/project/methhap/WGBS/hepG2 :$ awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;' hepG2.mr.haplo.merge.txt314959538 1667917 188.834### A549## meth + snp[15:44:13] qwzhou@mn02:~/project/methhap/WGBS/A549 :$ awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' A549.snpwithmr.p.hapcut2.haplo.txt A549.snpwithmr.n.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge &gt; A549.snpwithmr.haplo.merge.txt[15:46:01] qwzhou@mn02:~/project/methhap/WGBS/A549 :$ awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;' A549.snpwithmr.haplo.merge.txt670171648 2045102 327.696[19:21:07] qwzhou@mn02:~/project/methhap/WGBS/A549 :$ awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;' A549.snpwithmr.haplo.merge.txt14140 95721 301276## methawk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' A549.mr.hapcut2.p.haplo.txt A549.mr.hapcut2.n.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge &gt; A549.mr.haplo.merge.txtawk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;' A549.mr.haplo.merge.txt5381 58183 234785awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;' A549.mr.haplo.merge.txt525438628 1873522 280.455## snp[19:19:05] qwzhou@mn02:~/project/methhap/WGBS/A549 :$ awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' A549.snv.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'78669651 295069 266.614[19:19:59] qwzhou@mn02:~/project/methhap/WGBS/A549 :$ awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' A549.snv.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'749 5944 30007## + hicawk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' A549.snpwithmr.merge.hic.haplo.txt | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'883475472 2284995 386.642awk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' A549.snpwithmr.merge.hic.haplo.txt | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'28314 85952 298869 A549 覆盖repeat情况12345678910111213141516171819202122232425### + hicawk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' A549.snpwithmr.merge.hic.haplo.txt | bedtools intersect -a - -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'2326516## meth snpbedtools intersect -a A549.snpwithmr.haplo.merge.txt -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'2207366## methbedtools intersect -a A549.mr.haplo.merge.txt -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'1845620## snpawk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' A549.snv.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | bedtools intersect -a - -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;' 统计IMR90、hepG2、K562的单倍型结果1234567891011121314151617181920## 150scp ./wgbs.replace.mdups.snp.filtered.sort.vcf qwzhou@211.69.141.142:/public/home/qwzhou/project/methhap/WGBS/imr90scp ./run.hapcut2snv.sh qwzhou@211.69.141.142:/public/home/qwzhou/project/methhap/WGBS/imr90scp ./run.hapcut2snv.sh qwzhou@211.69.141.142:/public/home/qwzhou/project/methhap/WGBS/imr90## 142[15:38:15] qwzhou@mn02:~/project/methhap/WGBS/imr90 :$ bsub &lt; run.lsf## 150[15:55:16] qwzhou@login:~/practice/hepG2/WGBS :$ scp ./hepG2.snp*haplo* qwzhou@211.69.141.142:~/project/methhap/WGBS/hepG2[16:11:46] qwzhou@login:~/practice/Imr90_epi/encode/BSseq :$ scp ./imr90.snp*haplo* qwzhou@211.69.141.142:~/project/methhap/WGBS/imr90[15:57:52] qwzhou@login:~/practice/k562/WGBS :$ scp ./k562.snp*haplo* qwzhou@211.69.141.142:~/project/methhap/WGBS/k562[16:10:31] qwzhou@login:~/practice/A549_BS :$ scp ./bshichap.cpp qwzhou@211.69.141.142:~/project/methhap/WGBS/ – 单倍型长度1234567891011121314151617181920212223242526272829### imr90 2k 1k 500bp## meth/snp[16:06:02] qwzhou@mn02:~/project/methhap/WGBS/imr90 :$ awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' imr90.snpwithmr.p.hapcut2.haplo.txt imr90.snpwithmr.n.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge &gt; imr90.hapcut2.haplo.merge.bed[16:07:48] qwzhou@mn02:~/project/methhap/WGBS/imr90 :$ awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;' imr90.hapcut2.haplo.merge.bed1525 13531 77132## snp[16:08:00] qwzhou@mn02:~/project/methhap/WGBS/imr90 :$ awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' imr90.snp.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'22 235 3053## meth +snp, snp[16:15:37] qwzhou@mn02:~/project/methhap/WGBS/imr90 :$ awk -v OFS="\t" 'ARGIND==1&#123;v[$1" "$2]&#125;ARGIND!=1 &amp;&amp; $1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0 &amp;&amp; pp==1)&#123;print "=== "chr,start,end"\n"inf&#125;;pp=0;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0 &amp;&amp; pp==1)&#123;print "=== "chr,start,end"\n"inf&#125;;pp=0;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if($4" "$5 in v)&#123;pp=1&#125;;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' wgbs.replace.mdups.snp.filtered.sort.vcf imr90.snpwithmr.p.hapcut2.haplo.txt imr90.snpwithmr.n.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'1186 9720 51002#### total len## meth/snp[16:11:36] qwzhou@mn02:~/project/methhap/WGBS/imr90 :$ awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;' imr90.hapcut2.haplo.merge.bed278401202 1571037 177.209## snp[16:11:59] qwzhou@mn02:~/project/methhap/WGBS/imr90 :$ awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' imr90.snp.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'30820961 227502 135.476## snp +meth, snp[16:12:33] qwzhou@mn02:~/project/methhap/WGBS/imr90 :$ awk -v OFS="\t" 'ARGIND==1&#123;v[$1" "$2]&#125;ARGIND!=1 &amp;&amp; $1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0 &amp;&amp; pp==1)&#123;print "=== "chr,start,end"\n"inf&#125;;pp=0;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0 &amp;&amp; pp==1)&#123;print "=== "chr,start,end"\n"inf&#125;;pp=0;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if($4" "$5 in v)&#123;pp=1&#125;;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' wgbs.replace.mdups.snp.filtered.sort.vcf imr90.snpwithmr.p.hapcut2.haplo.txt imr90.snpwithmr.n.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'149721774 681489 219.698 —合并hap123456## 合并meth[14:57:07] qwzhou@mn02:~/project/methhap/WGBS/imr90 :$ ../bsmerge imr90.snpwithmr.p.hapcut2.haplo.txt imr90.snpwithmr.n.hapcut2.haplo.txt &gt; imr90.snpwithmr.merge.hapcut2.haplo.txt##合并hic[14:59:00] qwzhou@mn02:~/project/methhap/WGBS/imr90 :$ ../bsmergehic imr90.snpwithmr.merge.hapcut2.haplo.txt ../../hic/imr90/hic_out/bowtie_results/bwt2/imr90.haplo.txt &gt; hap.mergedhic.txt 统计长度 + hic12345678910111213141516171819202122232425262728293031323334hicmerge="hap.mergedhic.txt"awk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' $&#123;hicmerge&#125; | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'331143923 1823085 181.639awk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' $&#123;hicmerge&#125; | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'2136 15067 91041 覆盖repeat情况1234567891011121314151617181920212223242526### + hichicmerge="A549.snpwithmr.merge.hic.haplo.txt"snpmrmerge="A549.snpwithmr.haplo.merge.txt"mrmerge="A549.mr.haplo.merge.txt"snphap="A549.snv.hapcut2.haplo.txt"awk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' $&#123;hicmerge&#125; | bedtools intersect -a - -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'## meth snpbedtools intersect -a $&#123;snpmrmerge&#125; -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'## methbedtools intersect -a $&#123;mrmerge&#125; -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'## snpawk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;snphap&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | bedtools intersect -a - -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;' 整合成脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899cd WGBS/imr90/methsnpp="imr90.snpwithmr.p.hapcut2.haplo.txt"methsnpn="imr90.snpwithmr.n.hapcut2.haplo.txt"methp="imr90.mr.hapcut2.p.haplo.txt"methn="imr90.mr.hapcut2.n.haplo.txt"snphap="imr90.snp.hapcut2.haplo.txt"## meth + snpmethsnpmerge="snpwithmr.haplo.merge.txt"methmerge="mr.haplo.merge.txt"hichap="/public/home/qwzhou/project/methhap/hic/imr90/hic_out/bowtie_results/bwt2/imr90.haplo.txt"awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;methsnpp&#125; $&#123;methsnpp&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge &gt; $&#123;methsnpmerge&#125;awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;' $&#123;methsnpmerge&#125;awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;' $&#123;methsnpmerge&#125;## methawk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;methp&#125; $&#123;methp&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge &gt; $&#123;methmerge&#125;awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;' $&#123;methmerge&#125;awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;' $&#123;methmerge&#125;## snpawk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;snphap&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;snphap&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'## snp meth +hic##合并snpmeth~/project/methhap/WGBS/bsmerge $&#123;methsnpp&#125; $&#123;methsnpn&#125; &gt; snpwithmr.merge.hapcut2.haplo.txt##合并hic~/project/methhap/WGBS/bsmergehic snpwithmr.merge.hapcut2.haplo.txt $&#123;hichap&#125; &gt; snpwithmr.hap.mergedhic.txtawk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' snpwithmr.hap.mergedhic.txt | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'awk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' snpwithmr.hap.mergedhic.txt | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'### 覆盖 repeat## meth snpbedtools intersect -a $&#123;methsnpmerge&#125; -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'## methbedtools intersect -a $&#123;methmerge&#125; -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'## snpawk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' $&#123;snphap&#125; | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | bedtools intersect -a - -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'### + hicawk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^B/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' snpwithmr.hap.mergedhic.txt | bedtools intersect -a - -b ~/project/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;' ASM on exon 脚本部分1234567891011readfile("/Users/qiangweizhou/K562.asmonExonend.0.02.Methy.1.txt", y,z, k)readfile("/Users/qiangweizhou/IMR90.asmonExonend.0.02.Methy.1.txt", y,z, k)readfile("/Users/qiangweizhou/HepG2.asmonExonend.0.02.Methy.1.txt", y,z, k)readfile("/Users/qiangweizhou/A549.asmonExonend.0.02.Methy.1.txt", y,z, k)readfile("/Users/qiangweizhou/HUES64.asmonExonend.0.02.Methy.1.txt", y,z, k)readfile("/Users/qiangweizhou/GM12878.asmonExonend.0.02.Methy.1.txt", y,z, k)x = np.linspace(1, len(y[0]), len(y[0]))label=['K562', 'IMR90', 'HepG2', 'A549', 'HUES64', 'GM12878']filename="ASMonExonE.all" 工作1 整理拟南芥数据结果。 拟南芥单倍型长度、覆盖repeat数目、ASM 2 HiC + BS 单倍型组装 IMR90 K562 etc. HiC haplotype 根据SNP信息，整合单倍型结果 3 K562 HepG2 DNA单倍型文章组装DNA单倍型 k562 HepG2 单倍型与WGS比较首先完成WGBS meth+snv检测单倍型12[10:45:12] qwzhou@login:~/practice/k562/WGBS :$ echo 'sh run.hapcut2.sh' | qsub -l nodes=1:ppn=8 -d ./ -e ./ -N k562 WGS单倍型首先将下载的文件转为hg38基因组对应。过程查看dayday-liftover部分。先比较一下我们k562 vcf文件与结果中的信息重合度。123456[14:27:14] qwzhou@login:~/practice/k562/WGBS :$ awk 'ARGIND==1&#123;a[$1" "$2]&#125;ARGIND==2&#123;if($1" "$2 in a)&#123;print $0&#125;&#125;' wgbs.replace.mdups.snp.filtered.sort.vcf k562.wgshap.bed |wc -l944306[14:27:47] qwzhou@login:~/practice/k562/WGBS :$ wc -l k562.wgshap.bed1178703 k562.wgshap.bed 重合情况还算不错12345678910111213141516awk 'ARGIND==1&#123;a[$1" "$2]=$4;b[$1" "$2]=$5&#125;ARGIND==2&#123; if($1~/^B/)&#123;if(s1&gt;s2)&#123;same+=s1;diff+=d1&#125;else&#123;same+=s2;diff+=d2&#125;; s1=0;d1=0;s2=0;d2=0;&#125;else if($2==0 || $2==1)&#123; if($2==0)&#123; if($4" "$5 in a)&#123; if(a[$4" "$5]==$6)&#123;s1++&#125;else&#123;d1++&#125; if(b[$4" "$5]==$6)&#123;s2++&#125;else&#123;d2++&#125; &#125; &#125;else&#123; if($4" "$5 in a)&#123; if(a[$4" "$5]==$7)&#123;s1++&#125;else&#123;d1++&#125; if(b[$4" "$5]==$7)&#123;s2++&#125;else&#123;d2++&#125; &#125; &#125; &#125;&#125;END&#123;if(s1&gt;s2)&#123;same+=s1;diff+=d1&#125;else&#123;same+=s2;diff+=d2&#125;;print same, diff&#125;' k562.wgshap.bed k562.snp.hapcut2.haplo.txt 196340 22153 杂合SNP的数目：1579372杂合SNP与组装后单倍型重合数目：663911WGS单倍型杂合SNP数目：577474WGS杂合SNP与bs snp重合数目：479644WGS与单倍型重合数目：217711， 其中相同的196340，差异的22153 | 21371mrsnp与wgs单倍型：344913,1234567891011[15:04:30] qwzhou@comput54:~/practice/k562/WGBS :$ awk 'ARGIND==1 &amp;&amp; $NF~/0\/1/ &amp;&amp; $7=="PASS"' wgbs.replace.mdups.snp.filtered.sort.vcf | wc -l1579372awk 'ARGIND==1 &amp;&amp; $NF~/0\/1/ &amp;&amp; $7=="PASS"&#123;a[$1" "$2]&#125;ARGIND==2&#123;if($2==0 || $2==1)&#123;if($4" "$5 in a)&#123;print $0&#125;&#125;&#125;' wgbs.replace.mdups.snp.filtered.sort.vcf k562.snp.hapcut2.haplo.txt |wc -l663911awk 'ARGIND==1 &amp;&amp; $4!=$5' k562.wgshap.bed |wc -l577474awk 'ARGIND==1 &amp;&amp; $NF~/0\/1/ &amp;&amp; $7=="PASS"&#123;a[$1" "$2]&#125;ARGIND==2 &amp;&amp; $4!=$5&#123;if($1" "$2 in a)&#123;print $0&#125;&#125;' wgbs.replace.mdups.snp.filtered.sort.vcf k562.wgshap.bed |wc -l479644awk 'ARGIND==1 &amp;&amp; $4!=$5&#123;a[$1" "$2]&#125;ARGIND==2&#123;if($2==0 || $2==1)&#123;if($4" "$5 in a)&#123;print $0&#125;&#125;&#125;' k562.wgshap.bed k562.snp.hapcut2.haplo.txt |wc -l217711 计算methSNP重合度：12345678910111213141516171819202122232425262728293031awk 'BEGIN&#123;split("",s1);split("",d1);split("",s2);split("",d2);&#125; ARGIND==1&#123;a[$1" "$2]=$4;b[$1" "$2]=$5&#125;ARGIND!=1&#123; if($1~/^B/ &amp;&amp; FNR&gt;1)&#123; if(length(s1)&gt;length(s2))&#123; for(i in s1)&#123;same[i]=s1[i]&#125;;for(i in d1)&#123;diff[i]=d1[i]&#125; &#125;else&#123; for(i in s2)&#123;same[i]=s2[i]&#125;;for(i in d2)&#123;diff[i]=d2[i]&#125;; &#125; split("",s1);split("",d1);split("",s2);split("",d2); &#125;else if($2==0 || $2==1)&#123; if($2==0)&#123; if($4" "$5 in a)&#123; if(a[$4" "$5]==$6)&#123;s1[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d1[$4" "$5]&#125;&#125; if(b[$4" "$5]==$6)&#123;s2[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d2[$4" "$5]&#125;&#125; &#125; &#125;else&#123; if($4" "$5 in a)&#123; if(a[$4" "$5]==$7)&#123;s1[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d1[$4" "$5]&#125;&#125; if(b[$4" "$5]==$7)&#123;s2[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d2[$4" "$5]&#125;&#125; &#125; &#125; &#125;&#125;END&#123; if(length(s1)&gt;length(s2))&#123; for(i in s1)&#123;same[i]=s1[i]&#125;;for(i in d1)&#123;diff[i]=d1[i]&#125; &#125;else&#123; for(i in s2)&#123;same[i]=s2[i]&#125;;for(i in d2)&#123;diff[i]=d2[i]&#125;; &#125; print length(same), length(diff)&#125;' k562.wgshap.bed k562.snpwithmr.p.hapcut2.haplo.txt k562.snpwithmr.n.hapcut2.haplo.txt 335646 36349 统计mapQ==100的hap：123456789101112131415161718192021222324252627282930awk 'BEGIN&#123;split("",s1);split("",d1);split("",s2);split("",d2);&#125; ARGIND==1&#123;a[$1" "$2]=$4;b[$1" "$2]=$5&#125;ARGIND!=1&#123; if($1~/^B/ &amp;&amp; FNR&gt;1)&#123; if(length(s1)&gt;length(s2))&#123; for(i in s1)&#123;same[i]=s1[i]&#125;;for(i in d1)&#123;diff[i]=d1[i]&#125; &#125;else&#123; for(i in s2)&#123;same[i]=s2[i]&#125;;for(i in d2)&#123;diff[i]=d2[i]&#125;; &#125; split("",s1);split("",d1);split("",s2);split("",d2); &#125;else if($NF==100 &amp;&amp; ($2==0 || $2==1))&#123; if($2==0)&#123; if($4" "$5 in a)&#123; if(a[$4" "$5]==$6)&#123;s1[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d1[$4" "$5]&#125;&#125; if(b[$4" "$5]==$6)&#123;s2[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d2[$4" "$5]&#125;&#125; &#125; &#125;else&#123; if($4" "$5 in a)&#123; if(a[$4" "$5]==$7)&#123;s1[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d1[$4" "$5]&#125;&#125; if(b[$4" "$5]==$7)&#123;s2[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d2[$4" "$5]&#125;&#125; &#125; &#125; &#125;&#125;END&#123; if(length(s1)&gt;length(s2))&#123; for(i in s1)&#123;same[i]=s1[i]&#125;;for(i in d1)&#123;diff[i]=d1[i]&#125; &#125;else&#123; for(i in s2)&#123;same[i]=s2[i]&#125;;for(i in d2)&#123;diff[i]=d2[i]&#125;; &#125; print length(same), length(diff)&#125;' k562.wgshap.bed k562.snpwithmr.p.hapcut2.haplo.txt k562.snpwithmr.n.hapcut2.haplo.txt 统计k562、hepG2与WGS hap重合位点，方便可视化。123456789101112131415161718192021222324252627282930awk 'BEGIN&#123;split("",s1);split("",d1);split("",s2);split("",d2);&#125; ARGIND==1&#123;a[$1" "$2]=$4;b[$1" "$2]=$5&#125;ARGIND!=1&#123; if($1~/^B/ &amp;&amp; FNR&gt;1)&#123; if(length(s1)&gt;length(s2))&#123; for(i in s1)&#123;same[i]=s1[i]&#125;;for(i in d1)&#123;diff[i]=d1[i]&#125; &#125;else&#123; for(i in s2)&#123;same[i]=s2[i]&#125;;for(i in d2)&#123;diff[i]=d2[i]&#125;; &#125; split("",s1);split("",d1);split("",s2);split("",d2); &#125;else if($2==0 || $2==1)&#123; if($2==0)&#123; if($4" "$5 in a)&#123; if(a[$4" "$5]==$6)&#123;s1[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d1[$4" "$5]&#125;&#125; if(b[$4" "$5]==$6)&#123;s2[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d2[$4" "$5]&#125;&#125; &#125; &#125;else&#123; if($4" "$5 in a)&#123; if(a[$4" "$5]==$7)&#123;s1[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d1[$4" "$5]&#125;&#125; if(b[$4" "$5]==$7)&#123;s2[$4" "$5]&#125;else&#123;if($8~/:/)&#123;d2[$4" "$5]&#125;&#125; &#125; &#125; &#125;&#125;END&#123; if(length(s1)&gt;length(s2))&#123; for(i in s1)&#123;same[i]=s1[i]&#125;;for(i in d1)&#123;diff[i]=d1[i]&#125; &#125;else&#123; for(i in s2)&#123;same[i]=s2[i]&#125;;for(i in d2)&#123;diff[i]=d2[i]&#125;; &#125; for(i in same)&#123;print i,"same"&#125;;for(i in diff)&#123;print i,"diff"&#125;&#125;' k562.wgshap.bed k562.snp.hapcut2.haplo.txt | sort -k1,1 -k2,2n &gt; k562.snphap.wgshap.txt snpmr:12...k562.wgshap.bed k562.snpwithmr.p.hapcut2.haplo.txt k562.snpwithmr.n.hapcut2.haplo.txt | sort -k1,1 -k2,2n &gt; k562.mrsnphap.wgshap.txt 合并文件：12[15:14:49] qwzhou@login:~/practice/k562/WGBS :$ awk -v OFS="\t" 'ARGIND==1&#123;a[$1"\t"$2]="N\tN"&#125;ARGIND==2&#123;a[$1"\t"$2]=$3"\tN"&#125;ARGIND==3&#123;split(a[$1"\t"$2],b,"\t"); a[$1"\t"$2]=b[1]"\t"$3&#125;END&#123;for(i in a)&#123;print i,a[i]&#125;&#125;' k562.wgshap.bed k562.mrsnphap.wgshap.txt k562.snphap.wgshap.txt |sort -k1,1 -k2,2n &gt; k562.vs.wgshap.merge.txt 数据太大没法可视化，做进一步处理：1234567891011╭─[MacBook-Pro] as qiangweizhou in ~/科研/DNA甲基化单倍型/bshichaplo 04-11 16:19:43╰──➤ awk -v OFS="\t" '$3!="N" &amp;&amp; $4!="N"&#123;a[$1"\t"int($2/2000)"\t"$3]++; b[$1"\t"int($2/2000)"\t"$4]++; id[$1"\t"int($2/2000)];&#125;END&#123; for(i in id)&#123; if(!(i"\tsame" in a))&#123;a[i"\tsame"]=0&#125; if(!(i"\tdiff" in a))&#123;a[i"\tdiff"]=0&#125; if(!(i"\tsame" in b))&#123;b[i"\tsame"]=0&#125; if(!(i"\tdiff" in b))&#123;b[i"\tdiff"]=0&#125; print i,a[i"\tsame"],a[i"\tdiff"], b[i"\tsame"], b[i"\tdiff"] &#125;&#125;' k562.vs.wgshap.merge.txt | sort -k1,1 -k2,2n &gt; k562.vs.wgshap.merge.2kb.txt 加入位置信息：12345678910awk -v OFS="\t" '!($3=="N" &amp;&amp; $4=="N")&#123;a[$1"\t"int($2/2000)"\t"$3]++; b[$1"\t"int($2/2000)"\t"$4]++; id[$1"\t"int($2/2000)];&#125;END&#123; for(i in id)&#123; if(!(i"\tsame" in a))&#123;a[i"\tsame"]=0&#125; if(!(i"\tdiff" in a))&#123;a[i"\tdiff"]=0&#125; if(!(i"\tsame" in b))&#123;b[i"\tsame"]=0&#125; if(!(i"\tdiff" in b))&#123;b[i"\tdiff"]=0&#125; split(i,pos,"\t");print pos[2]*2000+1,i,a[i"\tsame"],a[i"\tdiff"], b[i"\tsame"], b[i"\tdiff"] &#125;&#125;' k562.vs.wgshap.merge.txt | sort -k2,2 -k1,1n &gt; k562.vs.wgshap.merge.2kb.txt hepG2格式转换1awk -v OFS="\t" '&#123;print "chr"$1,$2,$2+1,$3,$4&#125;' HepG2.haplotyped_across_tumor.passing.clean.txt &gt; HepG2.haplotyped.clean.bed 运行liftover：12[16:19:37] qwzhou@mn02:~/hapvswgs :$ ../liftOver HepG2.haplotyped.clean.bed hg19ToHg38.over.chain.gz HepG2.hapwgs.bed hepG2.unlifted.bed 计算重合度SNP: 72551 7711计算重合度MethSNP: 125816 12258123##脚本与k562过程一致，不再重复记录，只记录文件名这里。HepG2.hapwgs.bed hepG2.snp.hapcut2.haplo.txt &gt; hepG2.snphap.wgshap.txtHepG2.hapwgs.bed hepG2.snpwithmr.p.hapcut2.haplo.txt hepG2.snpwithmr.n.hapcut2.haplo.txt &gt; hepG2.mrsnphap.wgshap.txt 合并文件：12[15:14:49] qwzhou@login:~/practice/hepG2/WGBS :$ awk -v OFS="\t" 'ARGIND==1&#123;a[$1"\t"$2]="N\tN"&#125;ARGIND==2&#123;a[$1"\t"$2]=$3"\tN"&#125;ARGIND==3&#123;split(a[$1"\t"$2],b,"\t"); a[$1"\t"$2]=b[1]"\t"$3&#125;END&#123;for(i in a)&#123;print i,a[i]&#125;&#125;' HepG2.hapwgs.bed hepG2.mrsnphap.wgshap.txt hepG2.snphap.wgshap.txt |sort -k1,1 -k2,2n &gt; hepG2.vs.wgshap.merge.txt 数据太大没法可视化，做进一步处理,加入位置信息：12345678910awk -v OFS="\t" '!($3=="N" &amp;&amp; $4=="N")&#123;a[$1"\t"int($2/2000)"\t"$3]++; b[$1"\t"int($2/2000)"\t"$4]++; id[$1"\t"int($2/2000)];&#125;END&#123; for(i in id)&#123; if(!(i"\tsame" in a))&#123;a[i"\tsame"]=0&#125; if(!(i"\tdiff" in a))&#123;a[i"\tdiff"]=0&#125; if(!(i"\tsame" in b))&#123;b[i"\tsame"]=0&#125; if(!(i"\tdiff" in b))&#123;b[i"\tdiff"]=0&#125; split(i,pos,"\t");print pos[2]*2000+1,i,a[i"\tsame"],a[i"\tdiff"], b[i"\tsame"], b[i"\tdiff"] &#125;&#125;' hepG2.vs.wgshap.merge.txt | sort -k2,2 -k1,1n &gt; hepG2.vs.wgshap.merge.2kb.txt 尝试把间隔放大：awk -v OFS=”\t” ‘!($3==”N” &amp;&amp; $4==”N”){a[$1”\t”int($2/5000)”\t”$3]++; b[$1”\t”int($2/5000)”\t”$4]++; id[$1”\t”int($2/5000)];}END{ for(i in id){ if(!(i”\tsame” in a)){a[i”\tsame”]=0} xif(!(i”\tdiff” in a)){a[i”\tdiff”]=0} if(!(i”\tsame” in b)){b[i”\tsame”]=0} if(!(i”\tdiff” in b)){b[i”\tdiff”]=0} split(i,pos,”\t”);print pos[2]*5000+1,i,a[i”\tsame”],a[i”\tdiff”], b[i”\tsame”], b[i”\tdiff”] }}’ hepG2.vs.wgshap.merge.txt | sort -k2,2 -k1,1n &gt; hepG2.vs.wgshap.merge.5kb.txt因为DNA甲基化单倍型组装是区分正负链的，因此我们去掉重复的位置来统计与WGS hap的重合情况：12awk '&#123;print $1,$2,$3,$4&#125;' hepG2.mrsnphap.wgshap.txt | awk '&#123;if($3=="same")&#123;a[$1" "$2]&#125;else if(!($1" "$2 in a))&#123;b[$1" "$2]&#125;&#125;END&#123;print length(a),length(b)&#125;'125816 3907 wgs hap snp: 370768，其中杂合SNP：182255snp in bs-seq: 1942278snp in bs with wgs hap: 151546snp单倍型with wgs单倍型: 80262, 其中相同以及差异72551 7711mrsnp单倍型with wgs单倍型: 129723，相同差异：125816 3907 ======================================== 拟南芥目录：[10:25:19] qwzhou@login:~/practice/tair_zwang/PM : [150]合并正负链，并输出到bed格式。1awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' BS-cviler.p.hapcut2.haplo.txt BS-cviler.n.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | bedtools merge | less 替换染色体，保持一致，并去掉子类，防止重复。1awk -v OFS="\t" 'sub(/Chr/,"",$1) &amp;&amp; $4!~/transposon_fragment/' TAIR10_Transposable_Elements.bed &gt; TAIR10_Transposable_Elements.replacechr.bed bedtools merge/sort error:Error: Sorted input specified, but the file - has the following out of order record 统计覆盖repeat的数目： DNA甲基化+SNP组装 123[10:56:25] qwzhou@login:~/practice/tair_zwang/PM :$ awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' BS-cviler.p.hapcut2.haplo.txt BS-cviler.n.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge | bedtools intersect -a - -b TAIR10_Transposable_Elements.replacechr.bed -wo | awk '&#123;a[$7]&#125;END&#123;print length(a)&#125;'10927 SNP组装 12awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' BS-cviler.hapcut2.snp.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools intersect -a - -b TAIR10_Transposable_Elements.replacechr.bed -wo | awk '&#123;a[$7]&#125;END&#123;print length(a)&#125;'3890 DNA甲基化+SNP组装 (但是包含SNP) 12awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' BS-cviler.p.hapcut2.haplo.txt BS-cviler.n.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge | bedtools intersect -a - -b BS-cviler.snp.hetero.vcf -wo | awk -v OFS="\t" '&#123;print $1,$2,$3&#125;' |bedtools intersect -a - -b TAIR10_Transposable_Elements.replacechr.bed -wo | awk '&#123;a[$7]&#125;END&#123;print length(a)&#125;'6544 在基因组内的分布123456789101112131415161718192021222324252627[10:32:08] qwzhou@login:~/practice/tair_zwang/PM :$ awk -v OFS="\t" 'gsub(/Chr/,"",$1) &amp;&amp; $3!="chromosome"' ~/practice/Genome/arabidopsis/TAIR10_GFF3_genes.gff &gt; ~/practice/Genome/arabidopsis/TAIR10_GFF3_genes.replacechr.gffawk -v OFS="\t" '&#123;if($7=="+")&#123;if($4&gt;2000)&#123;print $1,$4-2000,$4&#125;else&#123;print $1,1,$4&#125;&#125;else if($7=="-")&#123;print $1,$5,$5+2000&#125; &#125;' ~/practice/Genome/arabidopsis/TAIR10.gene.modify.gff &gt; ~/practice/Genome/arabidopsis/TAIR10.gene.modify.2Kpromoter.bedcat BS-cviler.asm.plus.bed BS-cviler.asm.neg.bed | sort -k1,1 -k2,2n |bedtools merge | bedtools intersect -a - -b ~/practice/Genome/arabidopsis/TAIR10_GFF3_genes.replacechr.gff -f 0.50 -wo | awk '&#123;a[$6" "$7" "$8]&#125;END&#123;for(i in a)&#123;print i&#125;&#125;' | awk '&#123;a[$1]++&#125;END&#123;for(i in a)&#123;print i,a[i]&#125;&#125;'ncRNA 54pseudogene 69exon 4174rRNA 1protein 3195tRNA 3transposable_element_gene 898mRNA_TE_gene 900five_prime_UTR 75three_prime_UTR 133pseudogenic_transcript 69mRNA 3776pseudogenic_exon 61CDS 2932gene 3041Promoter 1890TE 1588cat BS-cviler.asm.plus.bed BS-cviler.asm.neg.bed | sort -k1,1 -k2,2n |bedtools merge | bedtools intersect -a - -b ~/practice/Genome/arabidopsis/TAIR10.gene.modify.2Kpromoter.bed -f 0.50 -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'1890cat BS-cviler.asm.plus.bed BS-cviler.asm.neg.bed | sort -k1,1 -k2,2n |bedtools merge | bedtools intersect -a - -b ~/practice/Genome/arabidopsis/TAIR10_Transposable_Elements.replacechr.bed -f 0.50 -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'1588 ASM在基因上的分布123~/software_devp/methyhaplo/ASManno -o ASMonGene -G ~/practice/Genome/arabidopsis/arabidopsis_batmeth2_index/TAIR10_chr_all.fa -gff ~/practice/Genome/arabidopsis/TAIR10.protein_coding_gene.gff -ap BS-cviler.asm.plus.bed -an BS-cviler.asm.neg.bed [23:11:53] qwzhou@comput54:~/practice/tair_zwang/PM :$ ~/practice/A549_BS/WGBS-HAIR/ASManno -o ASMonGene -G ~/practice/Genome/arabidopsis/arabidopsis_batmeth2_index/TAIR10_chr_all.fa -gff ~/practice/Genome/arabidopsis/TAIR10.protein_coding_gene.gff -ap BS-cviler.asm.plus.bed -an BS-cviler.asm.neg.bed -s 0.01 ASM基因GO分析：12[15:34:17] qwzhou@comput54:~/practice/tair_zwang/PM :$ cat BS-cviler.asm.plus.bed BS-cviler.asm.neg.bed | sort -k1,1 -k2,2n -k3,3n | bedtools merge | bedtools intersect -a - -b ~/practice/Genome/arabidopsis/TAIR10.gene.modify.gff -wo | awk -v OFS="\t" '&#123;print $4,$7,$8,$10,$12&#125;' | awk 'split($NF,a,";") &amp;&amp; sub(/ID=/,"",a[1])&#123;print a[1]&#125;' &gt; BS-cviler.asm.gene.txt A549 HiC SNPsplit根据单倍型结果区分123456[16:30:54] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2 :$ awk -v OFS="\t" '($2==0 || $2==1)&#123;if($2==0)&#123;snp=$6"/"$7&#125;else if($2==1)&#123;snp=$7"/"$6&#125;print ".",$4,$5,"1",snp&#125;' A549.hic.haplotype &gt; A549.hic.haplotype.SNPsplit.vcf## SNPsplit[16:31:16] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2 :$ ~/software/SNPsplit/SNPsplit --hic --snp_file A549.hic.haplotype.SNPsplit.vcf chr2.89771503-89802405.sortbyname.fix.bam A549 ASM分布12345[22:19:57] qwzhou@login:~/practice/Genome/hg38 :$ awk -v OFS="\t" '&#123;if($7=="-")&#123;print $1,$5,"-"&#125;else&#123;print $1,$4,"+"&#125;&#125;' gene.gtf &gt; gene.TSS.ped3[22:16:46] qwzhou@comput54:~/practice/A549_BS/WGBS-HAIR :$ ~/software_devp/methyhaplo/ASMannoSites -o ASMonGeneTSS -G ~/practice/Genome/hg38/batmeth2-chr/hg38.chr.fa --ped ~/practice/Genome/hg38/gene.ped3 -ap A549.newasm.plus.bed -an A549.newasm.neg.bed -s 0.01 统计单倍型长度 DNA甲基化 + SNP 1234awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' BS-cviler.p.hapcut2.haplo.txt BS-cviler.n.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge &gt; BS-cviler.hapcut2.haplo.merge.bed[11:08:48] qwzhou@login:~/practice/tair_zwang/PM :$ awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;' BS-cviler.hapcut2.haplo.merge.bed558 1533 5535 SNP 12awk -v OFS="\t" '$1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0)&#123;print "=== "chr,start,end"\n"inf&#125;;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' BS-cviler.hapcut2.snp.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'14 162 785 DNA甲基化+SNP组装 (但是包含SNP) 12awk -v OFS="\t" 'ARGIND==1&#123;v[$1" "$2]&#125;ARGIND!=1 &amp;&amp; $1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0 &amp;&amp; pp==1)&#123;print "=== "chr,start,end"\n"inf&#125;;pp=0;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0 &amp;&amp; pp==1)&#123;print "=== "chr,start,end"\n"inf&#125;;pp=0;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if($4" "$5 in v)&#123;pp=1&#125;;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' BS-cviler.snp.hetero.vcf BS-cviler.p.hapcut2.haplo.txt BS-cviler.n.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge | awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;'474 1325 4406 统计单倍型总长度 DNA甲基化+SNP (包含SNP)12awk -v OFS="\t" 'ARGIND==1&#123;v[$1" "$2]&#125;ARGIND!=1 &amp;&amp; $1!~/\*/&#123;if($1~/BLOCK/)&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0 &amp;&amp; pp==1)&#123;print "=== "chr,start,end"\n"inf&#125;;pp=0;chr="";start=0;end=0;inf="";&#125;else&#123;if($2=="-")&#123;if(chr!="" &amp;&amp; end&gt;start &amp;&amp; start!=0 &amp;&amp; pp==1)&#123;print "=== "chr,start,end"\n"inf&#125;;pp=0;chr="";start=0;end=0;inf=""&#125;else if($2==0 || $2==1)&#123;if($4" "$5 in v)&#123;pp=1&#125;;if(start==0)&#123;chr=$4;start=$5;inf=$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7&#125;else&#123;inf=inf"\n"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7;if($5&gt;end)&#123;end=$5&#125;&#125;&#125;&#125;&#125;' BS-cviler.snp.hetero.vcf BS-cviler.p.hapcut2.haplo.txt BS-cviler.n.hapcut2.haplo.txt | awk -v OFS="\t" '$1~/^=/&#123;print $2,$3,$4&#125;' | sort -k1,1 -k2,2n -k3,3n | bedtools merge | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'13787280 54362 253.62 统计覆盖在基因组上phased信息首先切割基因组：1awk -v OFS="\t" '&#123;bin=2000;l=1;len=int($2/bin);for(i=0;i&lt;len;i++)&#123;print $1,i*bin+1,(i+1)*bin,l;l++&#125;;if(len*bin &lt; $2)&#123;print $1,len*bin+1, $2,l&#125;&#125;' ~/practice/Genome/arabidopsis/TAIR10_chr_all.fa.fai &gt; TAIR10.splitby2k.bed 处理meth haplo，因为正负链不在一个文件1awk '$1!~/^B/ &amp;&amp; $1!~/^*/&#123;print $4"\t"$5&#125;' BS-cviler.p.hapcut2.haplo.txt BS-cviler.n.hapcut2.haplo.txt | sort -k1,1 -k2,2n &gt; BS-cviler.hapcut2.methsnv.sites.txt 统计phased数目1awk -v OFS="\t" 'ARGIND==1 &amp;&amp; $1!~/^#/&#123;sn[$1"\t"$2]&#125;ARGIND==2&#123;a[$4"\t"int($5/2000+1)]++&#125;ARGIND==3&#123;if($1"\t"$2 in sn)&#123;b[$1"\t"int($2/2000+1)]++&#125;&#125;ARGIND==4&#123;c[$1"\t"int($2/2000+1)]++&#125;ARGIND==5&#123;if($1"\t"$4 in a)&#123;v=a[$1"\t"$4]&#125;else&#123;v=0&#125;; if($1"\t"$4 in b)&#123;mv=b[$1"\t"$4]&#125;else&#123;mv=0&#125;;if($1"\t"$4 in c)&#123;m=c[$1"\t"$4]&#125;else&#123;m=0&#125;; print $1,$4,v,mv,m&#125;' BS-cviler.snp.hetero.vcf BS-cviler.hapcut2.snp.haplo.txt BS-cviler.hapcut2.methsnv.sites.txt BS-cviler.hapcut2.methsnv.sites.txt TAIR10.splitby2k.bed &gt; phased.txt –&gt; 2Kb太短了，换成10Kb1234## split genomeawk -v OFS="\t" '&#123;bin=10000;l=1;len=int($2/bin);for(i=0;i&lt;len;i++)&#123;print $1,i*bin+1,(i+1)*bin,l;l++&#125;;if(len*bin &lt; $2)&#123;print $1,len*bin+1, $2,l&#125;&#125;' ~/practice/Genome/arabidopsis/TAIR10_chr_all.fa.fai &gt; TAIR10.splitby10k.bed## 统计数目awk -v bin=10000 -v OFS="\t" 'ARGIND==1 &amp;&amp; $1!~/^#/&#123;sn[$1"\t"$2]&#125;ARGIND==2&#123;a[$4"\t"int($5/bin+1)]++&#125;ARGIND==3&#123;if($1"\t"$2 in sn)&#123;b[$1"\t"int($2/bin+1)]++&#125;&#125;ARGIND==4&#123;c[$1"\t"int($2/bin+1)]++&#125;ARGIND==5&#123;if($1"\t"$4 in a)&#123;v=a[$1"\t"$4]&#125;else&#123;v=0&#125;; if($1"\t"$4 in b)&#123;mv=b[$1"\t"$4]&#125;else&#123;mv=0&#125;;if($1"\t"$4 in c)&#123;m=c[$1"\t"$4]&#125;else&#123;m=0&#125;; print $1,$4,v,mv,m&#125;' BS-cviler.snp.hetero.vcf BS-cviler.hapcut2.snp.haplo.txt BS-cviler.hapcut2.methsnv.sites.txt BS-cviler.hapcut2.methsnv.sites.txt TAIR10.splitby10k.bed &gt; phased.10k.txt 画线图1234567891011121314151617181920212223242526272829303132a&lt;-read.table(&quot;phased.10k.txt&quot;)names(a)=c(&quot;chr&quot;,&quot;coord&quot;,&quot;SNV&quot;, &quot;MethSNV.SNV&quot;, &quot;MethSNV&quot;)a&lt;-a[a$chr==&quot;1&quot;,]profile_text&lt;-a[c(3,4,5)]library(ggplot2)library(reshape2)profile_text$xvariable = rownames(profile_text)data_m &lt;- melt(profile_text, id.vars=c(&quot;xvariable&quot;))data_m$xvariable &lt;- as.numeric(data_m$xvariable)##线图data_m2&lt;-data_m[data_m$variable!=&quot;MethSNV&quot;,]p &lt;- ggplot(data_m2, aes(x=xvariable, y=value,color=variable,group=variable)) + stat_smooth(method=&quot;auto&quot;, se=FALSE)p +labs(title=&quot;&quot;,x=&quot;&quot;, y = &quot;Phased number&quot;)+ theme_bw() + ## 背景 theme(panel.grid =element_blank()) + ## 删去网格线 theme(plot.title = element_text(hjust = 0.5, size = 18, colour = &quot;black&quot;, face = &quot;bold&quot;) ,axis.title.y = element_text(size=16,colour = &quot;black&quot;,face = &quot;bold&quot;), axis.text.y = element_text(size=10, colour = &quot;black&quot;), axis.text.x = element_text(size=16, colour = &quot;black&quot;), legend.position = c(0.85,0.5))## 箱线图names(a)=c(&quot;chr&quot;,&quot;coord&quot;,&quot;SNV&quot;, &quot;MethSNV.SNV&quot;, &quot;MethSNV&quot;)profile_text&lt;-a[c(3,4,5)]profile_text$xvariable = rownames(profile_text)data_m &lt;- melt(profile_text, id.vars=c(&quot;xvariable&quot;))data_m$xvariable &lt;- as.numeric(data_m$xvariable)data_m2&lt;-data_m[data_m$variable!=&quot;MethSNV&quot;,]data_m2$value &lt;- pmin(data_m2$value,100)pdf(&quot;tet.pdf&quot;)p &lt;- ggplot(data_m2, aes(x=variable, y=value,color=variable,group=variable)) +geom_boxplot()pdev.off() 统计meth+HiC合并后的长度分布12345678910111213141516171819./bshichap HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2/A549.hic.haplotype WGBS-HAIR/A549.snpwithmr.p.hapcut2.haplo.txt &gt; A549.hapmerge.txt./bshichap HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2/A549.hic.haplotype WGBS-HAIR/A549.snpwithmr.n.hapcut2.haplo.txt &gt; A549.hapmerge.n.txtawk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^=/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' A549.hapmerge.txt A549.hapmerge.n.txt | sort -k1,1 -k2,2n -k3,3n | bedtools merge | awk '&#123;a+=($3-$2);b++&#125;END&#123;print a,b,a/b&#125;'742297819 1630041 455.386 统计与repeat的覆盖情况123456789101112131415161718awk -v OFS="\t" 'BEGIN&#123;a=0;b=0;chr=""&#125;&#123; if($1~/^=/)&#123; if(b&gt;a)&#123;print chr,a,b;a=0;b=0;chr="";&#125; else&#123;a=0;b=0;chr="";&#125; &#125; else if(a==0)&#123; chr=$1;a=$2;b=$2 &#125;else&#123; if($2&gt;b+3000)&#123; if(b&gt;a)&#123;print chr,a,b; a=$2;b=$2;chr=$1&#125; &#125;else if($2&gt;b)&#123; b=$2 &#125; &#125;&#125;END&#123;if(b&gt;a)&#123;print chr,a,b&#125;&#125;' A549.hapmerge.txt A549.hapmerge.n.txt | sort -k1,1 -k2,2n -k3,3n | bedtools merge &gt; A549.hapmerge.split3k.txtbedtools intersect -a A549.hapmerge.split3k.txt -b ~/practice/Genome/hg38/hg38.fa.out.repeat -wo | awk '&#123;a[$4" "$5" "$6]&#125;END&#123;print length(a)&#125;'2150406 统计长度：12awk '&#123;if($3-$2&gt;2000)&#123;a++&#125;else if($3-$2&gt;1000)&#123;b++&#125;else if($3-$2&gt;500)&#123;c++&#125;&#125;END&#123;print a,b,c&#125;' A549.hapmerge.split3k.txt41571 38724 142570 A549 单倍型间隔，在HiC中的情况123456$ samtools view -h A549.allmerge.sort.bam chr2:89771503-89802405 | samtools sort -o chr2.89771503-89802405.sort.bam -[10:25:40] qwzhou@login:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2 :$ samtools view -h chr2.89771503-89802405.sort.bam |less[10:26:01] qwzhou@login:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2 :$ samtools index chr2.89771503-89802405.sort.bam##这个区间不行 区间2:12samtools view -h A549.allmerge.sort.bam chr1:125147238-125170518 | samtools sort -n - | samtools view -h | awk '$1~/^@/ || ($7=="=" &amp;&amp; $8&gt;125147238-150 &amp;&amp; $8&lt;125170518+150)' | samtools view -hbS -o chr1.125147238-125170518.sortbyname.bam -##这个区间不行 区间3:12samtools view -h A549.allmerge.sort.bam chr17:21850913-26796347 | samtools sort -n - | samtools view -h | awk '$1~/^@/ || ($7=="=" &amp;&amp; $8&gt;21850913-150 &amp;&amp; $8&lt;26796347+150)' | samtools view -hbS -o chr17.21850913-26796347.sortbyname.bam -###区间不行 区间4:12 samtools view -h A549.allmerge.sort.bam chr9:43317096-43348509 | samtools sort -n - | samtools view -h | awk '$1~/^@/ || ($7=="=" &amp;&amp; $8&gt;43317096-150 &amp;&amp; $8&lt;43348509)' | samtools view -hbS -o chr9.43317096-43348509.sortbyname.bam -###区间不同 区间5:12samtools view -h A549.allmerge.sort.bam chr20:29263493-29295290 | samtools sort -n - | samtools view -h | awk '$1~/^@/ || ($7=="=" &amp;&amp; $8&gt;29263493-150 &amp;&amp; $8&lt;29295290)' | samtools view -hbS -o chr20.29263493-29295290.sortbyname.bam -####不行 区间612samtools view -h A549.allmerge.sort.bam chr21:9035909-9342756 | samtools sort -n - | samtools view -h | awk '$1~/^@/ || ($7=="=" &amp;&amp; $8&gt;9035909-150 &amp;&amp; $8&lt;9342756)' | samtools view -hbS -o chr21.9035909-9342756.sortbyname.bam -##不行 区间712samtools view -h A549.allmerge.sort.bam chr16:34896690-34921521 | samtools sort -n - | samtools view -h | awk '$1~/^@/ || ($7=="=" &amp;&amp; $8&gt;34896690-150 &amp;&amp; $8&lt;34921521)' | samtools view -hbS -o chr16.34896690-34921521.sortbyname.bam -##不行 筛选长的相邻排序：1awk -v OFS="\t" '&#123;print $3-$2,$1,$2,$3,$4&#125;' A549.hapcut.bed | awk '$1&gt;5000' | sort -k2,2 -k3,3n -k1,1nr |less chr15可以 A549 SNP数目123456789[14:28:03] qwzhou@login:~/practice/A549_BS/WGBS-HAIR :$ awk '$2==0 || $3==0' A549.onlysnp.hapcut2.haplo.txt | wc -l866162[14:44:59] qwzhou@login:~/practice/A549_BS/WGBS-HAIR :$ awk 'ARGIND==1 &amp;&amp; $NF~/0\/1/ &amp;&amp; $1!~/^#/&#123;a[$1" "$2]&#125;ARGIND!=1 &amp;&amp; ($2==0 || $2==1)&#123;if($4" "$5 in a)&#123;d[$4" "$5]&#125;&#125;END&#123;print length(d)&#125;' wgbs.new.replace.mdups.snp.filtered.sort.vcf A549.snpwithmr.p.hapcut2.haplo.txt A549.snpwithmr.n.hapcut2.haplo.txt1261123[14:31:23] qwzhou@login:~/practice/A549_BS/WGBS-HAIR :$ awk '$NF~/0\/1/' wgbs.new.replace.mdups.snp.filtered.sort.vcf |wc -l1618244 SNP比例：866162/1618244=53.5%DNA甲基化组装中SNP比例：1261123/1618244=77.9% 123## A549 合并甲基化单倍型[16:13:39] qwzhou@mn02:~/project/methhap/WGBS/A549 :$ ../bsmerge A549.snpwithmr.p.hapcut2.haplo.txt A549.snpwithmr.n.hapcut2.haplo.txt &gt; A549.snpwithmr.merge.haplo.txt 相关文章Chen, Z., Hagen, D. E., Ji, T., Elsik, C. G., &amp; Rivera, R. M. (2017). Global misregulation of genes largely uncoupled to DNA methylome epimutations characterizes a congenital overgrowth syndrome. Scientific reports, 7(1), 12667. doi:10.1038/s41598-017-13012-z 值得注意的是，在骨骼肌中，参与成肌细胞增殖和肌管融合的多种途径在LOS胎儿中被错误调节。此外，骨骼肌DNA甲基组的特征表明LOS和对照组之间存在许多局部甲基化差异；然而，只有一小部分差异表达基因（DEG），包括印记基因IGF2R，可能与相邻的差异甲基化区域有关。总之，我们不仅表明非印记基因的错误调节和印记缺失是ART诱导的过度生长综合征的特征，而且证明大多数DEG与DNA甲基体表观突变没有直接关联。 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5477265/ Hap-ASM https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5320668/ Vincent, M., Mundbjerg, K., Skou Pedersen, J., Liang, G., Jones, P. A., Ørntoft, T. F., … Wiuf, C. (2017). epiG: statistical inference and profiling of DNA methylation from whole-genome bisulfite sequencing data. Genome biology, 18(1), 38. doi:10.1186/s13059-017-1168-4 DNA甲基化单倍型与核小体占有率 Cheung, W. A., Shao, X., Morin, A., Siroux, V., Kwan, T., Ge, B., … Grundberg, E. (2017). Functional variation in allelic methylomes underscores a strong genetic contribution and reveals novel epigenetic alterations in the human epigenome. Genome biology, 18(1), 50. doi:10.1186/s13059-017-1173-7 七百多个样本检测ASM与表型相关的基因。 Marzi, S. J., Meaburn, E. L., Dempster, E. L., Lunnon, K., Paya-Cano, J. L., Smith, R. G., … Mill, J. (2016). Tissue-specific patterns of allelically-skewed DNA methylation. Epigenetics, 11(1), 24–35. doi:10.1080/15592294.2015.1127479 虽然DNA甲基化通常被认为是对称的两个等位基因，但也有一些值得注意的例外。基因组印记和X染色体失活是等位基因特异性甲基化（ASM）的两个被广泛研究的来源，但最近的研究表明，更复杂的模式，即基因型变异可能与顺式结构中等位基因偏斜的DNA甲基化有关。鉴于已知的跨组织和细胞类型的DNA甲基化的异质性，我们研究了人脑的几个区域和来自多个个体的全血中ASM的个体间和个体内变异。与以前的研究一致，我们发现广泛的ASM，在被询问的22万个位点中有4%以上的位点显示出等位基因甲基化的证据。我们确定了ASM侧翼已知的印记区域，并表明ASM位点富含dnase I超敏位点，通常位于中间DNA甲基化的扩展基因组背景中。我们还发现了基因型驱动的ASM的例子，其中一些是组织特异性的。这些发现有助于我们理解组织间差异DNA甲基化的性质，并对复杂疾病的遗传学研究具有重要意义。作为社区的一种资源，所研究的每个组织的ASM模式都可以在一个可搜索的在线数据库中找到：http://epigenemics.essex.ac.uk/asmbranblood。 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5373555/ Li, W., Xu, W., Fu, G., Ma, L., Richards, J., Rao, W., … Song, Q. (2015). High-accuracy haplotype imputation using unphased genotype data as the references. Gene, 572(2), 279–284. doi:10.1016/j.gene.2015.07.082 大量增长的基因组数据集对缺失的数据输入提出了新的挑战，这是一项众所周知的资源需求任务。单倍型需要种族匹配的参考。然而，迄今为止，在世界上大多数人口中没有单倍型参考。我们试图利用现有的非相位基因型（这是啥？）数据作为参考；如果成功，它将覆盖世界上几乎所有的种群。结果表明，我们的hifi软件成功地获得了99.43%的准确率，与无相基因型参考。该方法为突破大数据时代单倍型插补参考可用性有限的瓶颈提供了一种经济有效的解决方案。 单倍型的重要性 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4254418/ Glusman, G., Cox, H. C., &amp; Roach, J. C. (2014). Whole-genome haplotyping approaches and genomic medicine. Genome medicine, 6(9), 73. doi:10.1186/s13073-014-0073-7 报道的单倍型而非基因型的基因组信息对于个体化医学将越来越重要。目前的技术产生的二倍体序列数据很少被分解成其组成的单倍型。此外，考虑基因组信息的范例是基于解释基因型而不是单倍型。然而，单倍型在历史上一直是有用的背景下，从群体遗传学到疾病基因绘图的努力。分阶段基因组序列数据的主要方法是分子单倍体、遗传单倍体和基于人群的推断。长读测序技术使分子单倍型更长，而全基因组测序成本的降低使全染色体遗传单倍型测序成为可能。混合方法结合了高吞吐量短读汇编和战略方法，使物理或虚拟分块的读单倍型是使多基因单倍型产生的单个个体。这些技术可以与遗传和种群方法进一步结合。在这里，我们回顾了全基因组单倍体方法的进展，并讨论了单倍体在基因组医学中的重要性。临床应用包括通过识别复合杂合子和分阶段调节变异编码变异来诊断。单倍型比单核苷酸变异体等不太复杂的变异体更具特异性，在预后和诊断、肿瘤分析和移植组织分型中也有应用。未来的进展将包括技术创新，应用标准指标评估单倍型质量，以及开发将单倍型与疾病联系起来的数据库。]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>methhap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project_log]]></title>
    <url>%2F2019%2F03%2F19%2Fproject-log%2F</url>
    <content type="text"><![CDATA[temp work need to finishDNA甲基化单倍型拟南芥F11. 单倍型长度 2. 覆盖repeat数目 3. ASM HepG2 K562 WGS单倍型HiC + WGBS 单倍型整合HiC-DNA甲基化 单倍型DNA甲基化数据库根据excel RNAseq与BSseq对应关系，测试数据。DNA甲基化SNP检测想法： 每条read的信息； readid pos var 忘记了 😂， 在冲锋衣口袋里]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伯努利分布、二项式分布、beta分布、bayesian]]></title>
    <url>%2F2019%2F03%2F07%2Fstatics-distribution%2F</url>
    <content type="text"><![CDATA[1. 伯努力分布 (Bernoulli distribution)伯努利分布及两点分布，0-1分布。伯努利分布结果只能是两种情况，例如抛硬币。 如果独立重复n次，则称为n重伯努利。伯努利分布属于离散型概率分布。 2. 二项式分布 (Binomial distribution)伯努利分布是二项式分布在n=1时的特例，n表示重复次数。 二项分布的典型例子是扔硬币，硬币正面朝上概率为p, 重复n次，k次为正面的概率即为一个二项分布概率。 k~B(n,p) 3. 多项分布 多项式分布(Multinomial Distribution)是二项式分布的推广。二项式做n次伯努利实验，规定了每次试验的结果只有两个，如果现在还是做n次试验，只不过每次试验的结果可以有多m个，且m个结果发生的概率互斥且和为1，则发生其中一个结果X次的概率就是多项式分布。 扔骰子是典型的多项式分布。]]></content>
      <categories>
        <category>统计</category>
      </categories>
      <tags>
        <tag>伯努利分布</tag>
        <tag>二项式分布</tag>
        <tag>beta分布</tag>
        <tag>贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paper]]></title>
    <url>%2F2018%2F12%2F27%2Fpaper%2F</url>
    <content type="text"><![CDATA[1st2018An Integrated Package for Bisulfite DNA Methylation Data Analysis with Indel-sensitive Mapping 2016Tan, F., Zhou, C., Zhou, Q., Zhou, S., Yang, W., Zhao, Y., Li, G., … Zhou, D. X. (2016). Analysis of Chromatin Regulators Reveals Specific Features of Rice DNA Methylation Pathways. Plant physiology, 171(3), 2041-54. other2018Zhou, C., Wang, C., Liu, H., Zhou, Q., Liu, Q., Guo, Y., Peng, T., Song, J., Zhang, J., Chen, L., Zhao, Y., Zeng, Z., Zhou, D.-X., 2018. Identification and analysis of adenine N6-methylation sites in the rice genome. Nature Plants 4, 554-563. 2016Zhou, S., Liu, X., Zhou, C., Zhou, Q., Zhao, Y., Li, G., &amp; Zhou, D. X. (2016). Cooperation between the H3K27me3 Chromatin Mark and Non-CG Methylation in Epigenetic Regulation. Plant physiology, 172(2), 1131-1141. 2014Li, G., Cai, L., Chang, H., Hong, P., Zhou, Q., Kulakova, E. V., Kolchanov, N. A., … Ruan, Y. (2014). Chromatin Interaction Analysis with Paired-End Tag (ChIA-PET) sequencing technology and application. BMC genomics, 15 Suppl 12(Suppl 12), S11.]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>workfinished</category>
      </categories>
      <tags>
        <tag>bioinformatics</tag>
        <tag>workfinished</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20181225]]></title>
    <url>%2F2018%2F12%2F25%2F20181225%2F</url>
    <content type="text"><![CDATA[HapCut2 methylationF123 WGBS123456789[11:12:27] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ awk -v OFS="\t" '$3=="+" &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,".\tC\tT\t600\tPASS\t.\tGT\t0/1"&#125;' F123bt2.methratio.txt &gt; methyF123.mr.methratio.p.txt[11:27:05] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ awk -v OFS="\t" '$3=="-" &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,".\tG\tA\t600\tPASS\t.\tGT\t0/1"&#125;' F123bt2.methratio.txt &gt; methyF123.mr.methratio.n.txt[11:40:03] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ cat ../methyHic/GSE48592_castx129_variants.mm10.vcf methyF123.mr.methratio.n.txt &gt; methyF123.snpwithmr.n.vcf[11:42:46] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ cat ../methyHic/GSE48592_castx129_variants.mm10.vcf methyF123.mr.methratio.p.txt &gt; methyF123.snpwithmr.p.vcf sort merged vcf12345[11:46:23] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ sh run.sortvcf.sh methyF123.snpwithmr.n.vcf methyF123.snpwithmr.n.sort.vcf[11:46:23] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ sh run.sortvcf.sh methyF123.snpwithmr.p.vcf methyF123.snpwithmr.p.sort.vcf 只运行chr1：123456789101112131415161718[14:17:00] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ awk '$1~/^#/ || $1=="chr1"' methyF123.snpwithmr.p.sort.vcf &gt; methyF123.snpwithmr.p.sort.chr1.vcf[14:17:29] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ awk '$1~/^#/ || $1=="chr1"' methyF123.snpwithmr.n.sort.vcf &gt; methyF123.snpwithmr.n.sort.chr1.vcf###plus[11:43:55] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ ~/software/HapCUT2/build/extractHAIRS --hic 1 --bam F123.align.sort.p.bam --VCF methyF123.snpwithmr.p.sort.chr1.vcf --out methyF123.methsnv.p.chr1.fragment_file[09:33:13] qwzhou@node62:~/practice/mus_hic_mth/wgbs :$ ~/software/HapCUT2/build/HAPCUT2 --hic 1 --fragments methyF123.methsnv.p.chr1.fragment_file --vcf methyF123.snpwithmr.p.sort.chr1.vcf --output methyF123.methsnv.p.haplo.chr1.txt##neg[22:29:44] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ ~/software/HapCUT2/build/extractHAIRS --hic 1 --bam F123.align.sort.n.bam --VCF methyF123.snpwithmr.n.sort.chr1.chr1.vcf --out methyF123.methsnv.n.chr1.fragment_file[09:35:27] qwzhou@node62:~/practice/mus_hic_mth/wgbs :$ ~/software/HapCUT2/build/HAPCUT2 --hic 1 --fragments methyF123.methsnv.n.chr1.fragment_file --vcf methyF123.snpwithmr.n.sort.chr1.vcf --output methyF123.methsnv.n.chr1.haplo.txt hapcut2plus12345[11:43:55] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ ~/software/HapCUT2/build/extractHAIRS --hic 1 --bam F123.align.sort.p.bam --VCF methyF123.snpwithmr.p.sort.vcf --out methyF123.methsnv.p.fragment_file[09:33:13] qwzhou@node62:~/practice/mus_hic_mth/wgbs :$ ~/software/HapCUT2/build/HAPCUT2 --hic 1 --fragments methyF123.methsnv.p.fragment_file --vcf methyF123.snpwithmr.p.sort.vcf --output methyF123.methsnv.p.haplo.txt neg12345[22:29:44] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ ~/software/HapCUT2/build/extractHAIRS --hic 1 --bam F123.align.sort.n.bam --VCF methyF123.snpwithmr.n.sort.vcf --out methyF123.methsnv.n.fragment_file[09:35:27] qwzhou@node62:~/practice/mus_hic_mth/wgbs :$ ~/software/HapCUT2/build/HAPCUT2 --hic 1 --fragments methyF123.methsnv.n.fragment_file --vcf methyF123.snpwithmr.n.sort.vcf --output methyF123.methsnv.n.haplo.txt F123 methyHiCSNP format123456789101112[22:32:05] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ awk -v OFS=&quot;\t&quot; &apos;$3==&quot;+&quot; &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,&quot;.\tC\tT\t600\tPASS\t.\tGT\t0/1&quot;&#125;&apos; methyHiC.mr.methratio.txt &gt; methyHiC.mr.methratio.p.txt[22:40:51] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ awk -v OFS=&quot;\t&quot; &apos;$3==&quot;-&quot; &amp;&amp; $6&gt;=10 &amp;&amp; ($7&gt;=0.2 &amp;&amp; $7&lt;=0.8)&#123;print $1,$2,&quot;.\tG\tA\t600\tPASS\t.\tGT\t0/1&quot;&#125;&apos; methyHiC.mr.methratio.txt &gt; methyHiC.mr.methratio.n.txt[22:50:56] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ cat GSE48592_castx129_variants.mm10.vcf methyHiC.mr.methratio.n.txt &gt; methyHiC.snpwithmr.n.vcf[22:51:52] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ cat GSE48592_castx129_variants.mm10.vcf methyHiC.mr.methratio.p.txt &gt; methyHiC.snpwithmr.p.vcf[22:55:22] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ sh run.sortvcf.sh methyHiC.snpwithmr.n.vcf methyHiC.snpwithmr.n.sort.vcf[23:07:29] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ sh run.sortvcf.sh methyHiC.snpwithmr.p.vcf methyHiC.snpwithmr.p.sort.vcf methyHiC hapcutplus12345[22:29:44] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ ~/software/HapCUT2/build/extractHAIRS --hic 1 --bam methyHiC.sort.p.bam --VCF methyHiC.snpwithmr.p.sort.vcf --out methyHiC.methsnv.p.fragment_file[09:33:13] qwzhou@node62:~/practice/mus_hic_mth/methyHic :$ ~/software/HapCUT2/build/HAPCUT2 --hic 1 --v 1 --t 80 --fragments methyHiC.methsnv.p.fragment_file --vcf methyHiC.snpwithmr.p.sort.vcf --output methyHiC.methsnv.p.haplo.txt neg12345[22:29:44] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ ~/software/HapCUT2/build/extractHAIRS --hic 1 --bam methyHiC.sort.n.bam --VCF methyHiC.snpwithmr.n.sort.vcf --out methyHiC.methsnv.n.fragment_file[09:35:27] qwzhou@node62:~/practice/mus_hic_mth/methyHic :$ ~/software/HapCUT2/build/HAPCUT2 --hic 1 --v 1 --t 80 --fragments methyHiC.methsnv.n.fragment_file --vcf methyHiC.snpwithmr.n.sort.vcf --output methyHiC.methsnv.n.haplo.txt 12]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F24%2FBSNPS%2F</url>
    <content type="text"><![CDATA[Bisulfite-seq Single Nucleotide Polymorphism Scan/Calling (BSNPS/BSNPC)Results 1 [Sample: HUES64]workdir: [14:45:13] qwzhou@login:~/practice/HUES64/test data: HUES64 Tested chromosome: chr1 WGSfilename: wgs.snp.all.default.vcf SNP: 285348 WGBSbssnperfilename: ~/../hhwang/HUES64_re/bssnper/HUES64.SNP.out SNP: 185617 bissnpfilename: [14:32:19] qwzhou@comput54: ~/practice/HUES64/tes/wgbs.replace.sort.snp.filtered.sort.vcf SNP: 134547 Overlap between WGS and WGBS Tools number of SNPs overlap with WGS BS-SNPer 185617 118307 (63.7%) BiS-SNP 134547 116521 (86.6%) WGS 285348 new-bsnps-v0.1Modify: bayes genotype function, likehood function. Genotype: Bayesian modeling $P(G|D)$ $P(G|D) = P(G) * P(D|G) / P(D)$ The prior distribution of the genotype: $P(G)$ Likelihood: $P(D|G)$, probability of observing reads $D$ given genotype $G$ $P(D│G)= ∏^n_{(i=1)}P(D_i |G)$ Where $i=1, 2, …, n$, and n is the number of reads. Genotypes: $AA, AT, AC, AG, TT, TC, TG, CC, CG, GG​$ Available base in BS-seq data: Base Waston Crick T T T C Cm / Tu C A A A G G Gm / Au BS-Seq data table of waston and crick bases in the sequencing read. m stands for methylated and u stands for unmethylated. We can see if there is a conflict between different bases according to this table, then calculated the mutation probability. For example, if we want to calculate the mutation probability of C to T, it can be seen that both C and T have T in the waston strand, as shown in the following table. We mark the conflicting information in blue and available information in red. Therefore, the C to T mutation probability formula is: $crickT / ( crickT + crickC)$. BaseWastonCrick C Cm / Tu C T T T lilelihood functionThe likelihood function need consider bisulfite treatment in BS-Seq data. The details showed in below: P: probability of the corresponding base call is correct Q: probability of the corresponding base call is incorrect wN: waston strand, N is A/T/C/G cN: crick strand, N is A/T/C/G 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091、AAif(wA&gt;0 and ref==&apos;G&apos;)&#123; AA = wA*P + （cT+wT+wC+cC+wG+cG）*Q&#125;if((wA&gt;0 || cA&gt;0) &amp;&amp; ref!=G)&#123; AA = (wA + cA)*P + （cT+wT+wC+cC+wG+cG）*Q&#125;2、GG if（(wG&gt;0|| cG&gt;0 || cA&gt;0) &amp;&amp; ref=!A）&#123; GG = (wG+cG+cA)*P + (wA+cT+wT+cC+wC)*Q;&#125;if(（wG&gt;0 || cG&gt;0）&amp;&amp; ref==A)&#123; GG = (wG+cG)*P + (wA+cT+wT+cC+wC)*Q;&#125;3、TTif(cT&gt;0 &amp;&amp; ref==C)&#123; TT= cT*P+ (wA+cC+wG+cG+wC+cA)*Q;&#125;if((wT&gt;0 || cT&gt;0)&amp;&amp; ref!=C)&#123; TT= (wT+cT）*P+ (wA+cC+wG+cG+wC+cA)*Q;&#125;4、CCif((cC&gt;0 || wC&gt;0) &amp;&amp; ref==T)&#123; CC = (cC+wC)*P + (wA+cA+cT+wG+cG)*Q;&#125;if((cC&gt;0 || wC&gt;0 || wT&gt;0) &amp;&amp; ref !=T)&#123; CC = (cC+wC+wT)*P + (wA+cA+cT+wG+cG)*Q;&#125;5、ACif(（wA&gt;0|| cA&gt;0）&amp;&amp;ref！=“G”)&#123; if((cC&gt;0 || wC&gt;0) &amp;&amp; ref==T)&#123; AC=(cC+wC+wA+cA)*P+(cT+wG+cG)*Q &#125; if((cC&gt;0 || wC&gt;0 || wT&gt;0) &amp;&amp; ref !=T)&#123; AC=(cC+wC+wT+wA+cA)*P+(cT+wG+cG)*Q &#125;&#125;if(wA&gt;0&amp;&amp;ref==“G”)&#123; if((cC&gt;0 || wC&gt;0 || wT&gt;0))&#123; AC=(cC+wC+wT+wA)*P+(cT+wG+cG)*Q &#125;&#125;6、AGif( (wA&gt;0|| cA&gt;0) &amp;&amp; ref != G)&#123; if（cG&gt;0 || wG&gt;0）&#123; AG = (wA +cA+ wG + cG)*P + （cC+cT+wC+ wT）*Q &#125;&#125;if(wA&gt;0 &amp;&amp; ref == G)&#123; if（cG&gt;0 || wG&gt;0）&#123; AG = (wA + wG + cG)*P + （cC+cT+wC+ wT）*Q &#125;&#125;7、ATif((wA&gt;0 || cA&gt;0)&amp;&amp;ref !=G)&#123; if((wT &gt;0 || cT&gt;0)&amp;&amp; ref=!=C)&#123; AT = (wA+cA+wT+cT)*P + （cC+wG+wC+cG）*Q &#125; if(cT&gt;0 &amp;&amp; ref!==C)&#123; AT = (wA+cA+cT)*P + （cC+wG+wC+cG）*Q &#125;&#125;if(wA&gt;0 &amp;&amp; ref ==G)&#123; if(wT&gt;0 || cT&gt;0)&#123; AT = (wA+wT+cT)*P + （cC+wG+wC+cG）*Q &#125;&#125;8、TCif(cT&gt;0 &amp;&amp; ref==“C”)&#123; if(wC&gt;0 || cC&gt;0)&#123; TC=(wC+cT+cC)*P + (wA+wG+cG+cA)*Q; &#125;&#125;if(（cT&gt;0||wT&gt;0）&amp;&amp;ref!=“C”)&#123; if(wC&gt;0 || cC&gt;0)&#123; TC= (wC+wT+cT+cC)*P + (wA+wG+cG+cA)*Q; &#125;&#125;9、TGif((cT&gt;0||wT&gt;0)&amp;&amp;ref !=C )&#123; if(（wG&gt;0 || cG&gt;0|| cA&gt;0）&amp;&amp; ref !=A)&#123; TG= (cT+wT+wG+cG+cA) * P + (wA+cC+wC)*Q; &#125; if(（wG&gt;0 || cG&gt;0）&amp;&amp; ref ==A)&#123; TG= (cT+wT+wG+cG) * P + (wA+cC+wC)*Q; &#125;&#125;if(cT&gt;0 &amp;&amp; ref==“C”)&#123; if(wG&gt;0 || cG&gt;0||cA&gt;0)&#123; TG=(cT+wG+cG+cA) * P + (wA+cC+wC)*Q; &#125;&#125;10、CGif((cC&gt;0 || wC&gt;0) &amp;&amp; ref==T )&#123; CG= (cC+wG+wC+cG+cA)*P + (wA+cT)*Q;&#125;if((cC&gt;0 || wC&gt;0 || wT&gt;0) &amp;&amp; ref !=T)&#123; if((wG&gt;0 || cG&gt;0||wT&gt;0) &amp;&amp; ref==A)&#123; CG= (cC+wG+wC+cG+wT)*P + (wA+cT)*Q; &#125; if((wG&gt;0 || cG&gt;0||cA&gt;0) &amp;&amp; ref !=A)&#123; CG= (cC+wG+wC+cG+ wT+cA)*P + (wA+cT)*Q; &#125;&#125; Filename: SNP.out SNP: 331110 Tools number of SNPs overlap with WGS BS-SNPer 185617 118307 (63.7%) newBSNPSv0.1 331110 139565 (42.1%) BiS-SNP 134547 116521 (86.6%) WGS 285348 new-bsnps-v0.2Modify: allowed max error rate 0.02 in per read. Tools number of SNPs overlap with WGS BS-SNPer 185617 118307 (63.7%) BSNPSv0.2 254706 134720 (52.9%) BiS-SNP 134547 116521 (86.6%) WGS 285348 new-bsnps-v0.3Modify: add pvalue by fisher’s exact test float fishers_exact(int expValue1, int expValue2, int obsValue1, int obsValue2) Calculates significance of variants Parameters: expValue1 - Total reads depth * Q expValue2 - Total reads depth 1th of variant (observed) obsValue2 - Total reads depth (observed) Returns: double, P-value from Fisher’s Exact Test Q: probability of sequence error, $0.1^{(AverQual/10)}/3​$ Tools number of SNPs overlap with WGS BS-SNPer 185617 118307 (63.7%) BSNPSv0.3 130148 120189 (92.3%) BiS-SNP 134547 116521 (86.6%) WGS 285348 new-bsnps-v0.4Modify: fix some bugs in genotype function Tools number of SNPs overlap with WGS BS-SNPer 185617 118307 (63.7%) BSNPSv0.4 139347 126704 (90.9%) BiS-SNP 134547 116521 (86.6%) WGS 285348 new-bsnps-v0.5Modify: 1, If variant position filter quality is Low, we also can set AD&gt;minvarread, ALFR&gt;minvarrate, pvalue &lt; pvalue_cutoff + 0.01 as PASS. AD, Total allelic depths ALFR, Allele frequency default, set minvarread = 5, minvarrate = 0.3. 1234567[12:39:37] qwzhou@login:~/software/BSsnpscan : $ awk '$1=="chr1" &amp;&amp; $7=="Low"' ~/practice/HUES64/test/chr1.mpall.vcf | awk 'split($8,a,";") &amp;&amp; split($10,b,":") &amp;&amp; gsub(/AD=/,"",a[5]) &amp;&amp; a[5]&gt;5 &amp;&amp; b[5]&gt;0.3 &amp;&amp; b[2]&lt;0.06&#123;print $1" "$2&#125;' |wc -l9882[12:39:06] qwzhou@login:~/software/BSsnpscan : $ awk '$1=="chr1" &amp;&amp; $7=="Low"' ~/practice/HUES64/test/chr1.mpall.vcf | awk 'split($8,a,";") &amp;&amp; split($10,b,":") &amp;&amp; gsub(/AD=/,"",a[5]) &amp;&amp; a[5]&gt;5 &amp;&amp; b[5]&gt;0.3 &amp;&amp; b[2]&lt;0.06 &#123;print $1"\t"$2&#125;' | awk 'ARGIND==1 &#123;a[$1" "$2]=$0&#125;ARGIND==2 &amp;&amp; $1=="chr1" &amp;&amp; $7=="PASS"&#123;if($1" "$2 in a)&#123;print a[$1" "$2]&#125;&#125;' - ~/practice/HUES64/test/wgs.snp.all.default.vcf |wc -l9212 if AD&gt;minvarread, ALFR&gt;minvarrate, pvalue &lt; pvalue_cutoff + 0.01 is true: ​ 9882 validated by WGS: ​ 9212 (93.2%) Modify: 2, add multi-thread Modify: 3, t test Results: Tools number of SNPs overlap with WGS BS-SNPer 185617 118307 (63.7%) BSNPSv0.5 152387 138908 (91.2%) BSNPS (with bis-snp realign and recall bam) 153972 141836 (92.1%) BiS-SNP 134547 116521 (86.6%) Bis-SNP (realign + recall) 145649 136946 (94.0%) WGS 285348 Used time Tools Thread x1 (hours) Thread x4 (hours) BS-SNPer 5.1 N BSNPSv0.5 2.3 0.56 BiS-SNP 152.1 64.2 BiS-SNP (realign + recall) 160.2 h Results 2 [Sample: GM12878]WGS SNP from 1000 project (Ilmn150bp300x) （GATK） v0.3 Tools number of SNPs overlap with WGS BS-SNPer 339259 221805 (65.4%) BSNPSv0.3 237500 217722 (91.7%) BiS-SNP 244473 205843 (84.2%) WGS 336372 v0.4 Tools number of SNPs overlap with WGS BS-SNPer 339259 221805 (65.4%) BSNPSv0.3 241408 220526 (91.3%) BiS-SNP 244473 205843 (84.2%) WGS 336372 v0.5 Tools number of SNPs overlap with WGS BS-SNPer 339259 221805 (65.4%) BSNPSv0.5 249575 227862 (91.3%) BiS-SNP 244473 205843 (84.2%) WGS 336372 Used time### Tools Thread x1 (hours) Thread x4 (hours) BS-SNPer 7.2 N BSNPSv0.5 2.8 0.95 BiS-SNP not finished (only finished chr1) not finished Others: scripts used to count overlapHUES641234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586[14:40:39] qwzhou@comput54:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"' wgs.snp.all.default.vcf |wc -l285348[12:09:25] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"' SNP.out |wc -l331110[15:06:45] qwzhou@comput54:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"&#123;print $1"_"$2&#125;' wgbs.replace.sort.snp.filtered.sort.vcf &gt; bisnp.chr1.txt[15:08:37] qwzhou@comput54:~/practice/HUES64/test : $ less Csnp.txt [15:13:56] qwzhou@comput54:~/practice/HUES64/test : $ less Cchr1.new.txt [15:15:24] qwzhou@comput54:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" &amp;&amp; $5&lt;0.05 ' Cchr1.new.txt |wc -l130148[15:15:47] qwzhou@comput54:~/practice/HUES64/test : $ less SNP.log [15:17:17] qwzhou@comput54:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" ' Cchr1.new.txt |wc -l254706[15:18:05] qwzhou@comput54:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" ' Cchr1.txt |wc -l346875[15:18:18] qwzhou@comput54:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" &amp;&amp; $1=="chr1"&#123;print $1"_"$2&#125;' Cchr1.new.txt &gt; newBsnpsV0.2.txt[15:20:35] qwzhou@comput54:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" &amp;&amp; $5&lt;0.05 &amp;&amp; $1=="chr1"&#123;print $1"_"$2&#125;' Cchr1.new.txt &gt; newBsnpsV0.3.txt[15:20:54] qwzhou@comput54:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" &amp;&amp; $5&lt;0.05 &amp;&amp; $1=="chr1"&#123;print $1"_"$2&#125;' chr1.new2chr1.txt &gt; newBsnpsV0.4.txt[15:22:40] qwzhou@comput54:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" &#123;a[$1" "$2]=$0&#125;ARGIND==2 &amp;&amp; $1=="chr1" &amp;&amp; $7=="PASS"&#123;if($1" "$2 in a)&#123;print a[$1" "$2]&#125;&#125;' Cchr1.new.txt wgs.snp.all.default.vcf |wc -l134720[14:45:13] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"' ~/../hhwang/HUES64_re/bssnper/HUES64.SNP.out |wc -l185617[14:48:04] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1" &#123;a[$1" "$2]=$0&#125;ARGIND==2 &amp;&amp; $1=="chr1" &amp;&amp; $7=="PASS"&#123;if($1" "$2 in a)&#123;print a[$1" "$2]&#125;&#125;' ~/../hhwang/HUES64_re/bssnper/HUES64.SNP.out wgs.snp.all.default.vcf |wc -l 118307[14:51:02] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1" &#123;a[$1" "$2]=$0&#125;ARGIND==2 &amp;&amp; $1=="chr1" &amp;&amp; $7=="PASS"&#123;if($1" "$2 in a)&#123;print a[$1" "$2]&#125;&#125;' ~/../hhwang/HUES64_re/bssnper/HUES64.SNP.out wgbs.replace.sort.snp.filtered.sort.vcf |wc -l92860[14:56:15] qwzhou@login:~/practice/HUES64/test : $ less wgbs.replace.sort.snp.filtered.sort.vcf [14:58:53] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"&#123;print $1"_"$2&#125;' ~/../hhwang/HUES64_re/bssnper/HUES64.SNP.out &gt; bissnp.chr1.txt^C[15:08:04] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"&#123;print $1"_"$2&#125;' ~/../hhwang/HUES64_re/bssnper/HUES64.SNP.out &gt; bssnper.chr1.txt[15:08:42] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"&#123;print $1"_"$2&#125;' wgs.snp.all.default.vcf &gt; wgs.chr1.txt[15:09:30] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"&#123;print $1"_"$2&#125;' SNP.out &gt; newBsnpsV0.1.txt[15:13:36] qwzhou@login:~/practice/HUES64/test : $ wc -l newBsnpsV0.3.txt 130148 newBsnpsV0.3.txt[15:21:49] qwzhou@login:~/practice/HUES64/test : $ wc -l newBsnpsV0.4.txt139347 newBsnpsV0.4.txt[15:24:17] qwzhou@login:~/practice/HUES64/test : $ wc -l newBsnpsV0.2.txt254706 newBsnpsV0.2.txt[14:06:06] qwzhou@comput54:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"&#123;print $1"_"$2&#125;' chr1.spnew2.vcf &gt; newBsnpsV0.5.txt[21:59:16] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &#123;a[$1" "$2]=$0&#125;ARGIND==2 &amp;&amp; $1=="chr1" &amp;&amp; $7=="PASS"&#123;if($1" "$2 in a)&#123;print a[$1" "$2]&#125;&#125;' wgbs.replace.sort.snp.filtered.sort.vcf wgs.snp.all.default.vcf |wc -l116521[21:59:46] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" &amp;&amp; $5&lt;0.05&#123;a[$1" "$2]=$0&#125;ARGIND==2 &amp;&amp; $1=="chr1" &amp;&amp; $7=="PASS"&#123;if($1" "$2 in a)&#123;print a[$1" "$2]&#125;&#125;' Cchr1.txt wgs.snp.all.default.vcf |wc -l128561[22:00:00] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" &amp;&amp; $5&lt;0.05&#123;a[$1" "$2]=$0&#125;ARGIND==2 &amp;&amp; $1=="chr1" &amp;&amp; $7=="PASS"&#123;if($1" "$2 in a)&#123;print a[$1" "$2]&#125;&#125;' Cchr1.new.txt wgs.snp.all.default.vcf |wc -l120189[22:01:23] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" &amp;&amp; $5&lt;0.05&#123;a[$1" "$2]=$0&#125;ARGIND==2 &amp;&amp; $1=="chr1" &amp;&amp; $7=="PASS"&#123;if($1" "$2 in a)&#123;print a[$1" "$2]&#125;&#125;' Cchr1.new.txt ../WGS/wgs.snp.vcf |wc -l117139[22:01:50] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" &amp;&amp; $5&lt;0.05&#123;a[$1" "$2]=$0&#125;ARGIND==2 &amp;&amp; $1=="chr1" &amp;&amp; $7=="PASS"&#123;if($1" "$2 in a)&#123;b[$1" "$2]&#125;&#125;ARGIND==3 &amp;&amp; $1=="chr1" &amp;&amp; $7=="PASS"&#123;if($1" "$2 in b)&#123;print b[$1" "$2]&#125;&#125;' Cchr1.new.txt ../WGS/wgs.snp.vcf wgbs.replace.sort.snp.filtered.sort.vcf |wc -l90111[22:03:54] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $4=="PASS" &amp;&amp; $5&lt;0.05 ' Cchr1.txt |wc -l164344[12:08:15] qwzhou@login:~/practice/HUES64/test : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"' wgbs.replace.sort.snp.filtered.sort.vcf |wc -l134547 GM12878123456789101112131415161718192021222324252627$ awk '$1=="chr1" &amp;&amp; length($4)==1 &amp;&amp; (length($5)==1 || ($5~/,/ &amp;&amp; length($5)==3))&#123;print $1"_"$2&#125;' ../../HG001_GRCh38_CHROM1-X_novoalign_Ilmn150bp300x_GATKHC.vcf &gt; wgs.chr1.txt[16:05:48] qwzhou@login:~/practice/GM12878/BS-Seq/SNPdefaultpara : $ awk '$7=="PASS"' bissnp.chr1.snp.filtered.sort.vcf &gt; bissnp.chr1.txt[16:08:17] qwzhou@login:~/practice/GM12878/BS-Seq/SNPdefaultpara : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1" &#123;print $1"_"$2&#125;' bssnper.default.onlySNP.out &gt; bssnper.chr1.txt[16:08:42] qwzhou@login:~/practice/GM12878/BS-Seq/SNPdefaultpara : $ awk '$7=="PASS"&#123;print $1"_"$2&#125;' bissnp.chr1.snp.filtered.sort.vcf &gt; bissnp.chr1.txt[06:16:50] qwzhou@comput54:~/practice/GM12878/BS-Seq/SNPdefaultpara :$ awk '$4=="PASS" &amp;&amp; $5&lt;0.05 &amp;&amp; $1=="chr1" &#123;print $1"_"$2&#125;' Cnewsnp.log &gt; newbsnps.v0.3.txt[16:14:27] qwzhou@login:~/practice/GM12878/BS-Seq/SNPdefaultpara : $ awk '$4=="PASS" &amp;&amp; $5&lt;0.05 &amp;&amp; $1=="chr1"&#123;print $1"_"$2&#125;' Cnew2snp.log &gt; newbsnp.v0.4.txt[17:39:36] qwzhou@comput54:~/practice/GM12878/BS-Seq/SNPdefaultpara : $ awk '$7=="PASS" &amp;&amp; $1=="chr1"' Cmpnewsnp.txt |wc -l249575[17:40:47] qwzhou@comput54:~/practice/GM12878/BS-Seq/SNPdefaultpara : $ less run.compare.sh [17:45:23] qwzhou@comput54:~/practice/GM12878/BS-Seq/SNPdefaultpara : $ awk 'ARGIND==1 &amp;&amp; $7=="PASS" &amp;&amp; $1=="chr1"&#123;a[$1" "$2]&#125;ARGIND==2 &amp;&amp; length($4)==1 &amp;&amp; (length($5)==1 || ($5~/,/ &amp;&amp; length($5)==3))&#123;if($1" "$2 in a)&#123;print $0&#125;&#125;' Cmpnewsnp.txt ../../HG001_GRCh38_CHROM1-X_novoalign_Ilmn150bp300x_GATKHC.vcf |wc -l227862[17:46:22] qwzhou@comput54:~/practice/GM12878/BS-Seq/SNPdefaultpara : $ vi run.compare.sh [21:44:50] qwzhou@comput54:~/practice/GM12878/BS-Seq/SNPdefaultpara : $ awk '$7=="PASS" &amp;&amp; $1=="chr1" &#123;print $1"_"$2&#125;' Cmpnewsnp.txt &gt; newbsnps.v0.5.txt]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>worklog</category>
      </categories>
      <tags>
        <tag>bioinformatics</tag>
        <tag>worklog</tag>
        <tag>newSNP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day20181224]]></title>
    <url>%2F2018%2F12%2F24%2Fday20181224%2F</url>
    <content type="text"><![CDATA[F123 WGBSalignment results123 Time Taken - 185316 Seconds .. [20:48:48] qwzhou@node62:~/practice/mus_hic_mth/wgbs :$ ~/software_devp/batmeth2/bin/penguin -g ~/practice/Genome/mouse/mm10/batmeth2/mouse_reference.fa -i read1.paired.fq.gz -i read2.paired.fq.gz -o F123.bt2bs.sam -p 8 sam2bam12[10:18:17] qwzhou@node62:~/practice/mus_hic_mth/wgbs : $ samtools sort -m 1G -@ 6 -o F123.align.sort.bam F123.bt2bs.sam]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>worklog</category>
      </categories>
      <tags>
        <tag>bioinformatics</tag>
        <tag>worklog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day20181223]]></title>
    <url>%2F2018%2F12%2F23%2Fday20181223%2F</url>
    <content type="text"><![CDATA[A549 HiC数据尤其是数目统计matrix目录下为准data下是SNPsplit结果，直接统计不能确认准确性。 A549 Allele RNAseq with ASM用SNPsplit将RNAseq bam文件按照SNP进行归类。 之后统计genome1 and genome2 gene表达情况，然后统计RNAseq，但是单倍型不完全是G1-G1-G1，所以直接统计不行。 思路： vcf overlap with gene vcf from 1 overlap with G1 bam and G2 bam count number of R2 R3 vcf overlap with ASM vcf overlap with gene12[14:47:23] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ bedtools intersect -a ../HiC_normal/wgbs.encode.bissnp.reformat.vcf -b ~/practice/Genome/hg38/gene.id.bed -wo |less vcf from 1 overlap with G1 bam and G2 bamG112[15:06:10] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ bedtools intersect -a ../HiC_normal/wgbs.encode.bissnp.reformat.vcf -b ~/practice/Genome/hg38/gene.id.bed -wo | awk 'ARGIND==1 &amp;&amp; $1~/^#/&#123;print $0&#125;ARGIND==2&#123;print $0&#125;' ../HiC_normal/wgbs.encode.bissnp.reformat.vcf - |bedtools intersect -a - -b A549.hg38-N.sort.genome1.bam -wo | awk '&#123;a[$1"\t"$2"\t"$2"\t"$16]++&#125;END&#123;for(i in a)&#123;print i"\t"a[i]&#125;&#125;' &gt; snpwtithgenewithG1.bed G212[15:06:10] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ bedtools intersect -a ../HiC_normal/wgbs.encode.bissnp.reformat.vcf -b ~/practice/Genome/hg38/gene.id.bed -wo | awk 'ARGIND==1 &amp;&amp; $1~/^#/&#123;print $0&#125;ARGIND==2&#123;print $0&#125;' ../HiC_normal/wgbs.encode.bissnp.reformat.vcf - |bedtools intersect -a - -b A549.hg38-N.sort.genome2.bam -wo | awk '&#123;a[$1"\t"$2"\t"$2"\t"$16]++&#125;END&#123;for(i in a)&#123;print i"\t"a[i]&#125;&#125;' &gt; snpwtithgenewithG2.bed count number of R212[15:10:15] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ awk 'ARGIND==1&#123;a[$1"\t"$2"\t"$3"\t"$4]=$5&#125;ARGIND==2&#123;if($1"\t"$2"\t"$3"\t"$4 in a)&#123;b[$1"\t"$2"\t"$3"\t"$4]=a[$1"\t"$2"\t"$3"\t"$4]"\t"$5;delete a[$1"\t"$2"\t"$3"\t"$4]&#125;else&#123;b[$1"\t"$2"\t"$3"\t"$4]="0\t"$5&#125;&#125;END&#123;for(i in a)&#123;b[i]=a[i]"\t0"&#125;;for(i in b)&#123;print i"\t"b[i]&#125;&#125;' snpwtithgenewithG1.bed snpwtithgenewithG2.bed |less R3 vcf overlap with ASM12345678910111213[15:36:47] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ awk 'ARGIND==1&#123;a[$1"\t"$2"\t"$3"\t"$4]=$5&#125;ARGIND==2&#123;if($1"\t"$2"\t"$3"\t"$4 in a)&#123;b[$1"\t"$2"\t"$3"\t"$4]=a[$1"\t"$2"\t"$3"\t"$4]"\t"$5;delete a[$1"\t"$2"\t"$3"\t"$4]&#125;else&#123;b[$1"\t"$2"\t"$3"\t"$4]="0\t"$5&#125;&#125;END&#123;for(i in a)&#123;b[i]=a[i]"\t0"&#125;;for(i in b)&#123;print i"\t"b[i]&#125;&#125;' snpwtithgenewithG1.bed snpwtithgenewithG2.bed | bedtools intersect -a - -b ../WGBS-HAIR/A549.hapcut.withsnv.bed -wo | awk '$5+$6&gt;20 &amp;&amp; $6/($5+1)&gt;2 &amp;&amp; length($11)-$13-$14&gt;2&#123;if($13&gt;$14)&#123;print $12&#125;if($14&gt;$13)&#123;print $11&#125;&#125;' | awk '$1~/U/ &amp;&amp; $1!~/M/' |wc -l116[15:37:06] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ awk 'ARGIND==1&#123;a[$1"\t"$2"\t"$3"\t"$4]=$5&#125;ARGIND==2&#123;if($1"\t"$2"\t"$3"\t"$4 in a)&#123;b[$1"\t"$2"\t"$3"\t"$4]=a[$1"\t"$2"\t"$3"\t"$4]"\t"$5;delete a[$1"\t"$2"\t"$3"\t"$4]&#125;else&#123;b[$1"\t"$2"\t"$3"\t"$4]="0\t"$5&#125;&#125;END&#123;for(i in a)&#123;b[i]=a[i]"\t0"&#125;;for(i in b)&#123;print i"\t"b[i]&#125;&#125;' snpwtithgenewithG1.bed snpwtithgenewithG2.bed | bedtools intersect -a - -b ../WGBS-HAIR/A549.hapcut.withsnv.bed -wo | awk '$5+$6&gt;20 &amp;&amp; $6/($5+1)&gt;2 &amp;&amp; length($11)-$13-$14&gt;2&#123;if($13&gt;$14)&#123;print $12&#125;if($14&gt;$13)&#123;print $11&#125;&#125;' | awk '$1~/M/ &amp;&amp; $1!~/U/' |wc -l166[15:13:22] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ awk 'ARGIND==1&#123;a[$1"\t"$2"\t"$3"\t"$4]=$5&#125;ARGIND==2&#123;if($1"\t"$2"\t"$3"\t"$4 in a)&#123;b[$1"\t"$2"\t"$3"\t"$4]=a[$1"\t"$2"\t"$3"\t"$4]"\t"$5;delete a[$1"\t"$2"\t"$3"\t"$4]&#125;else&#123;b[$1"\t"$2"\t"$3"\t"$4]="0\t"$5&#125;&#125;END&#123;for(i in a)&#123;b[i]=a[i]"\t0"&#125;;for(i in b)&#123;print i"\t"b[i]&#125;&#125;' snpwtithgenewithG1.bed snpwtithgenewithG2.bed | bedtools intersect -a - -b ../WGBS-HAIR/A549.hapcut.withsnv.bed -wo | awk '$5+$6&gt;20 &amp;&amp; $5/($6+1)&gt;2 &amp;&amp; length($11)-$13-$14&gt;2&#123;if($13&gt;$14)&#123;print $11&#125;if($14&gt;$13)&#123;print $12&#125;&#125;' | awk '$1~/M/ &amp;&amp; $1!~/U/' |wc -l245[15:38:59] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ awk 'ARGIND==1&#123;a[$1"\t"$2"\t"$3"\t"$4]=$5&#125;ARGIND==2&#123;if($1"\t"$2"\t"$3"\t"$4 in a)&#123;b[$1"\t"$2"\t"$3"\t"$4]=a[$1"\t"$2"\t"$3"\t"$4]"\t"$5;delete a[$1"\t"$2"\t"$3"\t"$4]&#125;else&#123;b[$1"\t"$2"\t"$3"\t"$4]="0\t"$5&#125;&#125;END&#123;for(i in a)&#123;b[i]=a[i]"\t0"&#125;;for(i in b)&#123;print i"\t"b[i]&#125;&#125;' snpwtithgenewithG1.bed snpwtithgenewithG2.bed | bedtools intersect -a - -b ../WGBS-HAIR/A549.hapcut.withsnv.bed -wo | awk '$5+$6&gt;20 &amp;&amp; $5/($6+1)&gt;2 &amp;&amp; length($11)-$13-$14&gt;2&#123;if($13&gt;$14)&#123;print $11&#125;if($14&gt;$13)&#123;print $12&#125;&#125;' | awk '$1~/U/ &amp;&amp; $1!~/M/' |wc -l96 Not ASEG123456789101112[15:40:00] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ awk 'ARGIND==1&#123;a[$1"\t"$2"\t"$3"\t"$4]=$5&#125;ARGIND==2&#123;if($1"\t"$2"\t"$3"\t"$4 in a)&#123;b[$1"\t"$2"\t"$3"\t"$4]=a[$1"\t"$2"\t"$3"\t"$4]"\t"$5;delete a[$1"\t"$2"\t"$3"\t"$4]&#125;else&#123;b[$1"\t"$2"\t"$3"\t"$4]="0\t"$5&#125;&#125;END&#123;for(i in a)&#123;b[i]=a[i]"\t0"&#125;;for(i in b)&#123;print i"\t"b[i]&#125;&#125;' snpwtithgenewithG1.bed snpwtithgenewithG2.bed | bedtools intersect -a - -b ../WGBS-HAIR/A549.hapcut.withsnv.bed -wo | awk '$5+$6&gt;20 &amp;&amp; $5/($6+1)&lt;2 &amp;&amp; length($11)-$13-$14&gt;2&#123;if($13&gt;$14)&#123;print $11&#125;if($14&gt;$13)&#123;print $12&#125;&#125;' | awk '$1~/U/ &amp;&amp; $1!~/M/' |wc -l397[15:44:00] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ awk 'ARGIND==1&#123;a[$1"\t"$2"\t"$3"\t"$4]=$5&#125;ARGIND==2&#123;if($1"\t"$2"\t"$3"\t"$4 in a)&#123;b[$1"\t"$2"\t"$3"\t"$4]=a[$1"\t"$2"\t"$3"\t"$4]"\t"$5;delete a[$1"\t"$2"\t"$3"\t"$4]&#125;else&#123;b[$1"\t"$2"\t"$3"\t"$4]="0\t"$5&#125;&#125;END&#123;for(i in a)&#123;b[i]=a[i]"\t0"&#125;;for(i in b)&#123;print i"\t"b[i]&#125;&#125;' snpwtithgenewithG1.bed snpwtithgenewithG2.bed | bedtools intersect -a - -b ../WGBS-HAIR/A549.hapcut.withsnv.bed -wo | awk '$5+$6&gt;20 &amp;&amp; $5/($6+1)&lt;2 &amp;&amp; length($11)-$13-$14&gt;2&#123;if($13&gt;$14)&#123;print $11&#125;if($14&gt;$13)&#123;print $12&#125;&#125;' | awk '$1~/M/ &amp;&amp; $1!~/U/' |wc -l381[15:44:13] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ awk 'ARGIND==1&#123;a[$1"\t"$2"\t"$3"\t"$4]=$5&#125;ARGIND==2&#123;if($1"\t"$2"\t"$3"\t"$4 in a)&#123;b[$1"\t"$2"\t"$3"\t"$4]=a[$1"\t"$2"\t"$3"\t"$4]"\t"$5;delete a[$1"\t"$2"\t"$3"\t"$4]&#125;else&#123;b[$1"\t"$2"\t"$3"\t"$4]="0\t"$5&#125;&#125;END&#123;for(i in a)&#123;b[i]=a[i]"\t0"&#125;;for(i in b)&#123;print i"\t"b[i]&#125;&#125;' snpwtithgenewithG1.bed snpwtithgenewithG2.bed | bedtools intersect -a - -b ../WGBS-HAIR/A549.hapcut.withsnv.bed -wo | awk '$5+$6&gt;20 &amp;&amp; $6/($5+1)&lt;2 &amp;&amp; length($11)-$13-$14&gt;2&#123;if($13&gt;$14)&#123;print $12&#125;if($14&gt;$13)&#123;print $11&#125;&#125;' | awk '$1~/U/ &amp;&amp; $1!~/M/' |wc -l514[16:03:51] qwzhou@comput54:~/practice/A549_BS/RNAseqEncode : $ awk 'ARGIND==1&#123;a[$1"\t"$2"\t"$3"\t"$4]=$5&#125;ARGIND==2&#123;if($1"\t"$2"\t"$3"\t"$4 in a)&#123;b[$1"\t"$2"\t"$3"\t"$4]=a[$1"\t"$2"\t"$3"\t"$4]"\t"$5;delete a[$1"\t"$2"\t"$3"\t"$4]&#125;else&#123;b[$1"\t"$2"\t"$3"\t"$4]="0\t"$5&#125;&#125;END&#123;for(i in a)&#123;b[i]=a[i]"\t0"&#125;;for(i in b)&#123;print i"\t"b[i]&#125;&#125;' snpwtithgenewithG1.bed snpwtithgenewithG2.bed | bedtools intersect -a - -b ../WGBS-HAIR/A549.hapcut.withsnv.bed -wo | awk '$5+$6&gt;20 &amp;&amp; $6/($5+1)&lt;2 &amp;&amp; length($11)-$13-$14&gt;2&#123;if($13&gt;$14)&#123;print $12&#125;if($14&gt;$13)&#123;print $11&#125;&#125;' | awk '$1~/M/ &amp;&amp; $1!~/U/' |wc -l325 HiC ASM CTCFdata 下的 SNPsplit的结果，觉得不是很好，可以用matrix下的结果再看一遍123456789101112131415161718192021222324[15:10:59] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/data/SRR5129660 : $ awk '$4+$5&gt;=10 &amp;&amp; ($4/($5+1)&gt;=2 ) ' SRR5129660_G1vsG2.2000.bed | bedtools intersect -a - -b ../../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G1high.Peaks -wo | bedtools intersect -a - -b A549.hapcut.G1U.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'9[15:11:14] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/data/SRR5129660 : $ awk '$4+$5&gt;=10 &amp;&amp; ($4/($5+1)&gt;=2 ) ' SRR5129660_G1vsG2.2000.bed | bedtools intersect -a - -b ../../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G1high.Peaks -wo | bedtools intersect -a - -b A549.hapcut.G1M.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'10[15:11:24] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/data/SRR5129660 : $ awk '$4+$5&gt;=10 &amp;&amp; ($5/($4+1)&gt;=2 ) ' SRR5129660_G1vsG2.2000.bed | bedtools intersect -a - -b ../../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G1high.Peaks -wo | bedtools intersect -a - -b A549.hapcut.G1M.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'1[15:13:27] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/data/SRR5129660 : $ awk '$4+$5&gt;=10 &amp;&amp; ($5/($4+1)&gt;=2 ) ' SRR5129660_G1vsG2.2000.bed | bedtools intersect -a - -b ../../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G1high.Peaks -wo | bedtools intersect -a - -b A549.hapcut.G1U.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'2[15:13:37] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/data/SRR5129660 : $ awk '$4+$5&gt;=10 &amp;&amp; ($5/($4+1)&gt;=2 ) ' SRR5129660_G1vsG2.2000.bed | bedtools intersect -a - -b ../../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G2high.Peaks -wo | bedtools intersect -a - -b A549.hapcut.G1U.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'4[15:14:40] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/data/SRR5129660 : $ awk '$4+$5&gt;=10 &amp;&amp; ($5/($4+1)&gt;=2 ) ' SRR5129660_G1vsG2.2000.bed | bedtools intersect -a - -b ../../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G2high.Peaks -wo | bedtools intersect -a - -b A549.hapcut.G1M.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'5[15:14:47] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/data/SRR5129660 : $ awk '$4+$5&gt;=10 &amp;&amp; ($4/($5+1)&gt;=2 ) ' SRR5129660_G1vsG2.2000.bed | bedtools intersect -a - -b ../../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G2high.Peaks -wo | bedtools intersect -a - -b A549.hapcut.G1U.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'0[15:15:26] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/data/SRR5129660 : $ awk '$4+$5&gt;=10 &amp;&amp; ($4/($5+1)&gt;=2 ) ' SRR5129660_G1vsG2.2000.bed | bedtools intersect -a - -b ../../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G2high.Peaks -wo | bedtools intersect -a - -b A549.hapcut.G1M.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'1 matrix下的hicpro结果，还是一样123456789101112[16:26:16] qwzhou@login:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/matrix : $ awk '$4+$5&gt;=10 &amp;&amp; ($4/($5+1)&gt;=2 ) ' SRR5129660/raw/2000/SRR5129660_G1vsG2.ir.bed | bedtools intersect -a - -b ../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G1high.Peaks -wo | bedtools intersect -a - -b ../data/SRR5129660/A549.hapcut.G1U.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'7[16:26:33] qwzhou@login:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/matrix : $ awk '$4+$5&gt;=10 &amp;&amp; ($4/($5+1)&gt;=2 ) ' SRR5129660/raw/2000/SRR5129660_G1vsG2.ir.bed | bedtools intersect -a - -b ../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G1high.Peaks -wo | bedtools intersect -a - -b ../data/SRR5129660/A549.hapcut.G1M.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'7[16:26:53] qwzhou@login:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/matrix : $ awk '$4+$5&gt;=10 &amp;&amp; ($5/($4+1)&gt;=2 ) ' SRR5129660/raw/2000/SRR5129660_G1vsG2.ir.bed | bedtools intersect -a - -b ../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G1high.Peaks -wo | bedtools intersect -a - -b ../data/SRR5129660/A549.hapcut.G1U.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'1[16:27:10] qwzhou@login:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/hic_results_allele_withencodesnp/matrix : $ awk '$4+$5&gt;=10 &amp;&amp; ($5/($4+1)&gt;=2 ) ' SRR5129660/raw/2000/SRR5129660_G1vsG2.ir.bed | bedtools intersect -a - -b ../matrix/SRR5129660/raw/2000/CTCF_UT-A.Allele.G1high.Peaks -wo | bedtools intersect -a - -b ../data/SRR5129660/A549.hapcut.G1M.bed -wo | awk '&#123;b[$1"\t"$2"\t"$3]&#125;END&#123;print length(b)&#125;'0]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>worklog</category>
      </categories>
      <tags>
        <tag>bioinformatics</tag>
        <tag>ASMG with ASM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mm9tomm10vcf]]></title>
    <url>%2F2018%2F12%2F21%2Fmm9tomm10vcf%2F</url>
    <content type="text"><![CDATA[1234567## mm9 vcf 转为 mm10 vcf​```bash[15:51:49] qwzhou@node62:~/practice/Genome/mouse/mm10 : $ java -jar ~/software/picard-tools-1.119/CreateSequenceDictionary.jar REFERENCE=mouse_reference.fa OUTPUT=mouse_reference.dictjava -jar picard.jar LiftoverVcf I=input.vcf O=lifted_over.vcf CHAIN=b37tohg38.chain REJECT=rejected_variants.vcf R=reference_sequence.fasta​ errorCaused by: htsjdk.tribble.TribbleException$InvalidHeader: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file write header​123[16:00:21] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ cat vcfheader.txt GSE48592_castx129_variants.vcf.mm9.txt &gt;GSE48592_castx129_variants.mm9.vcf​ CHAIN=~/practice/Genome/mouse/mm9ToMm10.over.chain download from UCSCrerun vcflift​123[16:01:01] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ java -jar ~/software/picard.jar LiftoverVcf I=GSE48592_castx129_variants.mm9.vcf O=GSE48592_castx129_variants.mm10.vcf CHAIN=~/practice/Genome/mouse/mm9ToMm10.over.chain REJECT=rejected_variants.vcf R=~/practice/Genome/mouse/mm10/mouse_reference.fa​ 仍旧报错，尝试去掉第八列，并筛选snp​123[16:24:03] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ awk -v OFS="\t" '&#123;if($1~/^#/)&#123;print $0&#125;else&#123;if($8~/SNP/)&#123;print $1,$2,$3,$4,$5,$6,$7,".",$9,$10&#125;&#125;&#125;' GSE48592_castx129_variants.mm9.vcf &gt; GSE48592_castx129_variants.mm9.snp.vcf​ 可以正常运行​123[16:25:18] qwzhou@node62:~/practice/mus_hic_mth/methyHic : $ java -jar ~/software/picard.jar LiftoverVcf I=GSE48592_castx129_variants.mm9.snp.vcf O=GSE48592_castx129_variants.mm10.vcf CHAIN=~/practice/Genome/mouse/mm9ToMm10.over.chain REJECT=rejected_variants.vcf R=~/practice/Genome/mouse/mm10/mouse_reference.fa​ `]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>SNP</category>
      </categories>
      <tags>
        <tag>bioinformactis</tag>
        <tag>vcf from mm9 to mm10</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20181219]]></title>
    <url>%2F2018%2F12%2F19%2F20181219%2F</url>
    <content type="text"><![CDATA[F123 HiC-Pro 报错123456Tue Dec 18 23:28:59 CST 2018Assign alignments to restriction fragments ...Logs: logs/sep1/mapped_2hic_fragments.logLogs: logs/sep2/mapped_2hic_fragments.logmake: *** [mapped_2hic_fragments] Error 1[00:13:53] qwzhou@node62:~/practice/mus_hic_mth/F123HiC : F123 运行mergebam12[14:19:43] qwzhou@node62:~/practice/mus_hic_mth/F123HiC :$ samtools merge -@ 6 F123.allmerge.bam hicsnp_latest_allele/bowtie_results/bwt2/sep*/*_mm10.masked.fa.bwt2pairs.bam]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>worklog</category>
      </categories>
      <tags>
        <tag>bioinformatics</tag>
        <tag>worklog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20181218]]></title>
    <url>%2F2018%2F12%2F18%2F20181218%2F</url>
    <content type="text"><![CDATA[A549 hapcut212[10:53:25] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2 :$ ~/software/HapCUT2/build/extractHAIRS --hic 1 --bam A549.allmerge.sort.bam --VCF ../../../wgbs.encode.bissnp.reformat.vcf --out A549.hic.fragment 但是所有染色体速度太慢了，只取chr1运行123456789[10:54:18] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2 :$ samtools index A549.allmerge.sort.bam &amp;&amp; samtools view -bh A549.allmerge.sort.bam chr1 &gt; A549.all.chr1.bam[14:16:41] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2 :$ awk '$1~/^#/ || $1=="chr1"' ../../../wgbs.encode.bissnp.reformat.vcf &gt; wgbs.chr1.vcf[14:35:39] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2 : $ ~/software/HapCUT2/build/extractHAIRS --hic 1 --bam A549.all.chr1.bam --VCF wgbs.chr1.vcf --out A549.hic.chr1.fragment[14:57:14] qwzhou@comput54:~/practice/A549_BS/HiC_normal/hicsnp_latest_allele_withencodesnp/bowtie_results/bwt2 :$ ~/software/HapCUT2/build/HAPCUT2 --hic 1 --fragments A549.hic.chr1.fragment --vcf wgbs.chr1.vcf --output A549.hic.chr1.haplotype 由于hic bam是单端比对后bam合并的，insert size都为0。 因此hapcut运行会过滤掉这些序列。修改hapcut2源代码1234172 if (read-&gt;tid == read-&gt;mtid &amp;&amp; read-&gt;IS==0) // use mateposition to calculate insert size, march 12 2013, wrong since we need to consider the readlength/cigar173 &#123;174 read-&gt;IS = read-&gt;mateposition - read-&gt;position;175 &#125; and then type make]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>worklog</category>
      </categories>
      <tags>
        <tag>bioinformatics</tag>
        <tag>hapcut2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[workingon]]></title>
    <url>%2F2018%2F12%2F16%2Fworkingon%2F</url>
    <content type="text"><![CDATA[A549WGBS | SNP+METH –&gt; doneWGS | SNP –&gt; Hapcut2 –&gt; doneHiC | SNP –&gt; merge bam –&gt; Hapcut … –&gt; Hapcut2WGBS+HiC | … coding –&gt; run WGBS and HiC hap A549 RNAseq SNPsplitKnown relationship bwttwen ASM and ASEQ –&gt; … GM12878 ChIP-Seq asm heatmapdivide Number –&gt; done! F123WGBS | SNP+METH –&gt; fqc –&gt; trim –&gt; merge fq and gzip –&gt; alignment … –&gt; mrsam2bam – merge SNP and meth – splitbam –&gt; hapcut2HiC | SNP –&gt; masked genome index –&gt; run Hic-pro … –&gt; mergebam –&gt; hapcut2 –&gt; doneMethyHiC –&gt; doneWGBS+HiC –&gt; … coding –&gt; run WGBS and HiC hap aradopisisF1 | WGBS –&gt; alignment –&gt; pipleline … -&gt; mrsam2bam –&gt; SNP calling – splitbam –&gt; merge SNP and meth –&gt; hapcut2]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>workingon</category>
      </categories>
      <tags>
        <tag>workingon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HiC-Pro]]></title>
    <url>%2F2018%2F12%2F16%2FHiC-Pro%2F</url>
    <content type="text"><![CDATA[修改vcf格式 不使用HiC-Pro的extract_SNP，因为只是提取的纯和SNP； 我们想要的是杂合SNP； 1awk -v OFS="\t" '&#123;if($1~/^#/)&#123;if($1=="#CHROM")&#123;print $1" "$2" "$3" "$4" "$5" "$6" "$7" "$8" "$9" REF-F123-F1"&#125;else&#123;print $0&#125;&#125;else&#123;if($NF~/0\/1/)&#123;print $1,$2,$3,$4,$5,$6,$7,$8,"GT\t0/1"&#125;&#125;&#125;' ../methyHic/GSE48592_castx129_variants.mm10.vcf &gt; F123.hetero.reformat.vcf build masked genome1bedtools maskfasta -fi ~/practice/Genome/mouse/mm10/mouse_reference.fa -fo mm10.masked.fa -bed ../F123.hetero.reformat.vcf build index of the masked genome1bowtie2-build mm10.masked.fa mm10.masked.fa Edit config-hicAllele.txt1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192# Please change the variable settings below if necessary########################################################################### Paths and Settings - Do not edit !#########################################################################TMP_DIR = tmpLOGS_DIR = logsBOWTIE2_OUTPUT_DIR = bowtie_resultsMAPC_OUTPUT = hic_results_alleleRAW_DIR = rawdata######################################################################### SYSTEM AND SCHEDULER - Start Editing Here !!#######################################################################N_CPU = 8LOGFILE = hicpro.logJOB_NAME = F123_hicJOB_MEM = 100gbJOB_WALLTIME = 1200:00JOB_QUEUE = batchJOB_MAIL = 1010170266@qq.com########################################################################### Data#########################################################################PAIR1_EXT = _1PAIR2_EXT = _2######################################################################### Alignment options#######################################################################FORMAT = phred33MIN_MAPQ = 15BOWTIE2_IDX_PATH = /public/home/qwzhou/practice/mus_hic_mth/F123HiC/bowtie2_AlleleBOWTIE2_GLOBAL_OPTIONS = --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorderBOWTIE2_LOCAL_OPTIONS = --very-sensitive -L 20 --score-min L,-0.6,-0.2 --end-to-end --reorder######################################################################### Annotation files#######################################################################REFERENCE_GENOME = mm10.masked.faGENOME_SIZE = chrom_mm10.sizesCAPTURE_TARGET =######################################################################### Allele specific analysis#######################################################################ALLELE_SPECIFIC_SNP = /public/home/qwzhou/practice/mus_hic_mth/F123HiC/F123.hetero.reformat.vcf######################################################################### Digestion Hi-C#######################################################################GENOME_FRAGMENT = mm10_dpnii_res.txtLIGATION_SITE = GATCGATCMIN_FRAG_SIZE = 100MAX_FRAG_SIZE = MIN_INSERT_SIZE = 100MAX_INSERT_SIZE = ######################################################################### Hi-C processing#######################################################################MIN_CIS_DIST = GET_ALL_INTERACTION_CLASSES = 1GET_PROCESS_SAM = 1RM_SINGLETON = 1RM_MULTI = 1RM_DUP = 1######################################################################### Contact Maps#######################################################################BIN_SIZE = 5000 10000 20000 40000 150000 500000MATRIX_FORMAT = upper######################################################################### Normalization#######################################################################MAX_ITER = 100FILTER_LOW_COUNT_PERC = 0.02FILTER_HIGH_COUNT_PERC = 0EPS = 0.1 run HiC-Pro1~/software/HiC-Pro_2.11.0-beta/bin/HiC-Pro -c config-hicAllele.txt -i rawdata/ -o hicsnp_latest_allele]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>HiC</category>
      </categories>
      <tags>
        <tag>bioinformatics</tag>
        <tag>HiC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[methLevelPlot]]></title>
    <url>%2F2018%2F12%2F15%2FmethLevelPlot%2F</url>
    <content type="text"><![CDATA[scripts123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166# -*- coding: utf-8 -*-"""Created on Fri 10:29:50 2018@author: qwzhou""""""=======================================plot line and dash======================================="""import numpy as npimport matplotlib.pyplot as pltimport sysfrom matplotlib.backends.backend_pdf import PdfPages#x = np.linspace(0, 10, 500)y = []z = []k = []def readfile(filename, y, z, k): nline=0 with open(filename, 'r') as fig: for line in fig: data = line.split() if nline == 0: y.append(map(float,data[1:])) elif nline == 1: z.append(map(float,data[1:])) elif nline == 2: k.append(map(float,data[1:])) nline=nline+1#readfile("IMR90.Methylevel.1.txt", y, z, k)## read file2#readfile("imr90.asmg.Methylevel.1.txt", y, z, k)###readfile("H1_bs.Methylevel.1.txt", y, z, k)#readfile("./IMR90/h3k4me3_peaks.Methy.1.txt", y, z, k)readfile("./IMR90/h3k27ac_peaks.Methy.1.txt", y, z, k)readfile("./IMR90/PolII_peaks.Methy.1.txt", y, z, k)#readfile("./A549/IMR90.gene.fcbneg2.p0.001.Methy.1.txt.Aver", y, z, k)#readfile("./A549/IMR90.gene.fcbneg4.p0.001.Methy.1.txt.Aver", y, z, k)#readfile("./A549/IMR90.gene.fcsneg4.p0.001.Methy.1.txt.Aver", y, z, k)#readfile("./IMR90/peaks.mr.Methylevel.7.txt", y, z, k)#readfile("./IMR90/peaks.mr.Methylevel.8.txt", y, z, k)#readfile("IMR90.asmanno.Methy.1.txt", y, z, k)# #readfile("ENCFF304DGQ.Methylevel.1.txt", y, z, k)x = np.linspace(1, len(y[0]), len(y[0]))label = ['H3K4me3', 'H3K27ac' , 'PollII']######################################################def find_martrix_max_value(data_matrix): new_data=[] for i in range(len(data_matrix)): new_data.append(max(data_matrix[i])) return max(new_data)#######################################################def plotline(x, y, title, label, nsample, legend, filename): prosamp = 0 fig, ax = plt.subplots() while prosamp &lt; nsample: y[prosamp] = [i*100 for i in y[prosamp]] ax.plot(x, y[prosamp], label=label[prosamp]) prosamp = prosamp +1 #dashes = [10, 5, 100, 5] #line1.set_dashes(dashes) # dash line # Remove the plot frame lines. They are unnecessary here. ax.spines['top'].set_visible(False) ax.spines['bottom'].set_visible(False) ax.spines['right'].set_visible(False) #ax.spines['left'].set_visible(False) ax.xaxis.set_major_formatter(plt.FuncFormatter('&#123;:.0f&#125;'.format)) ax.yaxis.set_major_formatter(plt.FuncFormatter('&#123;:.1f&#125;%'.format)) #plt.grid(True, 'major', 'y', ls='--', lw=.5, c='k', alpha=.3) plt.tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=True, left=False, right=False, labelleft=True) #ax.axes.get_xaxis().set_visible(False) if legend == 1: plt.legend(loc='best', prop=&#123;'size': 12&#125;) # legend , loc is the legend location plt.axhline(y=0, xmin=0.05, xmax=0.35, linewidth=8, color='gray') plt.axhline(y=0, xmin=0.65, xmax=0.35, linewidth=8, color='k' ) plt.axhline(y=0, xmin=0.65, xmax=0.95, linewidth=8, color='gray') scale_ls = [1,39,76,117] index_ls = ['upstream','Start','End', "downstream"] plt.xticks(scale_ls,index_ls,color='k', size=15) ax.set_title(title,size=15) ax.set_ylabel('ASM C count',size=15) #ax.set_ylabel('Methylation Level',size=15) maxy = 100 maxy = find_martrix_max_value(y) * 1.1 ax.set_ylim(0.0, maxy) #plt.show() #filename2=filename + ".png" #plt.savefig(filename2, bbox_inches='tight')#label = ['IMR90', 'A549', 'H1', 'GM12878', 'encodeA549']filename="methylation"filename2=filename + ".pdf"pdf = PdfPages(filename2)nsample=3legend=1plotline(x, y, "CG methylation distribution", label, nsample, legend, filename+".CG")legend=0plotline(x, z, "CHG methylation distribution", label, nsample, legend, filename+".CHG")plotline(x, k, "CHH methylation distribution", label, nsample, legend, filename+".CHH") pdf.savefig()pdf.close()''' fig, ax = plt.subplots() line1, = ax.plot(x, k1, label='IMR90') #dashes = [10, 5, 100, 5] #line1.set_dashes(dashes) # dash line line2, = ax.plot(x, k2, label='A549') # several dash line example #line3, = ax.plot(x, y3, ':', label='..style') #line4, = ax.plot(x,-np.sin(x)/2, '-.', label='-.style') #line5, = ax.plot(x,np.sin(x)/4, '--', label='--style') #line6, = ax.plot(x,-np.sin(x)/4, '^', label='--style') #plt.axis('off') #plt.xticks([]) #plt.yticks([]) #ax.axes.get_yaxis().set_visible(False) # Remove the plot frame lines. They are unnecessary here. ax.spines['top'].set_visible(False) ax.spines['bottom'].set_visible(False) ax.spines['right'].set_visible(False) #ax.spines['left'].set_visible(False) #ax.axes.get_xaxis().set_visible(False) plt.legend(loc='center right') # legend , loc is the legend location plt.axhline(y=0, xmin=0.05, xmax=0.35, linewidth=8, color='gray') plt.axhline(y=0, xmin=0.65, xmax=0.35, linewidth=8, color='k' ) plt.axhline(y=0, xmin=0.65, xmax=0.95, linewidth=8, color='gray') scale_ls = [1,39,76,117] index_ls = ['upstream','Start','End', "downstream"] plt.xticks(scale_ls,index_ls,color='k', size=15) #ax.set_title('Box plot') ax.set_ylabel('Methylation Level',size=15) maxy=max(k1) if max(k2) &gt; maxy: maxy = max(k2)*1.1 else: maxy = maxy*1.1 ax.set_ylim(0.0, maxy) #plt.savefig("test.png") plt.show() ''' results]]></content>
      <categories>
        <category>visualization</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>visualization, python, methylevel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[methpoint]]></title>
    <url>%2F2018%2F12%2F15%2Fmethpoint%2F</url>
    <content type="text"><![CDATA[scripts123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159# -*- coding: utf-8 -*-"""Created on Fri May 18 15:50:17 2018@author: qwzhou"""import numpy as npimport matplotlib.pyplot as pltfrom matplotlib.lines import Line2Dimport pysamimport sysdef usage(): print "\nPROGRAM input.sort.bam chr:start-end" print "\nPlease define the chrom region!\n"if len(sys.argv) &lt; 2: usage() sys.exit()##read meth filepath_in = sys.argv[1] ##bam filesamfile = pysam.AlignmentFile(path_in, "rb")#for line in samfile:# print(line)# breaklines = []postion = []neglines = []negpostion = []pchr = sys.argv[2].split(":")[0]pstart = int(sys.argv[2].split(":")[1].split("-")[0])pend = int(sys.argv[2].split(":")[1].split("-")[1])print pchr, pstart, pendstrand = '.'for read in samfile.fetch(pchr, pstart, pend): #tags = read.rstrip().split("\t") if( not (read.flag &amp; 0x2) and not (read.flag &amp; 0x10) or ( (read.flag &amp; 0x2) and ( ((read.flag &amp; 0x40) and (read.flag &amp; 0x20)) or ((read.flag &amp; 0x80) and (read.flag &amp; 0x10 ))) ) ): lines.append(read.get_tag("MD")) postion.append(read.pos) elif ( not (read.flag &amp; 0x2) and (read.flag &amp; 0x10) or ( (read.flag &amp; 0x2) and ( ((read.flag &amp; 0x40) and (read.flag &amp; 0x10)) or ((read.flag &amp; 0x80) and (read.flag &amp; 0x20 ))) ) ): neglines.append(read.get_tag("MD")) negpostion.append(read.pos)samfile.close()#points = ['1','1','1','3','2'] # Draw 3 points for each linetext_style = dict(horizontalalignment='right', verticalalignment='center', fontsize=12, fontdict=&#123;'family': 'monospace'&#125;)marker_style = dict(color='cornflowerblue', linestyle=':', marker='o', markersize=10, markerfacecoloralt='gray')def fillstyles(case): if case.isupper(): return 'full' else: return 'none'def markerstyle(case): global marker_style markersize = 4.5 if case.upper() == 'Z': marker_style = dict(color='cornflowerblue', linestyle=':', marker='o', markersize=markersize, markerfacecoloralt='gray') elif case.upper() == 'H': marker_style = dict(color='red', linestyle=':', marker='o', markersize=markersize, markerfacecoloralt='gray') elif case.upper() == 'X': marker_style = dict(color='green', linestyle=':', marker='o', markersize=markersize, markerfacecoloralt='gray') elif case == '=': marker_style = dict(color='gray', linestyle=':', marker='o', markersize=0.6) elif case == 'A': marker_style = dict(color='black', linestyle='-', marker='1', markersize=markersize) elif case == 'C': marker_style = dict(color='black', linestyle='-', marker='2', markersize=markersize) elif case == 'G': marker_style = dict(color='black', linestyle='-', marker='3', markersize=markersize) elif case == 'T': marker_style = dict(color='black', linestyle='-', marker='4', markersize=markersize) else: marker_style = dict(color='black', linestyle='-', marker='|', markersize=markersize)def format_axes(ax): ax.margins(0.2) ax.set_axis_off()def nice_repr(text): return repr(text).lstrip('u')fig, ax = plt.subplots(figsize=(10, 6))meth = []unmeth = []xpostion = []mratio = []def initarray(): for i in range(0,pend-pstart): meth.append(0) unmeth.append(0) mratio.append(0) for i in range(pstart, pend): xpostion.append(i)initarray()def calmeth(case, xpos): if case.upper() != 'Z' and case.upper() != 'H' and case.upper() != 'X' : return if case.isupper(): meth[xpos] = meth[xpos]+1 else: unmeth[xpos] = unmeth[xpos]+1nline=0for y,line in enumerate(lines): nline=nline+1 if nline&gt;1000: break# if postion[y] &gt; pstart:# continue if postion[y] &gt; pend: break for x, ch in enumerate(line): if x+postion[y] &lt; pstart: continue if x+postion[y] &gt; pend: break calmeth(ch, x+postion[y]-pstart) markerstyle(ch) ax.plot( x+postion[y], -round((y+y*0.1),2), fillstyle=fillstyles(ch), **marker_style) format_axes(ax)ax.plot([pstart,pend],[-round((y+y*0.1+1),2),-round((y+y*0.1+1),2)], color='black');ax.text(pstart, -round((y+y*0.1+3),2), sys.argv[2])print methprint unmethprint xpostion#[a[i]/b[i] if b[i] !=0 else 0 for i in range(3)]for i in range(0, len(meth)): if meth[i]+unmeth[i]&gt;0: mratio[i] = -1.0*meth[i]/(unmeth[i]+meth[i]) - round((y+y*0.1+4),2) else: mratio[i] = 0 -round((y+y*0.1+4),2)ax.plot(xpostion, mratio)# Plot all fill styles.#for y, fill_style in enumerate(Line2D.fillStyles):# ax.text(-0.5, y, nice_repr(fill_style), **text_style)# ax.plot(y * points, fillstyle=fill_style, **marker_style)# format_axes(ax)# ax.set_title('fill style')filename= "test.png"plt.savefig(filename, bbox_inches='tight', dpi=128)plt.show() Results]]></content>
      <categories>
        <category>visualization</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>visualization, python, methpoint</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotProfile]]></title>
    <url>%2F2018%2F12%2F15%2FplotProfile%2F</url>
    <content type="text"><![CDATA[scripts123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219# -*- coding: utf-8 -*-"""Created on Fri Sep 21 10:29:50 2018@author: qwzhou""""""=======================================plot line and dash======================================="""import numpy as npimport matplotlib.pyplot as pltimport sysfrom matplotlib.backends.backend_pdf import PdfPages#x = np.linspace(0, 10, 500)y = []z = []k = []def readfile(filename, y, z, k): nline=0 with open(filename, 'r') as fig: for line in fig: data = line.split() if nline == 0: y.append(map(float,data[1:])) elif nline == 1: z.append(map(float,data[1:])) elif nline == 2: k.append(map(float,data[1:])) nline=nline+1#readfile("IMR90.Methylevel.1.txt", y, z, k)## read file2#readfile("imr90.asmg.Methylevel.1.txt", y, z, k)###readfile("H1_bs.Methylevel.1.txt", y, z, k)#.narrowPeak .broadPeak .narrowPeak .broadPeak#.broadPeak .broadPeak .narrowPeak#readfile("./IMR90/H3K27ac_narrow_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K36me3_broad_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K4me3_narrow_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K9me3_broad_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K27me3_broad_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K4me1_broad_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K9ac_narrow_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K27ac_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K36me3_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K4me3_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K9me3_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K27me3_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K4me1_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/CTCF_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/PolII_peaks.sites.Methy.1.txt", y, z, k)readfile("./IMR90/gene.TSS.Methy.1.txt", y, z, k)##readfile("./A549_2/CTCF_UT-A_peaks.newasm.Methy.1.txt.Aver", y, z, k)#readfile("./A549_2/CTCF_UT-A.Allele.Methy.1.txt.Aver", y, z, k) #readfile("./k562/hg38.fa.out.repeat.Methy.1.txt.Aver", y, z, k)#readfile("./k562/hg38.fa.out.repeat.LINE.Methy.1.txt.Aver", y, z, k) #readfile("./k562/hg38.fa.out.repeat.SINE.Methy.1.txt.Aver", y, z, k) #readfile("./k562/hg38.fa.out.repeat.LTR.Methy.1.txt.Aver", y, z, k) #readfile("./A549/h3k27ac_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549/h3k4me3_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549/h3k4me1_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549/h3k36me3_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549/h3k27me3_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549/h3k9me3_peaks.newasm.Methy.1.txt", y, z, k) #readfile("./A549_2/CTCF_UT-A_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/H3K27me3_none_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/H3K9me3_stanford_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/CTCF_stanford_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/H3K4me1_stanford_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/H3K27ac_stanford_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/H3K4me3_UW_peaks.newasm.Methy.1.txt", y, z, k) # # # #readfile("ENCFF304DGQ.Methylevel.1.txt", y, z, k)x = np.linspace(1, len(y[0]), len(y[0]))#label=['h3k4me1']#label=[ 'h3k4me3', 'h3k27ac','h3k4me1', 'h3k36me3', 'h3k27me3', 'h3k9me3']#label=[ 'h3k27ac', 'h3k36me3','h3k4me3', 'h3k9me3', 'h3k27me3', 'h34me1', 'h3k9ac']#label=[ 'h3k27ac', 'h3k4me3','h34me1', 'h3k36me3', 'h3k27me3', 'h3k9me3']#label=[ 'h3k27ac', 'h3k36me3','h3k4me3', 'h3k9me3', 'h3k27me3', 'h3k4me1', 'CTCF', 'PolII']label=['gene']#label=['Repeat', 'LINE', 'SINE', 'LTR']#label=['CTCF_ALL', 'CTCF_Allele']#label=[ 'CTCF_UT-A', 'H3K27me3_none','H3K9me3_stanford', 'CTCF_stanford', 'H3K4me1_stanford', 'H3K27ac_stanford', 'H3K4me3_UW_peaks']filename="./IMR90/ASM.distri.TSS.Sites"filename2=filename + ".pdf"nsample=1legend=1percentage=1######################################################def find_martrix_max_value(data_matrix): new_data=[] for i in range(len(data_matrix)): new_data.append(max(data_matrix[i])) return max(new_data)#######################################################def plotline(x, y, title, label, nsample, legend, filename): prosamp = 0 fig, ax = plt.subplots() while prosamp &lt; nsample: y[prosamp] = [i*percentage for i in y[prosamp]] ax.plot(x, y[prosamp], label=label[prosamp]) prosamp = prosamp +1 #dashes = [10, 5, 100, 5] #line1.set_dashes(dashes) # dash line # Remove the plot frame lines. They are unnecessary here. ax.spines['top'].set_visible(False) ax.spines['bottom'].set_visible(False) ax.spines['right'].set_visible(False) #ax.spines['left'].set_visible(False) ax.xaxis.set_major_formatter(plt.FuncFormatter('&#123;:.0f&#125;'.format)) #ax.yaxis.set_major_formatter(plt.FuncFormatter('&#123;:.1f&#125;%'.format)) #plt.grid(True, 'major', 'y', ls='--', lw=.5, c='k', alpha=.3) plt.tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=True, left=False, right=False, labelleft=True) #ax.axes.get_xaxis().set_visible(False) if legend == 1: plt.legend(loc='best', prop=&#123;'size': 12&#125;) # legend , loc is the legend location plt.axhline(y=0, xmin=0.05, xmax=0.35, linewidth=8, color='gray') plt.axhline(y=0, xmin=0.65, xmax=0.35, linewidth=8, color='k' ) plt.axhline(y=0, xmin=0.65, xmax=0.95, linewidth=8, color='gray') scale_ls = [1,39,76,117] index_ls = ['upstream','Start','End', "downstream"] plt.xticks(scale_ls,index_ls,color='k', size=15) ax.set_title(title,size=15) ax.set_ylabel('ASM percentage (%)',size=15) #ax.set_ylabel('Methylation Level',size=15) maxy = 100 maxy = find_martrix_max_value(y) * 1.1 ax.set_ylim(0.0, maxy) #plt.show() #filename2=filename + ".png" #plt.savefig(filename2, bbox_inches='tight')#label = ['IMR90', 'A549', 'H1', 'GM12878', 'encodeA549']pdf = PdfPages(filename2)plotline(x, y, "ASM distribution", label, nsample, legend, filename+".CG")#plotline(x, y, "CG methylation distribution", label, nsample, legend, filename+".CG")legend=0#plotline(x, z, "CHG methylation distribution", label, nsample, legend, filename+".CHG")#plotline(x, k, "CHH methylation distribution", label, nsample, legend, filename+".CHH") pdf.savefig()pdf.close()''' fig, ax = plt.subplots() line1, = ax.plot(x, k1, label='IMR90') #dashes = [10, 5, 100, 5] #line1.set_dashes(dashes) # dash line line2, = ax.plot(x, k2, label='A549') # several dash line example #line3, = ax.plot(x, y3, ':', label='..style') #line4, = ax.plot(x,-np.sin(x)/2, '-.', label='-.style') #line5, = ax.plot(x,np.sin(x)/4, '--', label='--style') #line6, = ax.plot(x,-np.sin(x)/4, '^', label='--style') #plt.axis('off') #plt.xticks([]) #plt.yticks([]) #ax.axes.get_yaxis().set_visible(False) # Remove the plot frame lines. They are unnecessary here. ax.spines['top'].set_visible(False) ax.spines['bottom'].set_visible(False) ax.spines['right'].set_visible(False) #ax.spines['left'].set_visible(False) #ax.axes.get_xaxis().set_visible(False) plt.legend(loc='center right') # legend , loc is the legend location plt.axhline(y=0, xmin=0.05, xmax=0.35, linewidth=8, color='gray') plt.axhline(y=0, xmin=0.65, xmax=0.35, linewidth=8, color='k' ) plt.axhline(y=0, xmin=0.65, xmax=0.95, linewidth=8, color='gray') scale_ls = [1,39,76,117] index_ls = ['upstream','Start','End', "downstream"] plt.xticks(scale_ls,index_ls,color='k', size=15) #ax.set_title('Box plot') ax.set_ylabel('Methylation Level',size=15) maxy=max(k1) if max(k2) &gt; maxy: maxy = max(k2)*1.1 else: maxy = maxy*1.1 ax.set_ylim(0.0, maxy) #plt.savefig("test.png") plt.show() ''' Results]]></content>
      <categories>
        <category>visualization</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>visualization, python, profile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotHeatmap]]></title>
    <url>%2F2018%2F12%2F15%2FplotHeatmap%2F</url>
    <content type="text"><![CDATA[scripts123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155# -*- coding: utf-8 -*-"""Created on Fri Sep 21 15:37:26 2018@author: qwzhou"""import numpy as npimport matplotlib.pyplot as pltfrom matplotlib.backends.backend_pdf import PdfPagesfrom matplotlib import cm from matplotlib import axesy = []z = []k = []def readfile(filename, y, z, k): nline=0 with open(filename, 'r') as fig: for line in fig: data = line.split() if nline == 0: y.append(map(float,data[1:])) elif nline == 1: z.append(map(float,data[1:])) elif nline == 2: k.append(map(float,data[1:])) nline=nline+1 #readfile("./A549/PolII_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/CTCF_peaks.Methy.1.txt", y, z, k)#readfile("./A549/h3k4me3_peaks.Methy.1.txt", y, z, k)#readfile("./A549/h3k27ac_peaks.Methy.1.txt", y, z, k)#readfile("./A549/h3k4me1_peaks.Methy.1.txt", y, z, k)#readfile("./A549/h3k36me3_peaks.Methy.1.txt", y, z, k)#readfile("./A549/h3k27me3_peaks.Methy.1.txt", y, z, k)#readfile("./A549/h3k9me3_peaks.Methy.1.txt", y, z, k)#readfile("./k562/H3K27ac_narrow_peaks.Methy.1.txt", y, z, k)#readfile("./k562/H3K4me3_narrow_peaks.Methy.1.txt", y, z, k)#readfile("./k562/H3K9ac_narrow_peaks.Methy.1.txt", y, z, k)#readfile("./k562/H3K4me1_broad_peaks.Methy.1.txt", y, z, k)#readfile("./k562/H3K36me3_broad_peaks.Methy.1.txt", y, z, k)#readfile("./k562/H3K9me3_broad_peaks.Methy.1.txt", y, z, k)#readfile("./k562/H3K27me3_broad_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K27ac_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/PolII_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K4me3_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K4me1_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K36me3_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K9me3_peaks.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K27me3_peaks.Methy.1.txt", y, z, k)#readfile("./A549_2/CTCF_UT-A_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/H3K27me3_none_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/H3K9me3_stanford_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/CTCF_stanford_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/H3K4me1_stanford_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/H3K27ac_stanford_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/H3K4me3_UW_peaks.newasm.Methy.1.txt", y, z, k)#readfile("./A549_2/CTCF_UT-A_peaks.newasm.Methy.1.txt.Aver", y, z, k)#readfile("./A549_2/CTCF_UT-A.Allele.Methy.1.txt.Aver", y, z, k)#readfile("./k562/hg38.fa.out.repeat.Methy.1.txt.Aver", y, z, k)#readfile("./k562/hg38.fa.out.repeat.LINE.Methy.1.txt.Aver", y, z, k) #readfile("./k562/hg38.fa.out.repeat.SINE.Methy.1.txt.Aver", y, z, k) #readfile("./k562/hg38.fa.out.repeat.LTR.Methy.1.txt.Aver", y, z, k)#readfile("./IMR90/H3K27ac_peaks.Methy.1.txt.Aver", y, z, k)#readfile("./IMR90/H3K36me3_peaks.Methy.1.txt.Aver", y, z, k)#readfile("./IMR90/H3K4me3_peaks.Methy.1.txt.Aver", y, z, k)#readfile("./IMR90/H3K9me3_peaks.Methy.1.txt.Aver", y, z, k)#readfile("./IMR90/H3K27me3_peaks.Methy.1.txt.Aver", y, z, k)#readfile("./IMR90/H3K4me1_peaks.Methy.1.txt.Aver", y, z, k)#readfile("./IMR90/H3K4me3_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K27ac_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/PolII_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K4me1_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K9me3_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K27me3_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/H3K36me3_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/CTCF_peaks.sites.Methy.1.txt", y, z, k) #readfile("./gm12878/H3K27ac_narrow_peaks.sites.Methy.1.txt", y, z, k)#readfile("./gm12878/H3K4me3_narrow_peaks.sites.Methy.1.txt", y, z, k)#readfile("./gm12878/H3K9ac_narrow_peaks.sites.Methy.1.txt", y, z, k)#readfile("./gm12878/H3K4me1_broad_peaks.sites.Methy.1.txt", y, z, k)#readfile("./gm12878/H3K27me3_broad_peaks.sites.Methy.1.txt", y, z, k)#readfile("./gm12878/H3K9me3_broad_peaks.sites.Methy.1.txt", y, z, k)#readfile("./gm12878/H3K36me3_broad_peaks.sites.Methy.1.txt", y, z, k)#readfile("./IMR90/hg38.fa.out.repeat.start.sites.Methy.1.txt.Aver", y, z, k)readfile("./IMR90/hg38.fa.out.repeat.LINE.sites.Methy.1.txt.Aver", y, z, k) readfile("./IMR90/hg38.fa.out.repeat.SINE.sites.Methy.1.txt.Aver", y, z, k) readfile("./IMR90/hg38.fa.out.repeat.LTR.sites.Methy.1.txt.Aver", y, z, k)readfile("./IMR90/hg38.fa.out.repeat.Others.sites.Methy.1.txt.Aver", y, z, k)filename="./IMR90/ASM.distri.TE.Sites.heatmap"filename2=filename + ".pdf"pdf = PdfPages(filename2)xlabels=[]#ylabels=['PolII', 'h3k4me3', 'h3k27ac', 'h3k27me3', 'h3k36me3', 'h3k4me1', 'h3k9me3']#ylabels=[ 'h3k4me3', 'h3k27ac','h3k4me1', 'h3k36me3', 'h3k27me3', 'h3k9me3']#ylabels=[ 'h3k27ac', 'h3k4me3', 'h3k9ac' , 'h34me1' , 'h3k36me3', 'h3k9me3', 'h3k27me3' ]#ylabels=[ 'h3k27ac', 'PolII', 'h3k4me3', 'h3k4me1' , 'h3k36me3', 'h3k9me3', 'h3k27me3' ]#ylabels=[ 'CTCF_UT-A', 'H3K27me3_none','H3K9me3_stanford', 'CTCF_stanford', 'H3K4me1_stanford', 'H3K27ac_stanford', 'H3K4me3_UW_peaks']ylabels=[ 'LINE', 'SINE', 'LTR', 'Others']#ylabels=['H3K4me3' , 'H3K27ac', 'PolII', 'H3K4me1', 'H3K9me3' , 'H3K36me3', 'H3K27me3']#ylabels=[ 'H3K4me3' ,'H3K27ac', 'H3K9ac', 'H3K4me1', 'H3K27me3', 'H3K9me3', 'H3K36me3']title="ASM distribution"def draw_heatmap(data,title, xlabels,ylabels): #cmap=cm.Blues cmap=cm.get_cmap('RdYlBu_r') figure=plt.figure(facecolor='w') ax=figure.add_subplot(1,1,1,position=[0.1,0.15,0.8,0.8]) ax.set_yticks(range(len(ylabels))) ax.set_yticklabels(ylabels) ax.set_xticks(range(len(xlabels))) ax.set_xticklabels(xlabels) vmax=data[0][0] vmin=data[0][0] for i in data: for j in i: if j&gt;vmax: vmax=j if j&lt;vmin: vmin=j map=ax.imshow(data,interpolation='nearest',cmap=cmap,aspect='auto',vmin=vmin,vmax=vmax) cb=plt.colorbar(mappable=map,cax=None,ax=None,shrink=0.5) ax.set_title(title,size=15) #plt.show() #plt.savefig(filename3, bbox_inches='tight') pdf.savefig() #a=np.random.rand(10,10)draw_heatmap(y,title, xlabels,ylabels) pdf.close() Results]]></content>
      <categories>
        <category>visualization</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>visualization, python, heatmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotHeatmapFromMatrix]]></title>
    <url>%2F2018%2F12%2F15%2FplotHeatmapFromMatrix%2F</url>
    <content type="text"><![CDATA[scripts12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# -*- coding: utf-8 -*-"""Created on Thu Dec 06 22:07:56 2018@author: qwzhou"""import numpy as npimport matplotlib.pyplot as pltfrom matplotlib.backends.backend_pdf import PdfPagesfrom matplotlib import cm from matplotlib import axesy = []z = []k = []def readfile(filename, y): with open(filename, 'r') as fig: for line in fig: data = line.split() y.append(map(float,data[1:])) readfile("./asmSite.combine.bins500.sort.txt", y)filename="./ASMsite.distri.allSample500bp.heatmap"filename2=filename + ".pdf"pdf = PdfPages(filename2)xlabels=['GM12878', 'IMR90', 'A549', 'K562', 'HUES64', 'HepG2']#ylabels=['PolII', 'h3k4me3', 'h3k27ac', 'h3k27me3', 'h3k36me3', 'h3k4me1', 'h3k9me3']#ylabels=[ 'h3k4me3', 'h3k27ac','h3k4me1', 'h3k36me3', 'h3k27me3', 'h3k9me3']#ylabels=[ 'h3k27ac', 'h3k4me3', 'h3k9ac' , 'h34me1' , 'h3k36me3', 'h3k9me3', 'h3k27me3' ]#ylabels=[ 'h3k27ac', 'PolII', 'h3k4me3', 'h3k4me1' , 'h3k36me3', 'h3k9me3', 'h3k27me3' ]#ylabels=[ 'CTCF_UT-A', 'H3K27me3_none','H3K9me3_stanford', 'CTCF_stanford', 'H3K4me1_stanford', 'H3K27ac_stanford', 'H3K4me3_UW_peaks']ylabels=[]#ylabels=['H3K4me3' , 'H3K27ac', 'PolII', 'H3K4me1', 'H3K9me3' , 'H3K36me3', 'H3K27me3']#ylabels=[ 'H3K4me3' ,'H3K27ac', 'H3K9ac', 'H3K4me1', 'H3K27me3', 'H3K9me3', 'H3K36me3']title="ASM overlap between samples"def draw_heatmap(data,title, xlabels,ylabels): cmap=cm.Reds #cmap=cm.get_cmap('RdYlBu_r') figure=plt.figure(facecolor='w') ax=figure.add_subplot(1,1,1,position=[0.1,0.15,0.8,0.8]) ax.set_yticks(range(len(ylabels))) ax.set_yticklabels(ylabels) ax.set_xticks(range(len(xlabels))) ax.set_xticklabels(xlabels) vmax=data[0][0] vmin=data[0][0] for i in data: for j in i: if j&gt;vmax: vmax=j if j&lt;vmin: vmin=j map=ax.imshow(data,interpolation='nearest',cmap=cmap,aspect='auto',vmin=vmin,vmax=vmax-110) cb=plt.colorbar(mappable=map,cax=None,ax=None,shrink=0.5) ax.set_title(title,size=15) #plt.show() #plt.savefig(filename3, bbox_inches='tight') pdf.savefig() #a=np.random.rand(10,10)draw_heatmap(y,title, xlabels,ylabels) pdf.close() Results]]></content>
      <categories>
        <category>visualization</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>visualization, python, heatmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[check_install_Rpkg]]></title>
    <url>%2F2018%2F12%2F15%2Fcheck-install-Rpkg%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122# Check if necessary libraries are installed check_pkg &lt;- function(pkg) &#123; if(require(pkg, character.only = TRUE))&#123; print(paste("Package", pkg, "is loaded correctly", sep = " ")) &#125; else &#123; print(paste("Trying to install package", pkg, sep = " ")) install.packages(pkg, repos="http://cran.us.r-project.org", dep = TRUE) if(require(pkg, character.only = TRUE))&#123; print(paste("Package", pkg, "is installed and loaded correctly", sep = "")) &#125; else&#123; install.packages(pkg, repos="http://cran.rstudio.com/", dep = TRUE) if(require(pkg, character.only = TRUE))&#123; print(paste("Package", pkg, "is installed and loaded correctly", sep = "")) &#125; else&#123; stop(paste("Couldn't install package", pkg, sep = " ")); &#125; &#125; &#125;&#125;check_pkg("xtable")#check_pkg("RCircos")#check_pkg("grid")]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>bioinformatics, R, install package</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bionorm_R]]></title>
    <url>%2F2018%2F12%2F15%2Fbionorm-R%2F</url>
    <content type="text"><![CDATA[scripts1234567891011121314151617181920##bionnorm.test&lt;- function(input.data,alpha=0.05,pic=TRUE)&#123; if(pic==TRUE)&#123;#画图形 dev.new() par(mfrow=c(2,1)) qqnorm(input.data,main="qq图") qqline(input.data) hist(input.data,frep=F,main="直方图和密度估计曲线") lines(density(input.data),col="blue") #密度估计曲线 x&lt;- c(round(min(input.data)):round(max(input.data))) lines(x,dnorm(x,mean(input.data),sd(input.data)),col="red") #正态分布曲线 &#125; sol&lt;- shapiro.test(input.data) if(sol$p.value&gt;alpha)&#123; print(paste("success:服从正态分布,p.value=",sol$p.value,"&gt;",alpha)) &#125;else&#123; print(paste("error:不服从正态分布,p.value=",sol$p.value,"&lt;=",alpha)) &#125; sol&#125;]]></content>
      <categories>
        <category>bioinfromatics</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>bioinfromatics</tag>
        <tag>bionorm funcition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EdgeR]]></title>
    <url>%2F2018%2F12%2F15%2FEdgeR%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223library(edgeR)a&lt;-read.table("C:/Users/qwzhou/Desktop/code/A549/A549.Allgenecount", sep="\t", col.names = c("gene_id","control"))b&lt;-read.table("C:/Users/qwzhou/Desktop/code/IMR90/Imr90.Allgenecount", sep="\t", col.names = c("gene_id","control"))raw_count &lt;- merge(a, b, by="gene_id")#remove the last five line#raw_count_filt &lt;- raw_count[-1:-5,]raw_count_filt&lt;- raw_count[,2:3]rownames(raw_count_filt) &lt;-raw_count$gene_id ## remove other sig#ENSEMBL &lt;- gsub("(.*?)\\.\\d*?_\\d", "\\1", raw_count_filt$gene_id)#row.names(raw_count_filt) &lt;- ENSEMBLgroup &lt;- factor(c("A549","IMR90"))genelist &lt;- DGEList(counts=raw_count_filt[,1:2], group = group)bcv = 0.1et &lt;- exactTest(genelist, dispersion=bcv^2)results = et$tablewrite.table(results, file="C:/Users/qwzhou/Desktop/code/A549andIMR90.DEG.txt")]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>bioinformatics, edgeR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BisRNA]]></title>
    <url>%2F2018%2F12%2F15%2FBisRNA%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425source("http://bioconductor.org/biocLite.R")biocLite("BisRNA")library(BisRNA)data(Bisdata,package="BisRNA")lambda1 &lt;- RNAmeth.poisson.par(Bisdata1)$estimateBisXP1 &lt;- RNAmeth.poisson.test(Bisdata1,lambda1,method="BH")a&lt;-read.table("C:\\Users\\qwzhou\\Desktop\\zhouchao\\m6A.bed")names(a)=c("RNA", "Cpos", "coverage", "ncratio")lambda1 &lt;- RNAmeth.poisson.par(a)$estimateBisXP1 &lt;- RNAmeth.poisson.test(a,lambda1,method="BH")BisXP1.df &lt;- data.frame(BisXP1$nonconv.ratio, BisXP1$pv.adj, row.names=BisXP1$RNA.pos)write.table(BisXP1.df,file="C:\\Users\\qwzhou\\Desktop\\zhouchao\\m6A.bed.txt")data&lt;-read.table("C:\\Users\\qwzhou\\Desktop\\bt2new\\Methyl450withallaligner.txt", sep="\t", header=T)mydata &lt;- data[, c(3,4,5,6,7,8,9,10)]library(PerformanceAnalytics)chart.Correlation(mydata, histogram=TRUE, type="l")]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>DNA methylation</category>
      </categories>
      <tags>
        <tag>bioinformatics, bisulfite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ggplot_basic_plot]]></title>
    <url>%2F2018%2F12%2F15%2Fggplot-basic-plot%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091library(ggplot2)a&lt;-read.table("C:/Users/qwzhou/Desktop/code/A549/A549.haplen.statis.txt", sep="\t", col.names = c("group","len","number"))a&lt;-read.table("C:/Users/qwzhou/Desktop/code/IMR90/repeat.length", sep=" ", col.names = c("len","group"))p &lt;- ggplot(a, aes(x=group, y=len,color=group,group=group)) +geom_boxplot() +ylim(0,2000)p +labs(title="",x="", y = "Length")+ theme_bw() + ## 背景 theme(panel.grid =element_blank()) + ## 删去网格线 theme(plot.title = element_text(hjust = 0.5, size = 18, colour = "black", face = "bold") ,axis.title.y = element_text(size=16,colour = "black",face = "bold"), axis.text.y = element_text(size=10, colour = "black"), axis.text.x = element_text(size=16, colour = "black"), legend.position = c(0.85,0.75))## line plotprofile_text &lt;- read.table("C:/Users/qwzhou/Desktop/code/phaseddensity.chr1.txt", header=T, row.names=1, quote="")#head(profile_text)#Meth.SNP SNP Meth.SNP.SNP. #10000 10 3 3#10001 34 28 30#10002 36 21 19#10003 22 20 17#10004 52 36 40#10005 27 18 1library(reshape2)profile_text$xvariable = rownames(profile_text)data_m &lt;- melt(profile_text, id.vars=c("xvariable"))data_m$xvariable &lt;- as.numeric(data_m$xvariable)p &lt;- ggplot(data_m, aes(x=xvariable, y=value,color=variable,group=variable)) +geom_point() +ylim(0,100)#+ stat_smooth(method="auto", se=FALSE) + theme(legend.position=c(0.85,0.2))pdata_m$value &lt;- pmin(data_m$value,100)p &lt;- ggplot(data_m, aes(x=variable, y=value,color=variable,group=variable)) +geom_boxplot()pp &lt;- ggplot(data_m, aes(x=xvariable, y=value,color=variable,group=variable)) + stat_smooth(method="auto", se=FALSE)p +labs(title="",x="", y = "Phased number")+ theme_bw() + ## 背景 theme(panel.grid =element_blank()) + ## 删去网格线 theme(plot.title = element_text(hjust = 0.5, size = 18, colour = "black", face = "bold") ,axis.title.y = element_text(size=16,colour = "black",face = "bold"), axis.text.y = element_text(size=10, colour = "black"), axis.text.x = element_text(size=16, colour = "black"), legend.position = c(0.85,0.5))### bar plotb&lt;-a[a$len!="L0",]b$len&lt;-factor(b$len,levels=c("L500", "L1000", "L2000")) g &lt;- ggplot(data=b, aes(x=len, y=number, fill=group)) g + geom_bar(stat="identity", position=position_dodge()) + scale_fill_manual(values=c("#999999", "#009E73", "#D55E00"))+ labs(title="Haplotype length",x="", y = "Number")+ theme_bw() + ## 背景 theme(panel.grid =element_blank()) + ## 删去网格线 theme(plot.title = element_text(hjust = 0.5, size = 18, colour = "black", face = "bold") ,axis.title.y = element_text(size=16,colour = "black",face = "bold"), axis.text.y = element_text(size=10, colour = "black"), axis.text.x = element_text(size=16, colour = "black"), legend.position = c(0.8,0.8))### densityplotggplot(a,aes(x=pmin(a$len,1000),group=factor(group),colour=factor(group)))+ geom_density()###boxplotp&lt;-ggplot(a, aes(x=group, y=len, color=group)) + geom_boxplot() + ylim(0,1000) + scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9")) p+ labs(title="Haplotype length",x="", y = "Length") + theme_bw() + ## 背景 theme(panel.grid =element_blank()) + ## 删去网格线 theme(panel.border = element_blank()) + ## 删去外层边框 theme(axis.line = element_line(size=0.5, colour = "black")) + ## 再加上坐标轴（无刻度、无标签） theme(plot.title = element_text(hjust = 0.5, size = 18, colour = "black", face = "bold") ,axis.title.y = element_text(size=16,colour = "black",face = "bold"), axis.text.y = element_text(size=10, colour = "black"), axis.text.x = element_text(size=16, colour = "black"), legend.position='none') ## face取值：plain普通，bold加粗，italic斜体，bold.italic斜体加粗 #theme(axis.text = element_blank()) + ## 删去刻度标签#theme(axis.ticks = element_blank()) + ## 删去刻度线 #geom_dotplot(binaxis='y', stackdir='center', stackratio=0.1, dotsize=0.1)]]></content>
      <categories>
        <category>visualization</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>R, ggplot, visualization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac_usage]]></title>
    <url>%2F2018%2F10%2F06%2Fmac-usage%2F</url>
    <content type="text"><![CDATA[Error【Mac】invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library解决办法： xcode-select –install]]></content>
      <categories>
        <category>macbook</category>
      </categories>
      <tags>
        <tag>macbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CppUseEffective]]></title>
    <url>%2F2018%2F08%2F06%2FCppUseEffective%2F</url>
    <content type="text"><![CDATA[1. C++ 遇到的问题1.1 字符串频繁变动内容不要用 string1234567891011121314151617181920std::string map_seq=""; //too slow for map_seq = map_seq + 'N' bool valid=false;int index=0; while (m&lt;cLen)&#123; if(reds_loci.size()&gt;1)&#123; if (m &gt;= rstart &amp;&amp; m &lt; rend-redlen)&#123; if(distance&gt;=low_bound &amp;&amp; distance &lt;= up_bound)&#123; map_seq = map_seq + seq[m]; index++; valid=true; &#125;else&#123; map_seq = map_seq +'N'; //'-' index++; valid=false; &#125; .... ..... ..... m++; &#125; map_seq[cLen]='\0'; 问题描述程序中循环cLen（大约几千万到几个亿），每个位置需要在字符串map_string后面添加一个字符，导致string频繁变动内容以及长度，运行非常之慢。 解决将string修改为char*，按照cLen长度进行初始化字符串长度，因此每个位置赋值，并不会引起变化。 123456789101112131415161718192021222324252627282930313233343536373839404142434445char* map_seq = new char[cLen+1];strcpy(map_seq, "None");fprintf(stderr, "\nProcess the genome with restriction enzyme digestion sites number: %d, genomeLen: %d", reds_loci.size(), cLen);unsigned m=0;int rstart=0;int rend=0;int distance=0;if(reds_loci.size()&gt;1)&#123; rstart=reds_loci[0]; rend=reds_loci[1]+redlen; distance=rend-rstart;&#125;bool valid=false;int index=0;while (m&lt;cLen)&#123; if(reds_loci.size()&gt;1)&#123; if (m &gt;= rstart &amp;&amp; m &lt; rend-redlen)&#123; if(distance&gt;=low_bound &amp;&amp; distance &lt;= up_bound)&#123; map_seq[index] = seq[m]; index++; valid=true; &#125;else&#123; map_seq[index] = 'N'; //'-' index++; valid=false; &#125; &#125;else&#123; if(m&lt;rstart)&#123; m++; continue; &#125; if(m &lt; rend &amp;&amp; valid)&#123; map_seq[index] = seq[m]; index++; m++; continue; &#125;else m--; reds_loci.pop_front(); if(reds_loci.size()&gt;1)&#123; rstart=reds_loci[0]; rend=reds_loci[1]+redlen; distance=rend-rstart; &#125; &#125; &#125; m++;&#125;map_seq[cLen]='\0'; 1.2 what(): std::bad_alloc错误terminate called after throwing an instance of ‘std::bad_alloc’ what(): std::bad_alloc 问题分析可能原因： malloc 申请内存，但系统内存不足。 vector需要申请的内存，必须要连续的内存地址，例如我们需要申请200M大小的vector，但是没有连续200M的空间，尽管我们还是有较大的非连续的空间，也是不行的。 检查是否有频繁的申请内存但是没有释放，或者释放错误。 …… 解决办法如果是因为你必须申请一块较大的内存，例如我需要申请10G左右的内存来存储vector，当然我也不知道当时为什么没有用数组存储，总之这种情况不是因为频繁调用以及异常申请释放等问题，而且自己目前也不想去修改代码（懒…），那只能确保服务器内存足够的情况下提交程序。总之，针对这个问题需要根据自己的代码以及程序要做的问题来解决，一般比较容易解决。 BWT：检查过自己的程序，不是vector确实是new申请的数组需要较大内存。我对内存一直处于晕乎状态，如果有什么不对的，非常希望指正。 在论坛看到一个答复如下： 容量大小从小到大：栈≤全局数据≤堆≤文件≤硬盘≤磁盘阵列≤云存储 当程序需要使用比如2GB～1TB左右的存储时，最简单的办法恐怕得是用文件读写模拟内存读写了吧。windows参考_fseeki64函数，linux参考fseeko64函数。 12345FILE *fA;fA=fopen("A","rb+");_fseeki64(fA,10000000000i64*sizeof(int),SEEK_SET);fputc(fA,0);//int A[10000000000];int B;_fseeki64(fA,9999999999i64*sizeof(int),SEEK_SET);fread(&amp;B,1,sizeof(int),fA);//B=A[9999999999];_fseeki64(fA,9999999999i64*sizeof(int),SEEK_SET);fwrite(&amp;B,1,sizeof(int),fA);//A[9999999999]=B;fclose(fA); 没测试过可行性以及运行效率，大家有时间可以测试一下，欢迎回复测试结果，或提供其他办法。 参考 2. C++ 信息2.1 .a .o .so在Linux上创建静态库.a和动态库.so 我们通常把一些公用函数制作成函数库,供其它程序使用.函数库分为静态库和共享库两种:1.静态函数库这类库的名字一般是libxxx.a.利用静态函数库编译成的文件比较大,因为整个函数库的所有数据都会被整合进目标代码中.优点就显而易见了,即编译后的执行程序不需要外部的函数库支持,因为所有使用的函数都已经被编译进去了.当然这也会成为缺点,如果静态函数库改变了,那么你的程序必须重新编译.比如PHP的configure参数–enable-mbstring=static(默认),生成的mbstring.a被静态链接到二进制程序php,php-fpm,php-cgi,libphp.so中.2.共享函数库这类库的名字一般是libxxx.so.相对于静态函数库,共享函数库在编译的时候 并没有被编译进目标代码中.当程序执行到相关函数时才调用共享函数库里相应的函数,因此共享函数库所产生的可执行文件比较小.由于共享函数库没有被整合进你的程序,而是在程序运行时动态地申请并调用,所以程序的运行环境中必须提供相应的库.共享函数库的改变并不影响你的程序,所以共享函数库的升级比较方便.比如PHP的configure参数–enable-mbstring=shared,生成的mbstring.so就是共享库.另外用phpize生成PECL扩展库的configure文件,然后make编译,生成的也是共享库. –enable-static 生成静态库a文件–enable-shared 生成共享库so文件 用ar打包.o文件(obj对象文件,目标文件)生成.a共享库:ar -r libname.a name.oar -t libname.a 可见 name.o 参考链接]]></content>
      <categories>
        <category>language</category>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CorrelationR]]></title>
    <url>%2F2018%2F08%2F01%2FCorrelationR%2F</url>
    <content type="text"><![CDATA[读取文件1234data&lt;-read.table("C:\\data.txt")##data&lt;-read.table("C:\\Users\\qwzhou\\Desktop\\bt2new\\Methyl450withallaligner.txt", sep="\t", header=T)##提取数据列mydata &lt;- data[, c(3,4,5,6,7,8,9,10,11)] 计算相关系数1res &lt;- cor(mydata,use="complete.obs") 相关系数以及pvalue123456## cor只能计算相关系数，加载library(Hmisc)包，计算相关系数以及pvalue## source("http://bioconductor.org/biocLite.R")## biocLite("Hmisc")## biocLite("backports")library(Hmisc)res2&lt;-rcorr(as.matrix(mydata)) 可视化scatter plots （数据大时会特别慢，因为需要作图点多）123## biocLite("PerformanceAnalytics")library(PerformanceAnalytics)chart.Correlation(mydata, histogram=TRUE) 可视化2, 数据量大时show.points=FALSE123biocLite("psych")library(psych)pairs.panels(t, digits = 3, scale=TRUE, show.points=FALSE) 参考Seven Easy Graphs to Visualize Correlation Matrices in R]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>R</category>
        <category>visualization</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>相关系数，R，visualization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[韦恩图]]></title>
    <url>%2F2018%2F07%2F25%2F%E9%9F%A6%E6%81%A9%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[在线工具： Calculate and draw custom Venn diagrams Venny 2.1 R limma gplots venneuler VennDiagram 参考资料12 以上方法最多完成五个元素的韦恩图，当超过6个元素时怎么办？这里推荐使用R包： UpSetR 参考资料123 注意测试过程中发现五个元素完全没问题，当超过五个元素直接使用upset(data)做图时只显示五个元素。添加参数sets后，可以显示全部元素。或者添加nsets = 6, 因为默认5个可能。 在fromlist时，我的每个读入文件是一列chr_pos 12345678910111213biocLite("UpSetR")library(UpSetR)a1&lt;-read.table("A1.txt")a2&lt;-read.table("A2.txt")a3&lt;-read.table("A3.txt")......a6&lt;-read.table("A6.txt")##每个文件一列数据，可以合并到一起整合为csv，##data&lt;-read.csv(system.file("extdata", "merge.csv", package="UpSetR"), header=T, sep=",")##upset(data, ...)listInput &lt;- list(A1 = a1, A2 = a2, A3 = a3, A4 = a4, A5 = a5, A6 = a6) upset(fromList(listInput), sets =c("A1", "A2", "A3", "A4", "A5", "A6"), order.by ="freq", empty.intersections ="on")]]></content>
      <categories>
        <category>visualization</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>韦恩图, R, visualization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一台电脑配置多个github账户]]></title>
    <url>%2F2018%2F07%2F20%2F%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AAgithub%E8%B4%A6%E6%88%B7%2F</url>
    <content type="text"><![CDATA[解决过程： 生成SSH KEY ssh-keygen -t rsa -C “github-qw” 注意因为在~/.ssh/目录下已经存在id_rsa,因此需要你选择路径时，不能简单的确认，需要输入新的路径名称：我的是： ~/.ssh/id_rsa_qw 完成后可以看到自己~/.ssh/目录下的文件： 查看密钥~/.ssh/id_rsa_qw.pub并添加到自己的github SSH-Key 打开~/.ssh/config，添加内容，如果为空不影响。 如果未建立仓库 此时检查是否成功： ssh -T github-qw github-qw为ssh-keygen时指定的名称。 12345git initgit add .git commit -m "first commit"git remote add origin git@github-qw:ZhouQiangwei/BT2.gitgit push -u origin master 如果已经存在仓库以及文件，修改替换地址 查看： git remote -v 修改： git remote set-url github github-qw 修改后查看是否连接成功：ssh -T github-qw 然后可以进行push等操作 github账户如果还是显示之前id_rsa密钥账户的话请把你的密钥加入sshAgent代理中 因为没碰到这部分问题，不做记录，需要可以查看原文章。 参考链接Git 最著名报错 “ERROR: Permission to XXX.git denied to user”终极解决方案]]></content>
      <categories>
        <category>GitHub</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bs环境]]></title>
    <url>%2F2018%2F07%2F15%2Fbs%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[比对：Batmeth2 (git clone https://github.com/GuoliangLi-HZAU/BatMeth2.git)bismark2（https://www.bioinformatics.babraham.ac.uk/projects/bismark/）, 依赖 bowtie2bsmap （https://code.google.com/archive/p/bsmap/）bwa-meth （git clone https://github.com/brentp/bwa-meth.git）, 依赖bwaR (ggplot2/grid/gridExtra/xtable/pheatmap)]]></content>
  </entry>
  <entry>
    <title><![CDATA[bayses-possion-mm-etc]]></title>
    <url>%2F2018%2F07%2F13%2Fbayses-possion-mm-etc%2F</url>
    <content type="text"><![CDATA[Bayes分布：简单理解为在某条件A下事件B发生的概率。贝叶斯网络：每点只与上一点相关，即间接作用不计。贝叶斯网络可以看做是马尔科夫链（Markov）的非线性扩展。http://blog.csdn.net/u014593570/article/details/77663897https://www.zhihu.com/question/28006799https://zhuanlan.zhihu.com/p/22470375https://zhuanlan.zhihu.com/p/22455079http://blog.csdn.net/kl1411/article/details/74079885 马尔科夫链：每点只与上一点相关，即间接作用不计。https://zhuanlan.zhihu.com/p/21570899?refer=c_29122335http://blog.csdn.net/junli_chen/article/details/50489393 泊松分布：泊松分布是二项分布n很大而p很小时的一种极限形式https://www.zhihu.com/question/26441147 高斯分布：平均值与方差https://zhuanlan.zhihu.com/p/22541620 冥律分布：长尾分布，幂律分布最显著的特征是它的长尾，表示那些在高斯分布下的微小概率事件并非那样罕见。例如本分之20%的人掌握世界大部分财富典型的例子。https://zhuanlan.zhihu.com/p/22541620 二项分布，几何分布，超几合分布：https://www.zhihu.com/question/26441147https://www.zhihu.com/question/38191693 beta分布：https://www.zhihu.com/question/30269898]]></content>
      <categories>
        <category>MathStatics</category>
      </categories>
      <tags>
        <tag>Bayes</tag>
        <tag>Markov</tag>
        <tag>Possion</tag>
        <tag>Gaussian</tag>
        <tag>Pow-law (冥律分布)</tag>
        <tag>beta</tag>
        <tag>Hypergeometric (超几合)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shortmem]]></title>
    <url>%2F2018%2F07%2F10%2Fshortmem%2F</url>
    <content type="text"><![CDATA[1. 更改私钥密码ssh-keygen -f /Users/qiangweizhou/.ssh/id_rsa -p 2. warning: LF will be replaced by CRLF in tags/Others/index.html.git config core.autocrlf false 3. error: The following untracked working tree files would be overwritten by me 本地覆盖服务器git stashgit pullgit stash pop然后可以使用git diff -w +文件名 来确认代码自动合并的情况. 服务器覆盖本地2.1 本地电脑修改 git reset –hard git pull2.2 变动内容为其他客户端修改 git reset –hard HEAD git clean -f -d git pull 4. win, unix, mac文件格式转换 win: 0D0A unix: 0A mac: 0Dvi 修改： set ff=unix or doc 5. PPT/word高亮codeMAC:12brew install highlighthighlight -l -O rtf test.sh | pbcopy test.sh是输入文件，pbcopy是复制到剪切板然后按格式复制到PPT 6. win自动拨号上网 通过添加命令行Rasdial ADSL 你的帐号 你的密码，或者建立快捷方式到启动文件夹。但是这种方式是开始启动，断号后却不会尝试拨号，不是我想要的。所以选择饭软件： 拨号软件：http://soft.hao123.com/soft/appid/7993.html优势是可以断网后重新尝试拨号。 7. R levels(变量) &gt; null可能变量内容为数值。修改如下：levels(as.factor(变量)) 8. error: src refspec master does not match any.error: failed to push some refs to &#39;git@github.com:hahaha/user.git’本地仓库为空需要运行git add . 9. sublime text 缩进 注释多行选中后：注释以及去掉注释： command+/删除左端tab： command+[添加tab： command+] 10. c++ pthread lpthreadPOSIX线程（POSIX threads），简称Pthreads，是线程的POSIX标准。该标准定义了创建和操纵线程的一整套API。在类Unix操作系统（Unix、Linux、Mac OS X等）中，都使用Pthreads作为操作系统的线程。 pthread是linux下的线程库，用了多线程就要链接这个库，这时候要在编译选项上增加-pthread或者-lpthread -pthread选项对 预处理器和链接器起作用而老式的-lpthread只对链接器起作用推荐使用-pthread 11. github delete file1git add -A 它能stages所有文件，而之前用的 1git add . 只能stages新文件和被修改文件，没有被删除文件 12. github 删除本地.gitgit remote -v to get your github-uri. Step 1: remove all history 1rm -rf .git Step 2: reconstruct the Git repo with only the current content 123git initgit add .git commit -m &quot;Initial commit&quot; Step 3: push to GitHub. 12git remote add origin &lt;github-uri&gt;git push -u --force origin master 链接 13. 一篇文章多个categories子分类如果想将分章放到 A/B这个分类 123categories: - A - B 也可以这样实现： 1categories: [A, B] 多个分类如果想要A、B两类平行 123categories: - [A] - [B] 或者想放在A/a以及B类下：A/a 和 B ： 123categories: - [A, a] - [B] 14. kill screen1、使用screen名字，kill掉。 ​ screen -S session_name -X quit 2、激活screen： ​ screen -r session_name ​ 输入exit退出并kiil掉session。 15. git errorfatal: remote origin already exists.12345[11:24:23] qwzhou@login:~/software/BSsnpscan : $ git remote add origin git@github-qw:ZhouQiangwei/BSNPS.gitfatal: remote origin already exists.[11:25:33] qwzhou@login:~/software/BSsnpscan : $ git remote rm origin]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>Others</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROC plot]]></title>
    <url>%2F2018%2F07%2F10%2FROCplot%2F</url>
    <content type="text"><![CDATA[roc curvefile format: xvalue yvalue categories… … … R code1234567library(ggplot2)a&lt;-read.table("C:\\Users\\qwzhou\\Desktop\\bt2\\text.txt")ggplot(a,aes(a$V2, a$V1)) + geom_line(aes(color=a$V3)) + scale_shape_manual(values=c(1,2,3,4,5,6,7,8,9,10,11)) + geom_point(aes(shape=a$V3,color=a$V3)) + xlim(0,20000) + xlab("Discordant") + ylab("Concordant") + ggtitle("plot title") + theme_bw() + theme(legend.position='none') + theme(panel.grid =element_blank())##散点 fileformat: case xvalue yvalueggplot(a,aes(a$V3, a$V2)) + scale_shape_manual(values=c(1,2,3,4,5,6,7,8)) + geom_point(aes(shape=a$V1,color=a$V4)) + xlim(0,7000) + xlab("Discordant") + ylab("Concordant") + ggtitle("75bp simulate Illumina (1 Million)") + theme_bw() + theme(legend.position='none')##shape colorggplot(a,aes(a$V3, a$V2)) + scale_shape_manual(values=c(1,2,3,4,5,6)) + geom_point(aes(shape=a$V4,color=a$V1)) + xlim(0,7000) + xlab("Discordant") + ylab("Concordant") + ggtitle("75bp simulate Illumina (1 Million)") + theme_bw() + theme(legend.position='none') results: point results #未完…]]></content>
      <categories>
        <category>visualization</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>ggplot2</tag>
        <tag>visualization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[text2html and check R package and install]]></title>
    <url>%2F2018%2F07%2F10%2Ftext2html%2F</url>
    <content type="text"><![CDATA[R代码 args[1]: workdir args[2]: input_prefix args[3]: textfile text2html.r1234567891011121314151617181920212223242526272829303132333435363738394041424344options(warn = -1)args &lt;- commandArgs(trailingOnly = TRUE)#program_dir &lt;- args[1]setwd(args[1])input_prefix &lt;- args[2]convertfile &lt;- args[3]output_dir &lt;- paste(args[1], "/bt2_report_", input_prefix,"/images/", sep = "")##Check if necessary libraries are installed check_pkg &lt;- function(pkg) &#123; if(require(pkg, character.only = TRUE))&#123; print(paste("Package", pkg, "is loaded correctly", sep = " ")) &#125; else &#123; print(paste("Trying to install package", pkg, sep = " ")) install.packages(pkg, repos="http://cran.us.r-project.org", dep = TRUE) if(require(pkg, character.only = TRUE))&#123; print(paste("Package", pkg, "is installed and loaded correctly", sep = "")) &#125; else&#123; install.packages(pkg, repos="http://cran.rstudio.com/", dep = TRUE) if(require(pkg, character.only = TRUE))&#123; print(paste("Package", pkg, "is installed and loaded correctly", sep = "")) &#125; else&#123; stop(paste("Couldn't install package", pkg, sep = " ")); &#125; &#125; &#125;&#125;check_pkg("xtable")#check_pkg("RCircos")#check_pkg("grid")#install.packages("xtable", repos = "http://cran.us.r-project.org", dep = TRUE)library(xtable)filename&lt;- convertfilea&lt;-read.table(paste(output_dir, filename, sep=""), header=T, sep="\t")##c &lt;- xtable(a, align = c("c", "c", "c"))header&lt;-"&lt;!DOCTYPE HTML&gt;&lt;html lang=\"en-US\"&gt;&lt;meta charset=\"UTF-8\"&gt;&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"../style.css\" media=\"all\" /&gt;"write(header, file=paste(output_dir, gsub("txt","",filename), "html", sep = ""))print(c, type='html', file=paste(output_dir, gsub("txt","",filename), "html", sep = ""), include.rownames = F, append = T, html.table.attributes = "class = 'mytable'")]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>bioinformatics</tag>
        <tag>R</tag>
        <tag>check package</tag>
        <tag>text2html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime Text3配置Markdown编辑以及预览]]></title>
    <url>%2F2018%2F07%2F06%2Fsublime-Text%E9%85%8D%E7%BD%AEMarkdown%E7%BC%96%E8%BE%91%2F</url>
    <content type="text"><![CDATA[安装Package Control 快捷键 control (Mac下command) + shift + p， 当然也可以通过菜单栏 Preferences -&gt; Package Control 选择 Package Control:Install Package安装完重启sublime Text 配置Markdown control (Mac下command) + shift + p 调出package管理平台，选择 Package Control:Install Package 后输入Markdown Editing 后确认，安装过程左下角会有提示。 Markdown预览： control (Mac下command) + shift + p后选择 Package Control:Install Package 后输入 Markdown Preview:Preview in Browser 通过md文件实现自动更新 据说可以通过Auto-save实现自动更新，但是没有实际应用过，感兴趣的可以自己尝试。 我平时用的方法是在编辑的文件最后加上： 1&lt;meta http-equiv="refresh" content="5"&gt; 5是每5s时间浏览器刷新，时间可以根据个人目前修改频率调整。文档编辑成功之后建议删掉该命令，否则打开网页会一直在刷新。]]></content>
      <categories>
        <category>编辑工具</category>
      </categories>
      <tags>
        <tag>Sublime Text</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub pages与hexo建立个人博客]]></title>
    <url>%2F2018%2F07%2F05%2Fgithub%20pages%E5%92%8Chexo%E5%BB%BA%E7%AB%8B%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[具体搭建博客过程网上非常多的教程，不再复述了，以下为挑选的几个教程，可以参照： Mac平台打造github上hexo博客全过程 Mac上搭建基于GitHub的Hexo博客 Hexo-Next-主题优化 hexo博客的背景设置 hexo高阶教程：next主题优化之加入网易云音乐、网易云跟帖、炫酷动态背景、自定义样式，打造属于你自己的定制化博客 hexo生成博文插入图片 浏览器是如何使你的http网址变成https的 Font Awesome Icons hexo的next主题个性化教程：打造炫酷网站 next的自动更新背景图片实现方法及效果图展示 随机图片-可以做背景 markdown基本语法 hexo+next主题优化之加入网易云音乐、网易云跟帖、炫酷动态背景 Hexo添加字数统计、阅读时长、友情链接 Hexo系列教程之三：next主题的配置和优化 Hexo next主题搭建静态博客埋坑记录 以上内容涉及方面非常全面了。 修改的内容自己做的修改地方, 不是很喜欢sliderbar上的纯黑色背景，修改为背景图。修改前： 黑色背景 修改后：添加背景后 修改内容：打开themes/next/source/css/_custom/custom.styl， 添加一下内容： 1234567891011121314151617181920212223242526272829303132.site-meta &#123; background:url(/images/headerbackground.jpg); //#3090e4 background-repeat: no-repeat; background-size: cover;&#125;.brand &#123; color: #3090e4 ::selection &#123; color: rgb(199, 131, 255) //#ff00a3ba; &#125;&#125;.brand &#123; color: #3090e4 ::selection &#123; color: rgb(199, 131, 255) //#ff00a3ba; &#125;&#125;.brand:hover &#123; color: #ff00a3ba;&#125;.site-subtitle &#123; color: #f573b1;&#125;.site-subtitle::selection &#123; background: #ffffff; color: #7b9cde;&#125;]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>GitHub</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一篇个人博客]]></title>
    <url>%2F2018%2F07%2F05%2FwhyBuildThisBlogWeb%2F</url>
    <content type="text"><![CDATA[为什么建立这个博客 建立这个博客的初衷呢自己也说不清楚，无法避免的重要原因必然是理工觉得很酷啊、炫。 个人方面，主要想让自己养成一个习惯。平时接触到好的网站好的书好的信息资源非常多，经常随手收藏或者记在脑子里（当时真的记下了）这里有个很好的知识点/资源，以后有时间回来看。N天后甚至N月后遇到一个问题，既得肯定遇到过这个问题的解决方案或者类似的原理，哇塞 怎么去找呢，我记得保存到收藏夹里了，嗯 😄找出手机来发现，😅前几天手机内存不足格式化了（发一下牢骚，手机不能买16g的，存储空间完全不够用去掉系统软件后只有1～2g，还是经常清理的结果)。或者既得好像是哪本书？类似的问题。。。，总之，希望自己能坚持整理文档的习惯。 除了没有保存的内容外，存下来的内容也没有规律的收录在一起，找起来非常麻烦，自己去找都犯愁的地步，有时候想着把自己放到我收录的所有信息文件中，必须找到某一个知识点才能出来，第一感觉是头疼。😄 总之，希望自己多学习 博客的内容 自己遇到问题的解决思路方法。 学到的非常有意义新的内容。 转载的好的文章或者教程 个人生活]]></content>
      <categories>
        <category>个人</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>个人</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BisSNP分析BS-seq数据检测SNP]]></title>
    <url>%2F2018%2F07%2F05%2FBisSNP%2F</url>
    <content type="text"><![CDATA[运行BisSNP检测SNP使用BisSNP检测SNP相对BS-SNPer来说，需要运行多步操作，过程类似GATK，当然实际上该软件确实使用了GATK。但是福利来了，在提供jar文件的同时，提供了BisSNP_Utils/，其中包含一键式文件bissnp_easy_usage.pl 但是运行该文件需要dbSNP数据 因此首先下载vcf数据。来源GATK： https://software.broadinstitute.org/gatk/download/bundle基因组：hg38SNP version：146 下载链接：12345678ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/Mills_and_1000G_gold_standard.indels.hg38.vcf.gzftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz.tbiftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/dbsnp_146.hg38.vcf.gzftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/dbsnp_146.hg38.vcf.gz.tbiftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/hapmap_3.3.hg38.vcf.gzftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/hapmap_3.3.hg38.vcf.gz.tbiftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/hapmap_3.3_grch38_pop_stratified_af.vcf.gzftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/wgs_calling_regions.hg38.interval_list 下载后需要保证vcf的染色体排序与参考基因组一致，否则报错。 按照基因组顺序排序vcf文件run.sortsnv.sh12345678910111213141516input=$1out=$2chr_order="chrM\nchr1\nchr2\nchr3\nchr4\nchr5\nchr6\nchr7\nchr8\nchr9\nchr10\nchr11\nchr12\nchr13\nchr14\nchr15\nchr16\nchr17\nchr18\nchr19\nchr20\nchr21\nchr22\nchrY\nchrX"#echo -e $chr_order | while read line#do# echo $line#donecat $input | grep "^#" &gt; .header.vcfcat $input | grep -v "^#" | sort -k1,1 -k2,2n &gt; .pre.sorted.vcfecho -e $chr_order | while read linedo cat .pre.sorted.vcf | grep "^$line"$'\t' &gt;&gt; .header.vcfdonemv .header.vcf $&#123;out&#125; &amp;&amp; rm .pre.sorted.vcf 运行命令：1sh run.sort.sh dbsnp_146.hg38.vcf dbsnp_146.hg38.sort.vcf 运行bissnp_easy_usage.pl检测snp1perl ~/software/BisSNP_Utils/bissnp_easy_usage.pl --mmq 20 ~/software/BisSNP-1.0.0.jar wgbs.md.sort.bam ~/practice/Genome/hg38/hg38.chr.fa ~/practice/Genome/hg38/dbsnp_146.hg38.sort.vcf 可以安心等待结果，若程序中间报错，会返回更新。–mmq 20是可用reads的比对分值，20足够了认为。 程序报错：ERROR：Invalid command line: Failed to load reference dictionary因此建立genome index1java -jar ~/software/picard-tools-1.119/CreateSequenceDictionary.jar REFERENCE=hg38.chr.fa OUTPUT=hg38.chr.dict 注意生成的文件是hg38.chr.dict，而不是hg38.chr.fa.dict 注意如果bam文件与参考基因组文件染色体数目不一致，需要运行ReorderSam校正：1java -jar ~/software/picard-tools-1.119/ReorderSam.jar I=wgbs.rm.bam O=wgbs.fixRef.bam R=~/practice/Genome/hg38/hg38.chr.fa ALLOW_INCOMPLETE_DICT_CONCORDANCE=true 重新运行后依旧报错：ReplaceReadGroups to fix this problem因此运行程序：1java -jar ~/software/picard-tools-1.119/AddOrReplaceReadGroups.jar I=wgbs.md.sort.bam O=wgbs.md.replace.bam SORT_ORDER=coordinate RGPL=Illumina CREATE_INDEX=True RGLB=LaneX RGPU=NONE RGSM=SAMPLENAME 重新运行BisSNP1perl ~/software/BisSNP_Utils/bissnp_easy_usage.pl --mmq 20 ~/software/BisSNP-0.82.2.jar wgbs.md.replace.bam ~/practice/Genome/hg38/hg38.chr.fa ~/practice/Genome/hg38/dbsnp_146.hg38.sort.vcf 如果去冗余，则需要添加参数1perl ./BisSNP_Utils/bissnp_easy_usage.pl --duplicate ~/software/picard-tools-1.119/ -nt 8 --mmq 20 ./BisSNP-1.0.0.jar wgbs.new.replace.bam ../hg38/bowtie2_chr_index/hg38.chr.fa ./dbsnp_146.hg38.sort.vcf ======= 详细过程1234567891011121314input=$1SAMPLE=$2java -jar ~/software/picard-tools-1.119/AddOrReplaceReadGroups.jar I=$&#123;input&#125; O=wgbs.replace.bam SORT_ORDER=coordinate RGPL=Illumina CREATE_INDEX=True RGLB=LaneX RGPU=NONE RGSM=$&#123;SAMPLE&#125;java -Xmx10G -jar ~/software/BisSNP-0.82.2.jar -R ~/practice/Genome/hg38/hg38.chr.fa -I wgbs.replace.bam -D /public~/practice/Genome/hg38/dbsnp_146.hg38.sort.vcf -T BisulfiteGenotyper -vfn1 wgbs.replace.cpg.raw.vcf -vfn2 wgbs.replace.snp.raw.vcf -C CG,1 -C CH,1 -out_modes DEFAULT_FOR_TCGA -stand_call_conf 20 -stand_emit_conf 0 -nt 8 -minConv 1 -vcfCache 1000000 -mmq 20 -mbq 5perl ~/software/BisSNP_Utils/sortByRefAndCor.pl --k 1 --c 2 --tmp ./ wgbs.replace.cpg.raw.vcf ~/practice/Genome/hg38/hg38.chr.fa.fai &gt; wgbs.replace.cpg.raw.sort.vcfjava -Xmx10G -jar ~/software/BisSNP-0.82.2.jar -R ~/practice/Genome/hg38/hg38.chr.fa -T VCFpostprocess -qual 20 -C CG -C CH -oldVcf wgbs.replace.cpg.raw.sort.vcf -snpVcf wgbs.replace.snp.raw.sort.vcf -newVcf wgbs.replace.cpg.filtered.sort.vcf -o wgbs.replace.cpg.filtered.sort.vcf.cpgSummary.txt -minCT 1java -Xmx10G -jar ~/software/BisSNP-0.82.2.jar -R ~/practice/Genome/hg38/hg38.chr.fa -T VCFpostprocess -qual 20 -C CG -C CH -oldVcf wgbs.replace.snp.raw.sort.vcf -snpVcf wgbs.replace.snp.raw.sort.vcf -newVcf wgbs.replace.snp.filtered.sort.vcf -o wgbs.replace.snp.filtered.sort.vcf.cpgSummary.txt 9ab464f75714d060237c83716d7871c179cfe0a3 总结： step 1, download dbsnp: wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/dbsnp_146.hg38.vcf.gz step 2, sort vcf: sh run.sort.sh dbsnp_146.hg38.vcf dbsnp_146.hg38.sort.vcf step 3, ReplaceReadGroups: java -jar ~/software/picard-tools-1.119/AddOrReplaceReadGroups.jar I=wgbs.md.sort.bam O=wgbs.md.replace.bam SORT_ORDER=coordinate RGPL=Illumina CREATE_INDEX=True RGLB=LaneX RGPU=NONE RGSM=SAMPLENAME step 4, run BisSNP: perl ~/software/BisSNP_Utils/bissnp_easy_usage.pl -nt 8 --mmq 20 ~/software/BisSNP-0.82.2.jar wgbs.md.replace.bam ~/practice/Genome/hg38/hg38.chr.fa ~/practice/Genome/hg38/dbsnp_146.hg38.sort.vcf 注意本地java版本与BisSNP.jar版本，BisSNP-0.82.2.jar需要本地java version &lt; 1.8，BisSNP-1.0.jar则需要本地java版本 &gt; 1.8。]]></content>
      <categories>
        <category>bioinformatics</category>
        <category>DNA methylation</category>
      </categories>
      <tags>
        <tag>bioinformatics</tag>
        <tag>BisSNP</tag>
        <tag>DNA甲基化</tag>
        <tag>SNP</tag>
        <tag>sort vcf</tag>
      </tags>
  </entry>
</search>
